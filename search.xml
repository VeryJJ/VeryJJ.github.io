<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[浅聊分布式事务]]></title>
    <url>%2F2018%2F03%2F30%2F%E6%B5%85%E8%81%8A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[前言 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最近很久没有写博客了，一方面是因为公司事情最近比较忙，另外一方面是因为在进行 CAP 的下一阶段的开发工作，不过目前已经告一段落了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接下来还是开始我们今天的话题，说说分布式事务，或者说是我眼中的分布式事务，因为每个人可能对其的理解都不一样。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式事务是企业集成中的一个技术难点，也是每一个分布式系统架构中都会涉及到的一个东西，特别是在微服务架构中，几乎可以说是无法避免，本文就分布式事务来简单聊一下。 数据库事务 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在说分布式事务之前，我们先从数据库事务说起。 数据库事务可能大家都很熟悉，在开发过程中也会经常使用到。但是即使如此，可能对于一些细节问题，很多人仍然不清楚。比如很多人都知道数据库事务的几个特性：原子性(Atomicity )、一致性( Consistency )、隔离性或独立性( Isolation)和持久性(Durabilily)，简称就是ACID。但是再往下比如问到隔离性指的是什么的时候可能就不知道了，或者是知道隔离性是什么但是再问到数据库实现隔离的都有哪些级别，或者是每个级别他们有什么区别的时候可能就不知道了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文并不打算介绍这些数据库事务的这些东西，有兴趣可以搜索一下相关资料。不过有一个知识点我们需要了解，就是假如数据库在提交事务的时候突然断电，那么它是怎么样恢复的呢？ 为什么要提到这个知识点呢？ 因为分布式系统的核心就是处理各种异常情况，这也是分布式系统复杂的地方，因为分布式的网络环境很复杂，这种“断电”故障要比单机多很多，所以我们在做分布式系统的时候，最先考虑的就是这种情况。这些异常可能有 机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠的TCP、存储数据丢失、其他异常等等… &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们接着说本地事务数据库断电的这种情况，它是怎么保证数据一致性的呢？我们使用SQL Server来举例，我们知道我们在使用 SQL Server 数据库是由两个文件组成的，一个数据库文件和一个日志文件，通常情况下，日志文件都要比数据库文件大很多。数据库进行任何写入操作的时候都是要先写日志的，同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时候，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接着，我们就说一下分布式事务。 分布式理论 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们的单个数据库的性能产生瓶颈的时候，我们可能会对数据库进行分区，这里所说的分区指的是物理分区，分区之后可能不同的库就处于不同的服务器上了，这个时候单个数据库的ACID已经不能适应这种情况了，而在这种ACID的集群环境下，再想保证集群的ACID几乎是很难达到，或者即使能达到那么效率和性能会大幅下降，最为关键的是再很难扩展新的分区了，这个时候如果再追求集群的ACID会导致我们的系统变得很差，这时我们就需要引入一个新的理论原则来适应这种集群的情况，就是 CAP 原则或者叫CAP定理，那么CAP定理指的是什么呢？ CAP定理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CAP定理是由加州大学伯克利分校Eric Brewer教授提出来的，他指出WEB服务无法同时满足一下3个属性： 一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效) 可用性(Availability) ： 每个操作都必须以可预期的响应结束 分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成 具体地讲在分布式系统中，在任何数据库设计中，一个Web应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。 这个定理在迄今为止的分布式系统中都是适用的！ 为什么这么说呢？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个时候有同学可能会把数据库的2PC（两阶段提交）搬出来说话了。OK，我们就来看一下数据库的两阶段提交。 对数据库分布式事务有了解的同学一定知道数据库支持的2PC，又叫做 XA Transactions。 MySQL从5.5版本开始支持，SQL Server 2005 开始支持，Oracle 7 开始支持。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，XA 是一个两阶段提交协议，该协议分为以下两个阶段： 第一阶段：事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交. 第二阶段：事务协调器要求每个数据库提交数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。这样做的缺陷是什么呢? 咋看之下我们可以在数据库分区之间获得一致性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果CAP 定理是对的，那么它一定会影响到可用性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果说系统的可用性代表的是执行某项操作相关所有组件的可用性的和。那么在两阶段提交的过程中，可用性就代表了涉及到的每一个数据库中可用性的和。我们假设两阶段提交的过程中每一个数据库都具有99.9%的可用性，那么如果两阶段提交涉及到两个数据库，这个结果就是99.8%。根据系统可用性计算公式，假设每个月43200分钟，99.9%的可用性就是43157分钟, 99.8%的可用性就是43114分钟，相当于每个月的宕机时间增加了43分钟。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上，可以验证出来，CAP定理从理论上来讲是正确的，CAP我们先看到这里，等会再接着说。 BASE理论&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？ 前人已经给我们提出来了另外一个理论，就是BASE理论，它是用来对CAP定理进行进一步扩充的。BASE理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有了以上理论之后，我们来看一下分布式事务的问题。 分布式事务&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式系统中，要实现分布式事务，无外乎那几种解决方案。 一、两阶段提交（2PC）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;和上一节中提到的数据库XA事务一样，两阶段提交就是使用XA协议的原理，我们可以从下面这个图的流程来很容易的看出中间的一些比如commit和abort的细节。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;两阶段提交这种解决方案属于牺牲了一部分可用性来换取的一致性。在实现方面，在 .NET 中，可以借助 TransactionScop 提供的 API 来编程实现分布式系统中的两阶段提交，比如WCF中就有实现这部分功能。不过在多服务器之间，需要依赖于DTC来完成事务一致性，Windows下微软搞的有MSDTC服务，Linux下就比较悲剧了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外说一句，TransactionScop 默认不能用于异步方法之间事务一致，因为事务上下文是存储于当前线程中的，所以如果是在异步方法，需要显式的传递事务上下文。 优点： 尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能100%保证强一致） 缺点： 实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景，如果分布式系统跨接口调用，目前 .NET 界还没有实现方案。 二、补偿事务（TCC）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 举个例子，假入 Bob 要向 Smith 转账，思路大概是：我们有一个本地方法，里面依次调用1、首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。2、在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。3、如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。 优点： 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些 缺点： 缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。 三、本地消息表（异步确保）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理，这种思路是来源于ebay。我们可以从下面的流程图中看出其中的一些细节： 基本思路就是： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种方案遵循BASE理论，采用的是最终一致性，笔者认为是这几种方案里面比较适合实际业务场景的，即不会出现像2PC那样复杂的实现(当调用链很长的时候，2PC的可用性是非常低的)，也不会像TCC那样可能出现确认或者回滚不了的情况。 优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。在 .NET中 有现成的解决方案。 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 四、MQ 事务消息&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。 以阿里的 RocketMQ 中间件为例，其思路大致为： 第一阶段Prepared消息，会拿到消息的地址。 第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。 也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了RocketMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 优点： 实现了最终一致性，不需要依赖本地数据库事务。 缺点： 实现难度大，主流MQ不支持，没有.NET客户端，RocketMQ事务消息部分代码也未开源。 五、Sagas 事务模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Saga事务模型又叫做长时间运行的事务（Long-running-transaction）, 它是由普林斯顿大学的H.Garcia-Molina等人提出，它描述的是另外一种在没有两阶段提交的的情况下解决分布式系统中复杂的业务事务问题。你可以在这里看到 Sagas 相关论文。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们这里说的是一种基于 Sagas 机制的工作流事务模型，这个模型的相关理论目前来说还是比较新的，以至于百度上几乎没有什么相关资料。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该模型其核心思想就是拆分分布式系统中的长事务为多个短事务，或者叫多个本地事务，然后由 Sagas 工作流引擎负责协调，如果整个流程正常结束，那么就算是业务成功完成，如果在这过程中实现失败，那么Sagas工作流引擎就会以相反的顺序调用补偿操作，重新进行业务回滚。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如我们一次关于购买旅游套餐业务操作涉及到三个操作，他们分别是预定车辆，预定宾馆，预定机票，他们分别属于三个不同的远程接口。可能从我们程序的角度来说他们不属于一个事务，但是从业务角度来说是属于同一个事务的。 他们的执行顺序如上图所示，所以当发生失败时，会依次进行取消的补偿操作。 因为长事务被拆分了很多个业务流，所以 Sagas 事务模型最重要的一个部件就是工作流或者你也可以叫流程管理器（Process Manager），工作流引擎和Process Manager虽然不是同一个东西，但是在这里，他们的职责是相同的。在选择工作流引擎之后，最终的代码也许看起来是这样的 12345678910111213SagaBuilder saga = SagaBuilder.newSaga(&quot;trip&quot;) .activity(&quot;Reserve car&quot;, ReserveCarAdapter.class) .compensationActivity(&quot;Cancel car&quot;, CancelCarAdapter.class) .activity(&quot;Book hotel&quot;, BookHotelAdapter.class) .compensationActivity(&quot;Cancel hotel&quot;, CancelHotelAdapter.class) .activity(&quot;Book flight&quot;, BookFlightAdapter.class) .compensationActivity(&quot;Cancel flight&quot;, CancelFlightAdapter.class) .end() .triggerCompensationOnAnyError();camunda.getRepositoryService().createDeployment() .addModelInstance(saga.getModel()) .deploy(); 这里有一个 C# 相关示例，有兴趣的同学可以看一下。 优缺点 这里我们就不说了，因为这个理论比较新，目前市面上还没有什么解决方案，即使是 Java 领域，我也没有搜索的太多有用的信息。 转自：https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识鱼骨图]]></title>
    <url>%2F2018%2F03%2F29%2F%E8%AE%A4%E8%AF%86%E9%B1%BC%E9%AA%A8%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[今天，偶然的机会在同事电脑上漂见“鱼骨图”。晚上吃完饭就在思考这个问题：“为什么我从来没用过鱼骨图分析问题？鱼骨图适用于什么类型的分析？” 查了些资料追求普及，介绍的内容大同小异 概念摘要鱼骨分析法，又名 因果分析法，是一种发现问题”根本原因”的分析方法。 鱼骨图可以进一步被划分为： 整理问题型鱼骨图（各要素与特性值间不存在原因关系，而是结构构成关系） 原因型鱼骨图（鱼头在右，特性值通常以“为什么……”来写） 对策型鱼骨图（鱼头在左，特性值通常以“如何提高/改善……”来写） 怎么作图分析结构 A、针对问题点，选择层别方法（如人机料法环等）； B、按头脑风暴分别对各层别类别找出所有可能原因（因素）； C、将找出的各要素进行归类、整理，明确其从属关系； D、分析选取重要因素； E、检查各要素的描述方法，确保语法简明、意思明确; 分析要点 A、确定大要因（大骨）时，现场作业一般从“人机料法环”着手,管理类问题一般从“人事时地物”层别，应视具体情况决定； B、大要因必须用中性词描述（不说明好坏），中、小要因必须使用价值判断（如…不良）； C、头脑风暴时，应尽可能多而全地找出所有可能原因，而不仅限于自己能完全掌控或正在执行的内容。对人的原因，宜从行动而非思想态度面着手分析； D、中要因跟特性值、小要因跟中要因间有直接的原因-问题关系，小要因应分析至可以直接下对策； E、如果某种原因可同时归属于两种或两种以上因素，请以关联性最强者为准（必要时考虑三现主义：即现时到现场看现物，通过相对条件的比较，找出相关性最强的要因归类。）； F、选取重要原因时，不要超过7项，且应标识在最未端原因。 绘图过程 A、填写鱼头（按为什么不好的方式描述），画出主骨； B、画出大骨，填写大要因； C、画出中骨、小骨，填写中小要因； D、用特殊符号标识重要因素； 使用步骤(1) 查找要解决的问题； (2) 把问题写在鱼骨的头上； (3) 召集同事共同讨论问题出现的可能原因，尽可能多地找出问题； (4) 把相同的问题分组，在鱼骨上标出； (5) 根据不同问题征求大家的意见，总结出正确的原因； (6) 拿出任何一个问题，研究为什么会产生这样的问题； (7) 针对问题的答案再问为什么？这样至少深入五个层次（连续问五个问题）； (8) 当深入到第五个层次后，认为无法继续进行时，列出这些问题的原因，而后列出至少20个解决方法。 看了鱼骨图的概念介绍后，在脑海中立马出现了新的问题：”鱼骨图和思维导图有什么区别？” 鱼骨图和思维导图有什么区别？类同点 都是基于主题逐步分解、细化的过程 都是类树形结构 我的理解理解-1首先、思维导图和鱼骨图都是图形思维，而图形思维最大的特点就是将我们的思维结构化，并由此实现图形化。 而所谓的结构化一般就是构建逻辑思维，任何的逻辑思维都是基于这两个出发点而来的：1、分类；2、顺序；所以只要你的分类与顺序是一样的，那么你的逻辑思维是一样的，由此产生的图形思维也是一样的。而图形、分列、表格……只是图形思维具体的呈现方式。换句话说，在图形思维一样的前提下，不同的人选择了自己认为好的呈现方式让图形思维更可视化、更清晰化、更感性化。 另外，还有不同之处在于思维导图不仅仅能用于构建逻辑思维，还能扩展发散思维，以及还能强化思维记忆。这是和鱼骨图的区别之一！ 理解-2 【思维导图】在实际应用中，思维导图常用于个人，侧重于个人思维的发散，以求思维的全面性，思维导图的层次感是逻辑思维自然的产出。应用场景广泛。 【鱼骨图】常用在多人同时参与的头脑风暴场景，侧重于发挥团队智力逐层解剖问题，找到问题原因。往往会以”问题原因分析 + 跟进Action”作为结果产出。 鱼骨图作图工具 Xmind]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>分析图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo写作技巧]]></title>
    <url>%2F2018%2F03%2F17%2FHexo%E5%86%99%E4%BD%9C%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[Hexo 写作的技巧与备忘，不喜勿喷。 链接： Hexo命令 文章插入图片原生Markdown语法原生Markdown语法插入图片有三种方式 1. 插入本地图片只需要在基础语法的括号中填入图片的位置路径即可，支持绝对路径和相对路径。例如： 1![image](/home/picture/1.png) 评价：不灵活不好分享，本地图片的路径更改或丢失都会造成markdown文件调不出图。 2. 插入网络图片只需要在基础语法的括号中填入图片的网络链接即可，现在已经有很多免费/收费图床和方便传图的小工具可选。例如： 1![image](http://baidu.com/pic/doge.png) 评价：将图片存在网络服务器上，非常依赖网络和网络图片存储 3. 把图片存入markdown文件用base64转码工具把图片转成一段字符串，然后把字符串填到基础格式中链接的那个位置。基础用法： 1![avatar](data:image/png;base64,iVBORw0......) 这个时候会发现插入的这一长串字符串会把整个文章分割开，非常影响编写文章时的体验。如果能够把大段的base64字符串放在文章末尾，然后在文章中通过一个id来调用，文章就不会被分割的这么乱了。比如： 12![avatar][doge] [doge]:data:image/png;base64,iVBORw0...... 评价：麻烦，费劲。 Hexo方式安装插件与配置 把主页配置文件_config.yml 里的post_asset_folder:这个选项设置为true 在你的hexo目录下执行这样一句话npm install hexo-asset-image –save，这是下载安装一个可以上传本地图片的插件 等待一小段时间后，再运行hexo n “xxxx”来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 使用方式在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片 1![你想输入的替代文字](xxxx/图片名.jpg) 注意： xxxx是这个md文件的名字，也是同名文件夹的名字。只需要有文件夹名字即可，不需要有什么绝对路径。你想引入的图片就只需要放入xxxx这个文件夹内就好了，很像引用相对路径。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo装修记录]]></title>
    <url>%2F2018%2F03%2F17%2FHexo%E8%A3%85%E4%BF%AE%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[前篇《个人博客搭建-结缘Hexo》 从时间投入上来说，搭建Hexo可谓是分分钟的事情，装修可花了我近一天的时间。 Hexo 是一个开放、扩展性强的框架，样式风格、功能都可以通过主题包、插件来实现。完全可以根据个人口味来装修你的博客。 选主题关于Hexo的主题，你可以问度娘”Hexo Themes”网友好评度高的主题，也可以去官网自行挑选https://hexo.io/themes/ 需要提前说明的是：不是选上对应主题，所有功能就有了，这也是我为什么会单独写这篇备忘的原因。 经过各种试用和对比，我最终选择了：NexT这个主题 Go Github，理由如下： （Most Important）界面符合我口味。NexT 中的Pisces主题，样例：IIssNan’s Notes NexT主题集成的插件多，极大的方便了初级的小白用户，详见：NexT主题的_config.xml配置项 博客评论 Baidu Analytics / Google Analytics 文章阅读数量 baidu push algolia_search / local_search 背景画布特效 highlight_theme 等等 支持手机端 安装主题Hexo theme 统一放在Hexo根目录的themes目录下，每个主题一个子目录。 如果主题是Github上的，推荐使用如下命令下载 1git clone https://github.com/iissnan/hexo-theme-next.git themes/next 然后修改hexo根目录下的_config.xml，切换主题 OK, hexo g -&gt; hexo s 看下效果吧 主题配置找到 hexo/themes/next/_config.xml，一项项阅读熟悉吧，注释写的很详细。 基础配置基础配置项： 菜单配置：主页、关于、标签、分类、归档等 头像 打赏 社交主页 侧边栏 主题的_config.xml会引用hexo的_config.xml中基础配置，所以请同时配置hexo的_config.xml，例如：博客抬头、语种、相关数据目录等 背景特效效果图示 配置next主题的_config.xml 支持搜索 文章阅读计数NexT提供两种插件方式：1、leancloud_visitors（国内的） 和 2、firestore(谷歌的)我选用的是leancloud_visitors，配置相对简单一些 配置LeanCloud 注册：https://leancloud.cn打开LeanCloud官网，进入注册页面注册。完成邮箱激活后，点击头像，进入控制台页面创建新应用，如下： 创建名称为Counter的Class 修改NexT的_config.xml配置文件 123456# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.leancloud_visitors: enable: true app_id: "你的App Id" app_key: "你的App Key" PV/UV Google Analytics12# Google Analyticsgoogle_analytics: '你的Google Analytics Code' 问题解决标签和分类页面不显示问题当时切换NexT主题后，侧边栏的标签、分类点击时，是无法正常显示标签和分类的，属：Cannot Get /tags/ 若出现此问题，请按下方式解决在hexo 目录下执行 步骤一： 1hexo new page 'tags' 步骤二： 编辑刚新建的页面，将页面的类型设置为tags，主题会自动为这个页面显示标签云。 123456---title: TagClouddate: 2018-03-17 15:31:21type: "tags"comments: false #注意：如果有启动多说或Disqus评论，需要关闭评论，添加comments字段并设置为false--- “分类”同理~ 其他推荐 hexo的next主题个性化配置教程]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人博客搭建-结缘Hexo]]></title>
    <url>%2F2018%2F03%2F17%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA-%E7%BB%93%E7%BC%98Hexo%2F</url>
    <content type="text"><![CDATA[Github Pages + Hexo 搭建个人博客偶然的机会，看到”***.github.io”域名的个人博客，瞬间就来了兴趣，莫非Github能方便的创建个人博客？ 咨询了下度娘，知道了用GitHub Pages + Hexo 搭建个人博客的方式，于是说干就干！ PS: 我用的是Macbook + Shell，某些操作Windows的朋友可能要转化翻译成Windows上的命令。 1. 创建Github仓库首先，个人Github账号应该有吧？如果没有，先去注册一个。 然后，在Github上新建一个仓库，如下图： 确保新建的仓库以Github Pages方式发布 OK，此步骤完成了！ 2. 安装Hexo正式使用Hexo前，请先安装Node.js 和Git 安装Node.js去官网下载并安装：Link 安装Git 作为玩Github的程序员，默认你已经安装了Git 安装Hexo 新建一个目录作为Hexo的根目录（PS: 后续Hexo相关的功能以及写博客都基于此目录） 进入新建的目录 12345npm install hexo-cli -ghexo init #初始化网站npm installhexo g #hexo generate的简写，意思生成博客站点hexo s #hexo server的简写，即启动运行hexo的站点，这一步之后就可以通过http://localhost:4000 查看了 常用Hexo命令 1234hexo c : hexo clean 清除hexo已生成的publichexo g : hexo generate 重新生成hexo站点hexo s : hexo server 运行hexo站点。注：本地运行时，在hexo上做的修改保存后即生效的，不用重新hexo ghexo d : hexo deploy 将hexo发布到github上去。 3. Hexo deploy 到Github 编辑根目录下_config.yml文件 1234deploy: type: git repo: https://github.com/VeryJJ/VeryJJ.github.io.git #这里的网址填你自己的 branch: master 安装hexo deploy插件： npm install hexo-deployer-git –save 在Hexo目录下执行hexo d hexo d 成功后，就大工告成拉！你可以在浏览器输入***.github.io(你新建的github.io仓库)，就能看到你的个人博客拉！ 以后写博客的步骤为： 在电脑本地hexo new ‘文章名’ 丰富你的文章 hexo g hexo d 发布 博客搭建好了，但相信你会觉得它好丑，没关系，请继续阅读下一篇Hexo的装修总结 参考链接 我是如何利用Github Pages搭建起我的博客，细数一路的坑]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 场景化下的命令备忘]]></title>
    <url>%2F2018%2F03%2F15%2FGit%20%E5%9C%BA%E6%99%AF%E5%8C%96%E4%B8%8B%E7%9A%84%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%2F</url>
    <content type="text"><![CDATA[查看分支1234git branchgit branch -a 查看远端所有分支git branch -v 查看本地分支，以及分支上最新的commit提交信息git branch -vv 在-v基础上，多现实本地分支和远程分支的关联关系 查看某次commit的修改1git show commit号 查看某个文件的历史修改记录12345678910111213141516171819202122232425262728293031323334git log 文件名git log -p 文件名git log --author=提交人 只查看提交人的提交记录git log --pretty=oneline 单行显示提交记录git log --name-only 显示每次commit修改的文件列表git log --name-status 查看commit记录里的文件修改状态git log --grep=&apos;abc&apos; 显示commit描述匹配abc的commit记录git log -S &quot;代码内容&quot; 按代码内容搜索commit记录，如果代码内容部分想用正则表达式，则将-S换成-Ggit log --pretty=&apos;%H %Cblue%cd %C(yellow)%cn %Cred%s&apos; 按commit号+提交日期+提交人+commit标题 显示pretty格式%H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %_ae 作者的电子邮件地址 （由于新浪博客显示问题，请去除 %_ae 中的 _ ）%_ad 作者修订日期（可以用 -date= 选项定制格式）（由于新浪博客显示问题，请去除 % ad 中的 _ ）%ar 作者修订日期，按多久以前的方式显示 %cn 提交者(committer)的名字 %_ce 提交者的电子邮件地址（由于新浪博客显示问题，请去除 %_ce 中的 _ ）%_cd 提交日期 （由于新浪博客显示问题，请去除 %_cd 中的 _ ）%cr 提交日期，按多久以前的方式显示 %d: ref名称%s: 提交的信息标题%b: 提交的信息内容%Cred: 切换到红色 %Cgreen: 切换到绿色 %_Cblue: 切换到蓝色 （由于新浪博客显示问题，请去除 %_Cblue 中的 _）%Creset: 重设颜色 %C(...): 制定颜色, as described in color.branch.* config option %n: 换行 查看未commit的本地修改12git diff git diff 文件名 git diff 比较commit之间的差异123git diff commit 比较HEAD与commit之间的差异git diff commit_1 commit_2 比较两个commit之间的差异git diff commit_1..commit_2 与git diff commit_1 commit_2 一样效果 从服务器拉代码git pull --rebase (推荐)会把本地未push得commit放到缓冲区，然后把远程最新版本拉过来，再应用本地commit，这样不会造成本地有新commit时，merge的效果。 git pull 直接更新，若本地和远端都有新commit，都执行自动merge。 拉分支git checkout -b branchName 创建本地新分支 git checkout -b branchName remotes/origin/branchName 以远端分支创建本地新分支 git push origin $newBranch:$newBranch 将本地分支提交到远端进行创建 删除远程分支123$ git push origin :master# 等同于$ git push origin --delete master 提交修改git add . 将修改加到stage状态区 git commint -m &quot;注释&quot; git push 推送所有分支 git push origin develop 只推送develop分支 添加文件git add -A 删除文件git rm 文件名 git rm -r 目录名 Pushgit push push所有分支 git push origin master 将本地主分支推到远程主分支 git push –u origin master 将本地主分支推到远程（如无远程主分支则创建，用于初始化远程仓库） git push origin &lt;local_branch&gt; 创建远程分支，origin是远程仓库名。 git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; 创建远程分支 强制push如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用–force选项。 git push --force origin 合并分支mergegit merge remotes/origin/mc-s-3 将远端mc-s-3分支merge到本地 rebasegit rebase develop git rebase remotes/origin/develop 配置mergetoolgit config –global merge.tool bc3 git config –global mergetool.bc3.path 软件执行文件地址 merge策略1234567891011Git merge 策略的总结:1、使用 -s 指定策略，使用 -X 指定策略的选项2、默认策略是recursive3、策略有 ours，但是没有theirs (Git老版本好像有)4、策略ours直接 忽略 合并分支的任何内容，只做简单的合并，保留分支改动的存在5、默认策略recursive有选项ours 和 theirs6、-s recursive -X ours 和 -s ours 不同，后者如第3点提到直接忽略内容，但是前者会做合并，遇到冲突时以自己的改动为主7、-s recursive -X theirs的对立面是 -s recursive -X ours`注：-s recursive -X ours 合并分支，冲突时以本地为主` 回退未commit的修改git checkout [path] 将指定路径的修改还原到最新版本 回退已commit，未push的修改git reset HEAD &lt;file&gt; --mixed 选项：默认的 --soft 选项：改动会回退到stage状态 --hard 选项：改动会直接丢失。 git rebase -i 想要删除的commit的前一个commit号。 出来的界面里，将想要删除的commit描述改为drop，保存即可。 回退已push的修改git revert 指定的commit号。跳出来的界面，选择要回退的commit内容（取消前面的#） 可以随便选某个commit删除 若revert一个merge的commit，则要指定parent 号 git revert commit 号 -m 1。 这样就选parent 1，那么parent 1又是哪一个呢？一般来说，如果你在master上mergezhc_branch,那么parent 1就是master，parent 2就是zhc_branch. 重排commit顺序git rebase -i commit号 出来的界面中，将列出来的commit行重新排序再保存，就等于修改commit顺序了。 修改commit的描述未push方法一： git rebase -i commit号 对应commit号前改为edit，保存。出来后git commit --amend。将commit描述修改掉，保存。 出来后再git rebase --continue即可。 方法二： git commit --amend 修改最近的一次commit 代码仓库迁移git clone --bare robbin_site robbin_site.git git remote remove origin git remote add origin git@120.27.160.167:ZCY/doc-round-1.git git push –-all -–progress origin 导出指定版本的代码版本 git archive -o ../updated.zip HEAD $(git diff --name-only HEAD^) 例如：git archive -o ./version.zip 指定commit号 或者 git archive --format zip -output &quot;./archive.zip&quot; HEAD tag功能创建taggit tag -a v1.0.0 -m &apos;备注&apos; 查看taggit tag 切换taggit checkout tag名 删除taggit tag -d v1.0.0 指定commit打taggit tag -a v1.0.0 commit号 发布标签git push origin v1.0.0 将本地v1.0.0标签推送到git服务器 git push origin -tags 将本地所有tag一次性推送到git服务器 创建补丁当前分支所有超前master的提交：git format-patch -M master 某次提交以后的所有patch:git format-patch 4e16 --4e16指的是commit名 从根到指定提交的所有patch:git format-patch --root 4e16 某两次提交之间的所有patch:git format-patch 365a..4e16 -o &lt;patch_dir&gt; --365a和4e16分别对应两次提交的名称 某次提交（含）之前的几次提交：git format-patch –n 07fe --n指patch数，07fe对应提交的名称 故，单次提交即为： git format-patch -1 07fe 应用补丁方法一（推荐）12345678910111、在同一个仓库下找到对应的commit号2、切换到对应分支下，git cherry-pick commit 号3、如果冲突，git mergetool 解决冲突。4、git status根据提示commit代码，并pushcherry-pick 一个commit区间git cherry-pick &lt;start-commit-id&gt;^..&lt;end-commit-id&gt; start-commit-id是版本树里较早的commitcherry-pick一个merge commitgit cherry-pick &lt;commit-id&gt; -m parent-number -m代表 --mainline实际例子：git cherry-pick 32b234 -m 1 1，2分别代表什么 查看未push到远程仓库的commit1、查看到未传送到远程代码库的提交次数12345 git status //只能看次数显示结果类似于这样：# On branch master# Your branch is ahead of &apos;origin/master&apos; by 2 commits. 2、查看到未传送到远程代码库的提交描述/说明12345git cherry -v显示结果类似于这样：+ b6568326134dc7d55073b289b07c4b3d64eff2e7 add default charset for table items_has_images+ 4cba858e87752363bd1ee8309c0048beef076c60 move Savant3 class into www/includes/class/ 3、查看到未传送到远程代码库的提交详情1234567891011121314git log master ^origin/master这是一个git log命令的过滤，^origin/master可改成其它分支。显示结果类似于这样：commit 4cba858e87752363bd1ee8309c0048beef076c60Author: Zam &lt;zam@iaixue.com&gt;Date: Fri Aug 9 16:14:30 2013 +0800 move Savant3 class into www/includes/class/commit b6568326134dc7d55073b289b07c4b3d64eff2e7Author: Zam &lt;zam@iaixue.com&gt;Date: Fri Aug 9 16:02:09 2013 +0800 add default charset for table items_has_images 查看两个分支的差异查看dev中有，而master中没有的1234git log dev ^master反之：查看master中有，dev中没有的git log master ^dev 查看dev中比master多了哪些提交（A比B多了哪些，就把A放..右边）1git log master..dev 不在乎谁多谁少，只想看差异的提交1git log --left-right dev...master #--left-right 会帮助显示差异的commit属于哪个分支 整个目录比较差异详情1git difftool develop..pre-online --dir Git stash 暂存1234567891011121314151617git stash 将当前工作区里未commit的修改放到暂存区，将代码恢复到最近的一次修改git stash list 查看暂存区的列表git show stash@&#123;0&#125; see the last stash git stash pop apply lastest stash and remove it from th list git stash clear 清空暂存栈git stash apply stash@&#123;1&#125; 指定暂存区里的某一次stash，应用到本地 删除本地git branch -a 能看到，而远程已经删掉的分支记录1git fetch -p 更改时间显示方式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--date=(relative|local|default|iso|rfc|short|raw) Only takes effect for dates shown in human-readable format, such as when using &quot;--pretty&quot;. log.date config variable sets a default value for log command’s --date option.--date=relative shows dates relative to the current time, e.g. &quot;2 hours ago&quot;.--date=local shows timestamps in user’s local timezone.--date=iso (or --date=iso8601) shows timestamps in ISO 8601 format.--date=rfc (or --date=rfc2822) shows timestamps in RFC 2822 format, often found in E-mail messages.--date=short shows only date but not time, in YYYY-MM-DD format.--date=raw shows the date in the internal raw git format %s %z format.--date=default shows timestamps in the original timezone (either committer’s or author’s).####格式化显示例子：--date=format:&apos;%Y-%m-%d %H:%M:%S&apos;参数：%a Abbreviated weekday name%A Full weekday name%b Abbreviated month name%B Full month name%c Date and time representation appropriate for locale%d Day of month as decimal number (01 – 31)%H Hour in 24-hour format (00 – 23)%I Hour in 12-hour format (01 – 12)%j Day of year as decimal number (001 – 366)%m Month as decimal number (01 – 12)%M Minute as decimal number (00 – 59)%p Current locale&apos;s A.M./P.M. indicator for 12-hour clock%S Second as decimal number (00 – 59)%U Week of year as decimal number, with Sunday as first day of week (00 – 53)%w Weekday as decimal number (0 – 6; Sunday is 0)%W Week of year as decimal number, with Monday as first day of week (00 – 53)%x Date representation for current locale%X Time representation for current locale%y Year without century, as decimal number (00 – 99)%Y Year with century, as decimal number%z, %Z Either the time-zone name or time zone abbreviation, depending on registry settings; no characters if time zone is unknown%% Percent sign 全局更改方式1git config --global log.date relative 代码量统计当天提交的代码量1git log --author=&quot;$(git config --get user.name)&quot; --no-merges --since=1am --stat 统计报告-gitstats 用GitStatX图形化工具查看 统计报告-gitinspector1gitinspector --format=html --since=2018-01-01 --until=2018-12-30 --timeline --localize-output -w ./ &gt; ~/tmp/gitinspector/zcy-payment-center-201801.html gitinspector命令说明123456789101112131415161718192021222324252627282930313233343536➜ car-manage git:(master) gitinspector --help用法：/usr/local/bin/gitinspector [选项]... [目录] 在目录列出有关库的信息,如果没有指定目录，那么将使用现目录。如果有多个目录，将采用指定的最后一个目录长选项的强制性参数对短选项也适用布尔参数只能给予长选项 -f, --file-types=EXTENSIONS 一串逗号分隔的文件类型 这些文件将会被用于计算统计数据. 默认文件类型: java,c,cc,cpp,h,hh,hpp,py,glsl,rb,js,sql -F, --format=FORMAT 指定生成的输出文件的格式； 默认格式是&apos;text&apos; 和 可选格式: html,htmlembedded,text,xml --grading[=BOOL] 按照学生成评判项目的格式， 显示统计数据和信息； 等同于 -HlmrTw 选项 -H, --hard[=BOOL] 记录行数并且寻找重复的内容; 如果数据库较大，这个可能会需要一些时间 -l, --list-file-types[=BOOL] 列出所有现在的数据库分支的文件格式 -L, --localize-output[=BOOL] 在翻译版本存在的前提下，将输出结果翻译到系统语言 -m --metrics[=BOOL] 在分析提交时，检查特定指标 -r --responsibilities[=BOOL] 显示每位作者主要职责 --since=DATE 只显示从特定时间起的结果 -T, --timeline[=BOOL] 显示提交时间轴, 包括作者名称 --until=DATE 只显示特定时间前的结果 -w, --weeks[=BOOL] 按周来显示统计数据，而非月 -x, --exclude=PATTERN 按特定格式排除不应该被统计 的文件，作者名字或邮箱;可以按文件名，作者名， 作者邮箱。可以重复 -h, --help 显示这个帮助信息并退出 --version 显示版本信息并退出gitinspector 会过滤信息并且仅统计那些修改，增加或减少，指定文件类型的提交，如需详细信息，请参考 -f 或 --file-types 选项]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
