<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RocketMQ小笔记]]></title>
    <url>%2F2021%2F01%2F09%2FRocketMQ%E5%B0%8F%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[RocketMQ小笔记6种消息类型 普通消息 顺序消息 广播消息 延时消息 批量消息 事务消息 2种消费模式 集群消费：一个Group ID内只消费一次 广播消费：一个Group ID内所有Consumer都消费 部署架构 Name Server + broker（主/备） + producer + consumer 【broker】与所有Name Server建立长连接 【producer】与某个Name Server建立连接，查询topic所在broker，并与broker master建立连接 【consumer】与某个Name Server建立连接，查询topic所在broker，与broker master 和broker slave 分别建立连接。broker master会根据情况建议consumer从哪里拉消息 broker原理消息存储 一个broker一个commitLog（用于顺序写），broker上的多个topic共用一个commitLog。 基于commitLog ，会根据topic情况分别生成consumer queue，并建立indexFile，用于快速读取 高性能原理核心设计 - 1：（写优化）commitlog的顺序写PageCache 【页缓存 PageCache】PageCache是操作系统对文件的缓存，在PageCache上的顺序写操作速度接近于内存读写速度 核心设计 - 2：（读优化）commitlog的随机读优化 【PageCache的预读取】：从物理磁盘访问目标页时，会顺序对其相邻块的数据进行预读取。然后，在PageCache中的读取速度又接近于内存速度 【直接内存MMap】：减少了内核态和用户态的内存拷贝次数 【SSD硬盘】 核心设计 - 3：异步刷盘【默认】 【同步刷盘】真正到磁盘才回复ACK给producer。例如严格的金融业务使用。 【异步刷盘】消息刷到PageCache就回复ACK。提高性能和吞吐量 RPCRocketMQ的RPC通信采用Netty作为底层通信库，同样也遵循Reactor多线程模型。 oneway模式（极限高吞吐）此模式下，MQ Producer只发送请求不等待应答，耗时通常在微秒级完成。例如一般的日志收集场景。 怎么提升消息消费能力1、创建topic时放大queue大小，进而能提升consumer个数上限。（适用MQ队列水位高的情况） 2、增加新topic，目的也是增加queue，然后增加consumer。（适用消息量大，MQ队列水位较低的情况） 事务消息 见我另外一篇文章《分布式系统 之 分布式事务问题》 RocketMQ的问题1、消息过滤是consumer pull时，根据tag构造SubscriptionData发给broker，让broker去过滤的。而broker只会根据hashcode做过滤判断，做不到非常精确。故，在consumer端拉到消息后，还是要对消息的tag字符串进行一次比对，做到精确。 2、msgId一定是全局唯一标识符，但是实际使用中，可能会存在相同的消息有两个不同msgId的情况（消费者主动重发、因客户端重投机制导致的重复等），这种情况就需要使业务字段进行重复消费。 其他有关RocketMQ的细节备忘 NameServer可以部署多个，相互之间独立，其他角色同时向多个NameServer机器上报状态信息，从而达到热备份的目的。 NameServer本身是无状态的，也就是说NameServer中的Broker、Topic等状态信息不会持久存储，都是由各个角色定时上报并存储到内存中的(NameServer支持配置参数的持久化，一般用不到)。 为何不用ZooKeeper？ZooKeeper的功能很强大，包括自动Master选举等，RocketMQ的架构设计决定了它不需要进行Master选举， 用不到这些复杂的功能，只需要一个轻量级的元数据服务器就足够了。值得注意的是，NameServer并没有提供类似Zookeeper的watcher机制， 而是采用了每30s心跳机制。 心跳机制 单个Broker跟所有Namesrv保持心跳请求，心跳间隔为30秒，心跳请求中包括当前Broker所有的Topic信息。Namesrv会反查Broer的心跳信息， 如果某个Broker在2分钟之内都没有心跳，则认为该Broker下线，调整Topic跟Broker的对应关系。但此时Namesrv不会主动通知Producer、Consumer有Broker宕机。 Consumer跟Broker是长连接，会每隔30秒发心跳信息到Broker。Broker端每10秒检查一次当前存活的Consumer，若发现某个Consumer 2分钟内没有心跳， 就断开与该Consumer的连接，并且向该消费组的其他实例发送通知，触发该消费者集群的负载均衡(rebalance)。 生产者每30秒从Namesrv获取Topic跟Broker的映射关系，更新到本地内存中。再跟Topic涉及的所有Broker建立长连接，每隔30秒发一次心跳。 在Broker端也会每10秒扫描一次当前注册的Producer，如果发现某个Producer超过2分钟都没有发心跳，则断开连接。 Namesrv压力不会太大，平时主要开销是在维持心跳和提供Topic-Broker的关系数据。但有一点需要注意，Broker向Namesrv发心跳时， 会带上当前自己所负责的所有Topic信息，如果Topic个数太多（万级别），会导致一次心跳中，就Topic的数据就几十M，网络情况差的话， 网络传输失败，心跳失败，导致Namesrv误认为Broker心跳失败。 每个Topic可设置队列个数，自动创建主题时默认4个，需要顺序消费的消息发往同一队列，比如同一订单号相关的几条需要顺序消费的消息发往同一队列， 顺序消费的特点的是，不会有两个消费者共同消费任一队列，且当消费者数量小于队列数时，消费者会消费多个队列。至于消息重复，在消 费端处理。RocketMQ 4.3+支持事务消息，可用于分布式事务场景(最终一致性)。 关于queueNums: 客户端自动创建，Math.min算法决定最多只会创建8个(BrokerConfig)队列，若要超过8个，可通过控制台创建/修改，Topic配置保存在store/config/topics.json 消费负载均衡的最小粒度是队列，Consumer的数量应不大于队列数 读写队列数(writeQueueNums/readQueueNums)是RocketMQ特有的概念，可通过console修改。当readQueueNums不等于writeQueueNums时，会有什么影响呢？ 12345678topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(), 1000 * 3); if (topicRouteData != null) &#123; for (QueueData data : topicRouteData.getQueueDatas()) &#123; int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums()); data.setReadQueueNums(queueNums); data.setWriteQueueNums(queueNums); &#125; &#125; Broker上存Topic信息，Topic由多个队列组成，队列会平均分散在多个Broker上。Producer的发送机制保证消息尽量平均分布到 所有队列中，最终效果就是所有消息都平均落在每个Broker上。 RocketMQ的消息的存储是由ConsumeQueue和CommitLog配合来完成的，ConsumeQueue中只存储很少的数据，消息主体都是通过CommitLog来进行读写。 如果某个消息只在CommitLog中有数据，而ConsumeQueue中没有，则消费者无法消费，RocketMQ的事务消息实现就利用了这一点。 CommitLog：是消息主体以及元数据的存储主体，对CommitLog建立一个ConsumeQueue，每个ConsumeQueue对应一个（概念模型中的）MessageQueue，所以只要有 CommitLog在，ConsumeQueue即使数据丢失，仍然可以恢复出来。 ConsumeQueue：是一个消息的逻辑队列，存储了这个Queue在CommitLog中的起始offset，log大小和MessageTag的hashCode。每个Topic下的每个Queue都有一个对应的 ConsumeQueue文件，例如Topic中有三个队列，每个队列中的消息索引都会有一个编号，编号从0开始，往上递增。并由此一个位点offset的概念，有了这个概念，就可以对 Consumer端的消费情况进行队列定义。 RocketMQ的高性能在于顺序写盘(CommitLog)、零拷贝和跳跃读(尽量命中PageCache)，高可靠性在于刷盘和Master/Slave，另外NameServer 全部挂掉不影响已经运行的Broker,Producer,Consumer。 发送消息负载均衡，且发送消息线程安全(可满足多个实例死循环发消息)，集群消费模式下消费者端负载均衡，这些特性加上上述的高性能读写， 共同造就了RocketMQ的高并发读写能力。 刷盘和主从同步均为异步(默认)时，broker进程挂掉(例如重启)，消息依然不会丢失，因为broker shutdown时会执行persist。 当物理机器宕机时，才有消息丢失的风险。另外，master挂掉后，消费者从slave消费消息，但slave不能写消息。 RocketMQ具有很好动态伸缩能力(非顺序消息)，伸缩性体现在Topic和Broker两个维度。 Topic维度：假如一个Topic的消息量特别大，但集群水位压力还是很低，就可以扩大该Topic的队列数，Topic的队列数跟发送、消费速度成正比。 Broker维度：如果集群水位很高了，需要扩容，直接加机器部署Broker就可以。Broker起来后向Namesrv注册，Producer、Consumer通过Namesrv 发现新Broker，立即跟该Broker直连，收发消息。 Producer: 失败默认重试2次；sync/async；ProducerGroup，在事务消息机制中，如果发送消息的producer在还未commit/rollback前挂掉了，broker会在一段时间后回查ProducerGroup里的其他实例，确认消息应该commit/rollback Consumer: DefaultPushConsumer/DefaultPullConsumer，push也是用pull实现的，采用的是长轮询方式；CLUSTERING模式下，一条消息只会被ConsumerGroup里的一个实例消费，但可以被多个不同的ConsumerGroup消费，BROADCASTING模式下，一条消息会被ConsumerGroup里的所有实例消费。 DefaultPushConsumer: Broker收到新消息请求后，如果队列里没有新消息，并不急于返回，通过一个循环不断查看状态，每次waitForRunning一段时间(5s)，然后在check。当一直没有新消息，第三次check时，等待时间超过suspendMaxTimeMills(15s)，就返回空结果。在等待的过程中，Broker收到了新的消息后会直接调用notifyMessageArriving返回请求结果。“长轮询”的核心是，Broker端Hold住(挂起)客户端客户端过来的请求一小段时间，在这个时间内有新消息到达，就利用现有的连接立刻返回消息给Consumer。“长轮询”的主动权还是掌握在Consumer手中，Broker即使有大量消息积压，也不会主动推送给Consumer。长轮询方式的局限性，是在Hold住Consumer请求的时候需要占用资源，它适合用在消息队列这种客户端连接数可控的场景中。 DefaultPullConsumer: 需要用户自己处理遍历MessageQueue、保存Offset，所以PullConsumer有更多的自主性和灵活性。 对于集群模式的非顺序消息，消费失败默认重试16次，延迟等级为3~18。(messageDelayLevel = “1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”) MQClientInstance是客户端各种类型的Consumer和Producer的底层类，由它与NameServer和Broker打交道。如果创建Consumer或Producer 类型的时候不手动指定instanceName，进程中只会有一个MQClientInstance对象，即当一个Java程序需要连接多个MQ集群时，必须手动指定不同的instanceName。需要一提的是，当消费者(不同jvm实例)都在同一台物理机上时，若指定instanceName，消费负载均衡将失效(每个实例都将消费所有消息)。另外，在一个jvm里模拟集群消费时，必须指定不同的instanceName，否则启动时会提示ConsumerGroup已存在。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal内存泄露知识点详解]]></title>
    <url>%2F2021%2F01%2F09%2FThreadLocal%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ThreadLocal内存泄露知识点详解1、ThreadLocal常规用法12345678910public class ThreadLocal&lt;T&gt; &#123; public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier); public void set(T value); public T get(); public void remove();&#125; java.lang.ThreadLocal中只有4个public方法，非常清晰。 withInitial：是更灵活的set能力，支持传入一个方法，以方法的返回值作为ThreadLocal的初始值。 set：设置Value到当前线程的ThreadLocal中去。 get：获取当前线程存储在ThreadLocal中的Value。 remove：移除当前线程ThreadLocal存储的Value。 注：ThreadLocal是一个变量对象，一个ThreadLocal是一个存储位置。如果线程需要多个存储位置，则创建多个ThreadLocal。 常见用法： 1234567891011121314151617181920212223242526public class ThreadLocalDemo &#123; //2个ThreadLocal static ThreadLocal&lt;Integer&gt; countLocal1 = ThreadLocal.withInitial(() -&gt; 0); static ThreadLocal&lt;Integer&gt; countLocal2 = ThreadLocal.withInitial(() -&gt; 0); public static void main( String[] args ) &#123; Thread[] threads = new Thread[3]; //3个线程，共用2个ThreadLocal。互相不影响。 for(int i = 0; i &lt; threads.length; i++)&#123; threads[i] = new Thread(()-&gt;&#123; int count1 = countLocal1.get(); countLocal1.set(count1 + 5); int count2 = countLocal2.get(); countLocal2.set(count2 + 10); System.out.println(Thread.currentThread().getName() +":"+countLocal1.get()+"-&gt;"+countLocal2.get()); &#125;,"thread-"+i); &#125; for(Thread thread : threads)&#123; thread.start(); &#125; &#125;&#125; 1234运行结果：thread-0:5-&gt;10thread-2:5-&gt;10thread-1:5-&gt;10 2、ThreadLocal源码分析2.1、每个线程的ThreadLocal的Value存在哪？答： 具体是存储在当前线程Thread下的一个HashMap结构中。 此线程的所有ThreadLocal共享此HashMap。每个ThreadLocal是Map的Key，set的值就是Value。 123456789public class Thread implements Runnable &#123; ... ThreadLocal.ThreadLocalMap threadLocals = null; 《《《 存储位置 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ...&#125; ThreadLocal存储示意图 注：ThreadLocal本身不存储Value，而是以自身为标记索引，把Value存储到对应Thread的Map中去。 2.2、ThreadLocalMapThreadLocalMap是实现线程隔离机制的关键。 每个Thread内部都有 一个ThreadLocal.ThreadLocalMap类型的成员变量，该成员变量用来存储实际的ThreadLocal变量副本。 123456789public class Thread implements Runnable &#123; ... ThreadLocal.ThreadLocalMap threadLocals = null; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 这里 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ...&#125; ThreadLocalMap提供了一种用K-V健值对方式存储每个线程的变量副本的方法，key为ThreadLocal对象，value则是对应线程的变量副本。 可以看到ThreadLocalMap有个Entry内部静态类，并继承了WeakReference。由Entry记录两个信息：一个是ThreadLocal类型，一个是Object类型的值。 getEntry方法则是以ThreadLocal为Key，在线程的ThreadLocalMap中取对应的value值。set方法就是同理，更新或赋值相应ThreadLocal对应的值。 Entry继承自WeakReference（弱引用，在无强引用时，生命周期只能存活到下次GC前），但只有Key是弱引用类型的，Value并非弱引用。 特别说明： 一般网上资料介绍WeakReference特点时，表示弱引用对象的生命周期只能存活到下次GC前。这个描述不准确。 关于弱引用的GC回收，我推荐的准确描述：当一个对象仅仅被WeakReference指向，而没有任何其他StrongReference指向的时候，如果GC运行，那么这个对象就会被回收。（不错的举例） 所以，大家在代码上下文用ThreadLocal时，不用焦虑是否某个时刻被GC回收了而造成代码异常。因为当还在你代码调用上下文时，虚拟机栈上的栈帧里仍记录着对ThreadLocal的StrongReference，此时即使发生GC，ThreadLocal也是不会被回收的。 2.3、set方法123456789101112131415161718public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 获取当前线程的ThreadLocalMap map非空，则将ThreadLocal和新的value副本放入到map中。 map空，则创建ThreadLocalMap，赋值到线程Thread中，并将ThreadLocal和value副本放入map中。 2.4、get方法12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 获取当前线程的 ThreadLocalMap 以ThreadLocal为Key，从此线程的 map 中获取存储的K-V Entry节点。 从Entry节点获取存储的Value副本值返回。 2.5、remove方法123456789101112131415161718192021public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125;private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 移除当前线程的ThreadLocalMap中，ThreadLocal对应觉得Entry节点。 3、ThreadLocal什么时候会内存泄露 1、【因素1：WeakReference】线程的ThreadLocalMap中的K-V的K（ThreadLocal）是以一个弱引用身份存在的，因此当没有外部强引用来引用ThreadLocal时，在下次GC时此ThreadLocal会被回收。这个时候就会出现Entry中Key已经被回收，出现一个null Key的情况，Value讲永远不会被读取到。 2、【因素2：线程一直未退出】如果当前线程的生命周期很长，一直存在，那么其内部的ThreadLocalMap对象也一直生存下来，这些null key就存在一条强引用链的关系一直存在：Thread –&gt; ThreadLocalMap–&gt;Entry–&gt;Value，这条强引用链会导致Entry不会回收，Value也不会回收，但Entry中的Key却已经被回收的情况，造成内存泄漏。 4、如何避免ThreadLocal内存泄露4.1【知识点】JDK做了释放的优化JDK代码做了改进，会在set/get/remove操作中，主动释放属于当前线程的K为null的Entry。 4.2、【重点】良好的remove习惯既然Key是弱引用，那么我们要做的事就是在调用ThreadLocal的get()、set()方法时完成后再调用remove方法，将Entry节点和Map的引用关系移除，这样整个Entry对象在GC Roots分析后就变成不可达了，下次GC的时候就可以被回收。 良好的remove习惯可以加速ThreadLocal Value内存的释放。 如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露/内存溢出（因为会延迟到下一次调用ThreadLocal方法，有些时候可能没有下一次了）。 5、为什么ThreadLocalMap的Key是弱引用类型呢？如果 key 使用强引用：引用的ThreadLocal的对象Value被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。 如果 key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 6、最后，再特别强调关于弱引用类型： 一般网上资料介绍WeakReference特点时，表示弱引用对象的生命周期只能存活到下次GC前。这个描述是不准确的。 关于弱引用的GC回收，我推荐的准确描述：当一个对象仅仅被WeakReference指向，而没有任何其他StrongReference指向的时候，如果GC运行，那么这个对象就会被回收。（不错的举例） 所以，大家在代码上下文用ThreadLocal时，不用焦虑是否某个时刻被GC回收了而造成代码异常。因为当还在你代码调用上下文时，虚拟机栈上的栈帧里仍记录着对ThreadLocal的StrongReference，此时即使发生GC，ThreadLocal也是不会被回收的。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
        <tag>内存泄露</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手教你Java字节码Demo]]></title>
    <url>%2F2021%2F01%2F01%2F%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0Java%E5%AD%97%E8%8A%82%E7%A0%81Demo%2F</url>
    <content type="text"><![CDATA[手把手教你Java字节码Demo接触中间件的开发来说，了解像Pinpoint（https://github.com/naver/pinpoint）、BTrace（https://github.com/btraceio/btrace）、阿里的JVM-SANDBOX（https://github.com/alibaba/jvm-sandbox）、Java在线问题诊断工具**Greys**（https://github.com/oldmanpushcart/greys-anatomy）等，都是通过字节码技术，无侵入的干预到Java应用程序。很清爽又很实用。 今天就记录字节码的两种实现demo，作为入门了解。 Java Agent的最常用方式: 一种是premain方式：它属于静态注入。即在Java应用程序启动时，在类加载器对类的字节码进行加载之前对类字节码进行“再改造”来做功能增强（例如实现AOP） 一种是：HotSpot独有的attach方式（JDK1.6才出现），它能实现动态注入，对已经运行的Java应用的类进行字节码增强。 方式一：premain静态方式（大多中间件/工具的方式） 1java -javaagent:/root/application-premain.jar MyApp 如上面这句java启动命令，假定/root目录下已经有一个符合Java Agent规范的Jar了（这里指application-premain.jar），而MyApp是指我们Java应用的启动类（main方法的类），如此我们就能成功的对这个Java应用进行了静态注入。 接下来，分解一下具体实现步骤。 1、建个独立Maven工程 pom的必要依赖和设置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.21.0-GA&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 注意：如果需要进行attach，那么需要引入tools.jar--&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun&lt;/groupId&gt; &lt;artifactId&gt;tools&lt;/artifactId&gt; &lt;version&gt;1.8&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;java.home&#125;/../lib/tools.jar&lt;/systemPath&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;application-premain&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;!--避免MANIFEST.MF被覆盖--&gt; &lt;manifestFile&gt;src/main/resources/META-INF/MANIFEST.MF&lt;/manifestFile&gt; &lt;/archive&gt; &lt;descriptorRefs&gt; &lt;!--打包时加入依赖--&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 2、准备MyApp Java应用相当简单，里面就一个打印语句： 12345678910111213141516171819public class MyApp&#123; public static void main( String[] args ) &#123; while(true)&#123; printSth(); &#125; &#125; private static void printSth()&#123; System.out.println( "Hello World!" ); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 此例中，我们目标对printSth()方法进行字节码级改造，植入额外逻辑。（最终会打包成例子中的application-premain.jar） Maven工程结构大致如下： 3、编写MyTransformer MyTransformer类是具体实现字节码植入的实现类。 此例中，字节码植入的逻辑是两个打印语句。 具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package org.example.asm.premain;import java.lang.instrument.ClassFileTransformer;import java.lang.instrument.IllegalClassFormatException;import java.security.ProtectionDomain;import java.util.Objects;import javassist.ClassPool;import javassist.CtClass;import javassist.CtMethod;public class MyTransformer implements ClassFileTransformer &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; //跳过java自带方法 if (className.startsWith("java") || className.startsWith("sun"))&#123; return classfileBuffer; &#125; //好像使用premain这个className是没问题的，但使用attach时className的.变成了/，所以如果是attach，那么这里需要替换 className = className.replace("/", "."); //只处理MyApp类 if (!className.endsWith("MyApp"))&#123; return classfileBuffer; &#125; try &#123; ClassPool classPool = ClassPool.getDefault(); CtClass ctClass = classPool.get(className); CtMethod[] declaredMethods = ctClass.getDeclaredMethods(); for (CtMethod declaredMethod : declaredMethods)&#123; //只处理printSth方法 if (Objects.equals("printSth", declaredMethod.getName()))&#123; //在方法执行前插入打印语句 declaredMethod.insertBefore("System.out.println(\"=====start=====\");"); //在方法执行后插入打印语句 declaredMethod.insertAfter("System.out.println(\"=====end=====\");"); break; &#125; &#125; return ctClass.toBytecode(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return classfileBuffer; &#125;&#125; 可以看到MyTransformer实现了ClassFileTransformer接口，ClassFileTransformer是专门为Java Agent提供类转换功能的接口。 在transform方法中，我们可以大显身手了，从上面代码片段可以看出，我们只是对MyApp#printSth方法的之前和末尾各加入了一条打印语句，你可能会奇怪，不是字节码吗？为啥可以直接像表达式引擎一样直接输入Java表达式？是因为这里使用了javassist这一轻量级的字节码工具，它帮我们屏蔽了字节码的细节，使我们可以只关注Java代码。 4、编写Premain类 有了MyTransformer，在哪用？答案就在PremainMain类中，PremainMain要做的事情很简单，就是把我们自定义的类转换器MyTransformer加到前面提到的Instrumentation实例中： 1234567891011121314package org.example.asm.premain;import java.lang.instrument.Instrumentation;public class PremainMain &#123; /** * 注意，这个premain方法签名是Java Agent约定的，不要随意修改 * @param agentArgs * @param instrumentation */ public static void premain(String agentArgs, Instrumentation instrumentation) &#123; instrumentation.addTransformer(new MyTransformer()); &#125;&#125; 注意：PremainMain#premain的方法签名是Java Agent内部约定的，不能随意修改。 5、编写MANIFEST.MF Java Agent是怎么知道premain方法在哪个类中呢？答案就application-premain.jar的resources/META-INF/MANIFEST.MF文件中，MANIFEST.MF文件内容如下： 123Manifest-Version: 1.0Created-By: veryJJPremain-Class: org.example.asm.premain.PremainMain 注意：最后一行需要留一个空行 6、打包&amp;运行 几步操作下来，必要的文件已就绪，我们把它打成一个jar包（需要包含javassist），需用到maven-assembly-plugin插件（再check下pom），项目的pom.xml文件内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;build&gt; &lt;finalName&gt;asm-premain&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;!--避免MANIFEST.MF被覆盖--&gt; &lt;manifestFile&gt;src/main/resources/META-INF/MANIFEST.MF&lt;/manifestFile&gt; &lt;/archive&gt; &lt;descriptorRefs&gt; &lt;!--打包时加入依赖--&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 我们直接执行Maven的打包命令： 1mvn clean package 打包完成后，我们会在target目录下得到：application-premain.jar 和 application-premain-jar-with-dependences.jar。注，用application-premain-jar-with-dependences.jar哦。为了方便，可以在cp命令拷贝到/root目录时顺便重命名的短一些。（拷贝其他任何目录都可以的哦） 一切就绪了，idea上运行 运行结果如下： 1234567891011121314151617=====start=====Hello World!=====end==========start=====Hello World!=====end==========start=====Hello World!=====end==========start=====Hello World!=====end==========start=====Hello World!=====end==========start=====Hello World! 可以看到，原本只有一个打印”Hello World”语句的MyApp类，在前后加了两条打印语句，目标达成！！！！！ 方式二、AttachAgent动态方式（混动工程的实现方式） 如何动态注入字节码呢？为了更清晰的展示，我们创建两个独立的maven工程，一个模拟业务应用：循环执行printSth方法。一个模拟动态attach植入。 OrderApp代码如下 12345678910111213141516171819public class OrderApp&#123; public static void main( String[] args ) &#123; while(true)&#123; printSth(); &#125; &#125; private static void printSth()&#123; System.out.println( "Hello World!" ); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 准备动态植入的代码 1、编写Transformer类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package org.attach;import javassist.ClassPool;import javassist.CtClass;import javassist.CtMethod;import java.lang.instrument.ClassFileTransformer;import java.lang.instrument.IllegalClassFormatException;import java.security.ProtectionDomain;import java.util.Objects;public class MyAttachTransformer implements ClassFileTransformer &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException &#123; //跳过java自带方法 if (className.startsWith("java") || className.startsWith("sun"))&#123; return classfileBuffer; &#125; //好像使用premain这个className是没问题的，但使用attach时className的.变成了/，所以如果是attach，那么这里需要替换 className = className.replace("/", "."); //只处理MyApp类 if (!className.endsWith("OrderApp"))&#123; return classfileBuffer; &#125; try &#123; ClassPool classPool = ClassPool.getDefault(); CtClass ctClass = classPool.get(className); CtMethod[] declaredMethods = ctClass.getDeclaredMethods(); for (CtMethod declaredMethod : declaredMethods)&#123; //只处理printSth方法 if (Objects.equals("printSth", declaredMethod.getName()))&#123; //在方法执行前插入打印语句 declaredMethod.insertBefore("System.out.println(\"=====start=====\");"); //在方法执行后插入打印语句 declaredMethod.insertAfter("System.out.println(\"=====end=====\");"); break; &#125; &#125; return ctClass.toBytecode(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return classfileBuffer; &#125;&#125; 2、新增AttachAgent类 123456789101112131415161718192021222324252627282930313233343536373839404142434445package org.example.asm.attach;import org.example.asm.premain.MyTransformer;import java.lang.instrument.Instrumentation;import java.lang.instrument.UnmodifiableClassException;public class AttachAgent &#123; /** * 注意：agentmain的方法签名也是约定好的，不能随意修改 * * 其实如果要支持premain和attach两种方式的话，可以把premain和agentmain两个方法写在一个类里，这里为了方便演示，写成了两个 * * @param agentArgs * @param instrumentation */ public static void agentmain(String agentArgs, Instrumentation instrumentation) &#123; String targetClassPath = "org.example.MyApp"; System.out.println("come in agentmain"); for (Class&lt;?&gt; clazz : instrumentation.getAllLoadedClasses()) &#123; // 过滤掉不能修改的类 if(!instrumentation.isModifiableClass(clazz)) &#123; continue; &#125; System.out.println("clazz = " + clazz.getName()); // 只修改我们关心的类 if (clazz.getName().equals(targetClassPath)) &#123; // 最根本的目的还是把MyTransformer添加到instrumentation中 instrumentation.addTransformer(new MyTransformer(), true); try &#123; instrumentation.retransformClasses(clazz); &#125; catch (UnmodifiableClassException e) &#123; e.printStackTrace(); &#125; return; &#125; &#125; &#125;&#125; 这里约定好的方法是agentmain，但agentmain方法的本质也是把MyTransformer添加到instrumentation中，进而动态刷新目标class的transformer。 3、配置MANIFEST.MF 12345Manifest-Version: 1.0Created-By: veryJJAgent-Class: org.attach.AttachAgentCan-Redefine-Classes: trueCan-Retransform-Classes: true 4、test-asm-attach工程打包 得到attach-premain-jar-with-dependencies.jar和attach-premain.jar 记得使用：attach-premain-jar-with-dependencies.jar（对应下面attchMain中的jar，按需重命名） 5、此时，先运行OrderApp 会看到，此时OrderApp循环打印“Hello World！” 6、编写并运行动态AttachMain代码 编写attachMain，并attach到OrderApp上去。 1234567891011121314151617181920212223242526272829303132package org.attach;import com.sun.tools.attach.VirtualMachine;import java.io.File;import java.util.concurrent.TimeUnit;public class AttachMain &#123; public static void main(String[] args)&#123; //OrderApp的jvm进程ID String jvmPID = "6279"; File agentFile = new File("/你的目录路径/attach-premain-all.jar"); if (!agentFile.isFile())&#123; System.out.println("jar 不存在"); return; &#125; try &#123; VirtualMachine jvm = VirtualMachine.attach(jvmPID); jvm.loadAgent(agentFile.getAbsolutePath()); jvm.detach(); System.out.println("attach 成功"); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; //attach植入后就可以退出了哦。因为代码已经进入目标JVM的内存空间了。 &#125;&#125; 运行上述AttachMain，此时查看OrderApp的控制台界面，会得到： 至此，就完成了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CGLIB中常用API]]></title>
    <url>%2F2020%2F12%2F31%2FCGLIB%E4%B8%AD%E5%B8%B8%E7%94%A8API%2F</url>
    <content type="text"><![CDATA[CGLIBCGLIB，即Code Generation Library，是一个开源项目。Github地址：https://github.com/cglib/cglib。 CGLIB的github简介：CGLIB - 字节码生成库，是用于生成和转换Java字节码的高级API。它被AOP、测试、数据访问框架用于生成动态代理对象和拦截字段访问。 CGLIB提供两种类型的JAR包： cglib-nodep-x.x.x.jar：使用nodep包不需要关联ASM的jar包，jar包内部包含ASM的类库。 cglib-x.x.x.jar：使用此jar包需要另外提供ASM的jar包，否则运行时报错，建议选用不包含ASM类库的jar包，可以方便控制ASM的。 本文中使用的CGLIB依赖为： 1234567891011&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib-nodep&lt;/artifactId&gt; &lt;version&gt;3.2.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt;&lt;/dependency&gt; CGLIB基本原理 基本原理：动态生成一个要代理类的子类(被代理的类作为继承的父类)，子类重写要代理的类的所有不是final的方法。在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。它比使用Java反射的JDK动态代理要快，因为它采用了整形变量建立了方法索引。 底层实现：使用字节码处理框架ASM，用于转换字节码并生成新的类。不鼓励直接使用ASM，因为它要求必须对JVM内部结构包括class文件的格式和JVM指令集都很熟悉，否则一旦出现错误将会是JVM崩溃级别的异常。 CGLIB的包结构 net.sf.cglib.core：底层字节码处理类，大部分与ASM有关。 net.sf.cglib.transform：编译期或运行期类和类文件的转换。 net.sf.cglib.proxy：实现创建代理和方法拦截器的类。 net.sf.cglib.reflect：反射相关工具类。 net.sf.cglib.util：集合排序等工具类。 net.sf.cglib.beans：JavaBean相关的工具类。 CGLIB常用API下面介绍一下CGLIB中常用的几个API，先建立一个模特接口类和普通模特类： 1234567891011public class SampleClass &#123; public String sayHello(String name) &#123; return String.format("%s say hello!", name); &#125;&#125;public interface SampleInterface &#123; String sayHello(String name);&#125; EnhancerEnhancer，即(字节码)增强器。它是CGLIB库中最常用的一个类，功能与JDK动态代理中引入的Proxy类差不多，但是Enhancer既能够代理普通的Java类，也能够代理接口。 Enhancer创建一个被代理对象的子类并且拦截所有的方法调用（包括从Object中继承的toString和hashCode方法）。 Enhancer不能够拦截final方法，例如Object.getClass()方法，这是由于final关键字的语义决定的。基于同样的道理，Enhancer也不能对fianl类进行代理操作。这也是Hibernate为什么不能持久化final关键字修饰的类的原因。 12345678910111213141516public class EnhancerClassDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); //使用FixedValue，拦截返回值，每次返回固定值"Doge say hello!" enhancer.setCallback((FixedValue) () -&gt; "Doge say hello!"); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello("throwable-10086")); System.out.println(sampleClass.sayHello("throwable-doge")); System.out.println(sampleClass.toString()); System.out.println(sampleClass.getClass()); System.out.println(sampleClass.hashCode()); &#125;&#125; 输出结果： 123456Doge say hello!Doge say hello!Doge say hello!class club.throwable.cglib.SampleClass$$EnhancerByCGLIB$$6f6e7a68Exception in thread "main" java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number...... 上述代码中，FixedValue用来对所有拦截的方法返回相同的值，从输出我们可以看出来，Enhancer对非final方法test()、toString()、hashCode()进行了拦截，没有对getClass进行拦截。由于hashCode()方法需要返回一个Number，但是我们返回的是一个String，这解释了上面的程序中为什么会抛出异常。 Enhancer#setSuperclass()用来设置父类型，从toString()方法可以看出，使用CGLIB生成的类为被代理类的一个子类，类简写名称为SampleClass$$EnhancerByCGLIB$$e3ea9b7。 Enhancer#create(Class[] argumentTypes, Object[] arguments)方法是用来创建增强对象的，其提供了很多不同参数的方法用来匹配被增强类的不同构造方法。我们也可以先使用Enhancer#createClass()来创建字节码(.class)，然后用字节码加载完成后的类动态生成增强后的对象。Enhancer中还有其他几个方法名为create的方法，提供不同的参数选择，具体可以自行查阅。 下面再举个例子说明一下使用Enhancer代理接口： 1234567891011121314public class EnhancerInterfaceDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setInterfaces(new Class[]&#123;SampleInterface.class&#125;); enhancer.setCallback((FixedValue) () -&gt; "Doge say hello!"); SampleInterface sampleInterface = (SampleInterface) enhancer.create(); System.out.println(sampleInterface.sayHello("throwable-10086")); System.out.println(sampleInterface.sayHello("throwable-doge")); System.out.println(sampleInterface.toString()); System.out.println(sampleInterface.getClass()); System.out.println(sampleInterface.hashCode()); &#125;&#125; 输出结果和上一个例子一致。 CallbackCallback，即回调。值得注意的是，它是一个标识接口(空接口，没有任何方法)，它的回调时机是生成的代理类的方法被调用的时候。也就是说，生成的代理类的方法被调用的时候，Callback的实现逻辑就会被调用。Enhancer通过setCallback()和setCallbacks()设置Callback，设置了多个Callback实例将会按照设置的顺序进行回调。CGLIB中提供的Callback的子类有以下几种： NoOp FixedValue InvocationHandler MethodInterceptor Dispatcher LazyLoader NoOpNoOp，No Operation，也就是不做任何操作。这个回调实现只是简单地把方法调用委托给了被代理类的原方法(也就是调用原始类的原始方法)，不做任何其它的操作，所以不能使用在接口代理。 12345678910public class NoOpDemo &#123; public static void main(String[] args) throws Exception&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(NoOp.INSTANCE); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello("throwable")); &#125;&#125; 输出结果： 1throwable say hello! FixedValueFixedValue，Fixed Value，即固定值。 它提供了一个loadObject()方法，不过这个方法返回的不是代理对象，而是原方法调用想要的结果。也就是说，在这个Callback里面，看不到任何原方法的信息，也就没有调用原方法的逻辑，不管原方法是什么都只会调用loadObject()并返回一个固定结果。 需要注意的是，如果loadObject()方法的返回值并不能转换成原方法的返回值类型，那么会抛出类型转换异常(ClassCastException)。 最前面的Enhancer两个例子就是用FixedValue做分析的，这里不再举例。 InvocationHandlerInvocationHandler全类名为net.sf.cglib.proxy.InvocationHandler，它的功能和JDK动态代理中的java.lang.reflect.InvocationHandler类似，提供了一个Object invoke(Object proxy, Method method, Object[] objects)方法。 需要注意的是：所有对invoke方法的参数proxy对象的方法调用都会被委托给同一个InvocationHandler，所以可能会导致无限循环(因为invoke中调用的任何原代理类方法，均会重新代理到invoke方法中)。举个简单的例子： 123456789101112131415public class InvocationHandlerDeadLoopDemo &#123; public static void main(String[] args) throws Exception&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(new InvocationHandler() &#123; @Override public Object invoke(Object o, Method method, Object[] objects) throws Throwable &#123; return method.invoke(o, objects); &#125; &#125;); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello("throwable")); &#125;&#125; 上面的main方法执行后会直接爆栈，因为method#invoke()方法会重新调用InvocationHandler的invoke方法，形成死循环。 正确的使用例子如下： 12345678910111213141516171819public class InvocationHandlerDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(new InvocationHandler() &#123; @Override public Object invoke(Object o, Method method, Object[] objects) throws Throwable &#123; if (!Objects.equals(method.getDeclaringClass(), Object.class) &amp;&amp; Objects.equals(String.class, method.getReturnType())) &#123; return String.format("%s say hello!", objects); &#125; return "No one say hello!"; &#125; &#125;); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello("throwable")); &#125;&#125; 输出结果： 1throwable say hello! MethodInterceptorMethodInterceptor，即方法拦截器，这是一个功能很强大的接口，它可以实现类似于AOP编程中的环绕增强（Around Advice）。 它只有一个方法public Object intercept(Object obj,java.lang.reflect.Method method,Object[] args,MethodProxy methodProxy) throws Throwable。设置了MethodInterceptor后，代理类的所有方法调用都会转而执行这个接口中的intercept方法而不是原方法。如果需要在intercept方法中执行原方法可以使用参数method基于代理实例obj进行反射调用，但是使用方法代理methodProxy效率会更高（反射调用比正常的方法调用的速度慢很多）。 MethodInterceptor的生成效率不高，它的优势在于调用效率，它需要产生不同类型的字节码，并且需要生成一些运行时对象(InvocationHandler就不需要)。 注意，在使用MethodProxy调用invokeSuper方法相当于通过方法代理直接调用原类的对应方法，如果调用MethodProxy的invoke会进入死循环导致爆栈，原因跟InvocationHandler差不多。 123456789101112131415161718public class MethodInterceptorDemo &#123; public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SampleClass.class); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object obj, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("Before invoking sayHello..."); Object result = methodProxy.invokeSuper(obj, objects); System.out.println("After invoking sayHello..."); return result; &#125; &#125;); SampleClass sampleClass = (SampleClass) enhancer.create(); System.out.println(sampleClass.sayHello("throwable")); &#125;&#125; 输出结果： 123Before invoking sayHello...After invoking sayHello...throwable say hello! 这个例子就是Spring的AOP中的环绕增强(Around Advice)的简化版，这里没有改变原来的方法的行为，只是在方法调用前和调用后织入额外的逻辑。 DispatcherDispatcher，即分发器，提供一个方法Object loadObject() throws Exception;，同样地返回一个代理对象，这个对象同样可以代理原方法的调用。Dispatcher的loadObject()方法在每次发生对原方法的调用时都会被调用并返回一个代理对象来调用原方法。Dispatcher可以类比为Spring中的Prototype类型。 123456789101112131415161718192021222324252627282930313233public class DispatcherDemo &#123; private static final AtomicInteger COUNTER = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); SampleInterfaceImpl impl = new SampleInterfaceImpl(); enhancer.setInterfaces(new Class[]&#123;SampleInterface.class&#125;); enhancer.setCallback(new Dispatcher() &#123; @Override public Object loadObject() throws Exception &#123; COUNTER.incrementAndGet(); return impl; &#125; &#125;); SampleInterface sampleInterface = (SampleInterface) enhancer.create(); System.out.println(sampleInterface.sayHello("throwable-1")); System.out.println(sampleInterface.sayHello("throwable-2")); System.out.println(COUNTER.get()); &#125; private static class SampleInterfaceImpl implements SampleInterface&#123; public SampleInterfaceImpl()&#123; System.out.println("SampleInterfaceImpl init..."); &#125; @Override public String sayHello(String name) &#123; return "Hello i am SampleInterfaceImpl!"; &#125; &#125;&#125; 输出结果： 1234SampleInterfaceImpl init...Hello i am SampleInterfaceImpl!Hello i am SampleInterfaceImpl!2 计数器输出为2，印证了每次调用方法都会回调Dispatcher中的实例进行调用。 LazyLoaderLazyLoader，即懒加载器，它只提供了一个方法Object loadObject() throws Exception;，loadObject()方法会在第一次被代理类的方法调用时触发，它返回一个代理类的对象，这个对象会被存储起来然后负责所有被代理类方法的调用，就像它的名字说的那样，一种lazy加载模式。如果被代理类或者代理类的对象的创建比较麻烦，而且不确定它是否会被使用，那么可以选择使用这种lazy模式来延迟生成代理。 LazyLoader可以类比为Spring中的Lazy模式的Singleton。 123456789101112131415161718192021222324252627282930313233public class LazyLoaderDemo &#123; private static final AtomicInteger COUNTER = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; Enhancer enhancer = new Enhancer(); SampleInterfaceImpl impl = new SampleInterfaceImpl(); enhancer.setInterfaces(new Class[]&#123;SampleInterface.class&#125;); enhancer.setCallback(new LazyLoader() &#123; @Override public Object loadObject() throws Exception &#123; COUNTER.incrementAndGet(); return impl; &#125; &#125;); SampleInterface sampleInterface = (SampleInterface) enhancer.create(); System.out.println(sampleInterface.sayHello("throwable-1")); System.out.println(sampleInterface.sayHello("throwable-2")); System.out.println(COUNTER.get()); &#125; private static class SampleInterfaceImpl implements SampleInterface&#123; public SampleInterfaceImpl()&#123; System.out.println("SampleInterfaceImpl init..."); &#125; @Override public String sayHello(String name) &#123; return "Hello i am SampleInterfaceImpl!"; &#125; &#125;&#125; 输出结果： 1234SampleInterfaceImpl init...Hello i am SampleInterfaceImpl!Hello i am SampleInterfaceImpl!1 计数器输出为1，印证了LazyLoader中的实例只回调了1次，这就是懒加载。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>cglib</tag>
        <tag>字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决homebrew长时间停在Updating Homebrew 这个步骤]]></title>
    <url>%2F2020%2F12%2F19%2F%E8%A7%A3%E5%86%B3homebrew%E9%95%BF%E6%97%B6%E9%97%B4%E5%81%9C%E5%9C%A8Updating%20Homebrew%20%E8%BF%99%E4%B8%AA%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[在国内的网络环境下使用 Homebrew 安装软件的过程中可能会长时间卡在 Updating Homebrew 这个步骤。 例：执行 brew install composer 命令12➜ ~ brew install composerUpdating Homebrew... # 如果碰到长时间卡在这里，参考以下 2 种处理方法 方法 1：按住 control + c 取消本次更新操作12345678910111213➜ ~ brew install composerUpdating Homebrew...^C按住 control + c 之后命令行会显示 ^C，就代表已经取消了 Updating Homebrew 操作大概不到 1 秒钟之后就会去执行我们真正需要的安装操作了➜ ~ brew install composerUpdating Homebrew...^C==&gt; Satisfying dependencies==&gt; Downloading https://getcomposer.org/download/1.7.2/composer.phar...这个方法是临时的、一次性的 【推荐】方法 2：使用 Alibaba 的 Homebrew 镜像源进行加速平时我们执行 brew 命令安装软件的时候，跟以下 3 个仓库地址有关： brew.git homebrew-core.git homebrew-bottles 通过以下操作将这 3 个仓库地址全部替换为 Alibaba 提供的地址 1. 替换 / 还原 brew.git 仓库地址 替换成阿里巴巴的 brew.git 仓库地址:12cd "$(brew --repo)"git remote set-url origin https://mirrors.aliyun.com/homebrew/brew.git 还原为官方提供的 brew.git 仓库地址 12cd "$(brew --repo)"git remote set-url origin https://github.com/Homebrew/brew.git 2. 替换 / 还原 homebrew-core.git 仓库地址 替换成阿里巴巴的 homebrew-core.git 仓库地址: 12cd "$(brew --repo)/Library/Taps/homebrew/homebrew-core"git remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-core.git 还原为官方提供的 homebrew-core.git 仓库地址 12cd "$(brew --repo)/Library/Taps/homebrew/homebrew-core"git remote set-url origin https://github.com/Homebrew/homebrew-core.git 3. 替换 / 还原 homebrew-bottles 访问地址这个步骤跟你的 macOS 系统使用的 shell 版本有关系 所以，先来查看当前使用的 shell 版本1echo $SHELL 如果你的输出结果是 /bin/zsh，参考3.1的 zsh 终端操作方式 如果你的输出结果是 /bin/bash，参考3.2的 bash 终端操作方式 3.1 zsh 终端操作方式 替换成阿里巴巴的 homebrew-bottles 访问地址: 12echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.aliyun.com/homebrew/homebrew-bottles' &gt;&gt; ~/.zshrcsource ~/.zshrc 还原为官方提供的 homebrew-bottles 访问地址 123vi ~/.zshrc然后，删除 HOMEBREW_BOTTLE_DOMAIN 这一行配置source ~/.zshrc 3.2 bash 终端操作方式 替换 homebrew-bottles 访问 URL: 12echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.aliyun.com/homebrew/homebrew-bottles' &gt;&gt; ~/.bash_profilesource ~/.bash_profile 还原为官方提供的 homebrew-bottles 访问地址 123vi ~/.bash_profile然后，删除 HOMEBREW_BOTTLE_DOMAIN 这一行配置source ~/.bash_profile]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[slf4j MDC是个好东西]]></title>
    <url>%2F2020%2F12%2F19%2Fslf4j%20MDC%E6%98%AF%E4%B8%AA%E5%A5%BD%E4%B8%9C%E8%A5%BF%2F</url>
    <content type="text"><![CDATA[slf4j MDC是个好东西简介MDC 全拼 Mapped Diagnostic Contexts，是SLF4J类日志系统中实现分布式多线程日志数据传递的重要工具。 同时，用户也可利用MDC将一些运行时的上下文数据打印出来。 什么意思呢？ 常规情况下，写打日志的代码时，一般都是log.info、log.warn、log.error将想要打的日志进行拼装和格式化，打到日志输出中。MDC能干什么呢？能在不改动log.xxx打日志代码的情况下，在最终的日志输出的指定位置打印额外的信息。而这，就是靠MDC进行传递实现的。 应用场景在日志中自动打印框架/组件方面的信息 例如： 全链路日志traceId 用户请求的IP地址、user-agent 代码示例 一般配合AOP / Filter / Interceptor使用 12345678910111213@Around(value = "execution(* com.xx.xx.facade.impl.*.*(..))", argNames="pjp")public Object validator(ProceedingJoinPoint pjp) throws Throwable &#123; try &#123; String traceId = TraceUtils.begin(); MDC.put("mdc_trace_id", traceId); Object obj = pjp.proceed(args); return obj; &#125; catch(Throwable e) &#123; //TODO 处理错误 &#125; finally &#123; TraceUtils.endTrace(); &#125;&#125; 代码通过AOP记录了每次请求的traceId，并使用变量”mdc_trace_id”记录到MDC内。 在日志配置文件里需要设置变量才能将”mdc_trace_id”输出到日志文件中。以logback配置文件为例，看日志第10行%X{mdc_trace_id}： 123456789101112&lt;appender name="ALL" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;CATALINA_BASE&#125;/logs/all.log&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!-- daily rollover --&gt; &lt;fileNamePattern&gt;$&#123;CATALINA_BASE&#125;/logs/all.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;!-- keep 30 days' worth of history --&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder charset="UTF-8"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - traceId:[%X&#123;mdc_trace_id&#125;] - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; 可见的优势1、如果你的系统早已上线，突然有一天老板说我们增加一些用户数据到日志里分析一下。如果没有MDC，你不得不在N个工程里翻天覆地的“传参数+改打日志的代码”，你肯定很崩溃，不懂技术的老板也很无奈（就多加几点信息，这么大动静吗？）。而MDC能让你很从容的完成此事。 笔者团队就有这样的情况，但提出在日志里加内容的是我们自已的优化想法：将pinpoint的链路标识打到应用日志里去。 2、使代码简洁、日志风格统一、变更灵活。 对MDC源码的窥探MDC所在的jar包 此处以 Logback中的实现为例。为了方便讲解，我们只分析MDC的put()方法： 12345678910111213public class MDC &#123; public static void put(String key, String val) throws IllegalArgumentException &#123; if (key == null) &#123; throw new IllegalArgumentException("key parameter cannot be null"); &#125; if (mdcAdapter == null) &#123; throw new IllegalStateException("MDCAdapter cannot be null. See also " + NULL_MDCA_URL); &#125; mdcAdapter.put(key, val); &#125; MDC的put()方法利用MDCAdapter实现。 Logback中的具体实现 既然一般都是结合AOP使用MDC，那么还是要考虑内部方法实现时的支撑情况，例如：多线程 下面看一下Logback中MDCAdapter的实现LogbackMDCAdapter： 123456789101112131415161718public final class LogbackMDCAdapter implements MDCAdapter &#123; final InheritableThreadLocal&lt;Map&lt;String, String&gt;&gt; copyOnInheritThreadLocal = new InheritableThreadLocal(); public void put(String key, String val) throws IllegalArgumentException &#123; if (key == null) &#123; throw new IllegalArgumentException("key cannot be null"); &#125; else &#123; Map&lt;String, String&gt; oldMap = (Map)this.copyOnInheritThreadLocal.get(); Integer lastOp = this.getAndSetLastOperation(1); if (!this.wasLastOpReadOrNull(lastOp) &amp;&amp; oldMap != null) &#123; oldMap.put(key, val); &#125; else &#123; Map&lt;String, String&gt; newMap = this.duplicateAndInsertNewMap(oldMap); newMap.put(key, val); &#125; &#125; &#125;&#125; MDC只有一种用法：MDC.put(X,Y)。那么，在MDC的具体实现包中，肯定会有个Map作为存储容器。如上，LogbackMDCAdapter中也有Map&lt;String, String&gt;。 MDC内的key-value要能在调用链路中都能打印，那么Map肯定是存储在ThreadLocal中传递。 Map&lt;String, String&gt;存储在InheritableThreadLocal中，即AOP内真正的业务方法内部若进行了子线程的创建，MDC内的key-value也能正常的打印到日志中。但，内部若是线程池的方式执行细分业务，则线程池任务内打印的日志则不会有此内容（线程池的ThreadLocal传递需要用TransmittableThreadLocal）。比较遗憾，logback没有预留这一点的SPI。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>日志框架</tag>
        <tag>slf4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 生成随机数的 5 种方式]]></title>
    <url>%2F2020%2F12%2F16%2FJava%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%9A%84%205%20%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[先说结论 试测数据： 基于常见场景：在一个数据范围区间内生成随机数。 1000万的随机数范围，for循环生成50万个随机数。无其他额外操作。 SDK包 性能耗时 评价 java.util.Random 9毫秒 1、编写简单，方法较多，也快速。很多SDK包都基于此扩展。2、随机性重度依赖seed的情况，seed一样，分配的随机数和顺序一样。3、线程不安全。 ThreadLocalRandom 8毫秒 1、继承于java.util.Random2、与线程绑定，一个线程一个，多线程下安全。3、seed情况部分借助于线程的内存地址等随机信息，来提升随机性。 Math.Random 14毫秒 1、用法上比较费劲，只能生成double。2、内部有借用java.util.Random SecureRandom 142毫秒 线程安全，seed不可预测（借助于系统中的随机事件信息） Apache#RandomDataGenerator 54毫秒 API比较丰富，特殊场景下考虑。 it.unimi.dsi#XoRoShiRo128PlusRandom 17毫秒 偏门的三方包。比较快。线程不安全。 1. Math.random() 静态方法产生的随机数是 0 - 1 之间的一个 double，即 0 &lt;= random &lt;= 1。 使用： 123for (int i = 0; i &lt; 10; i++) &#123; System.out.println(Math.random());&#125; 结果：123456789100.3598613895606426 0.2666778145365811 0.25090731064243355 0.011064998061666276 0.600686228175639 0.9084006027629496 0.12700524654847833 0.6084605849069343 0.7290804782514261 0.9923831908303121 实现原理： When this method is first called, it creates a single new pseudorandom-number generator, exactly as if by the expression new java.util.Random() This new pseudorandom-number generator is used thereafter for all calls to this method and is used nowhere else. 当第一次调用 Math.random() 方法时，自动创建了一个伪随机数生成器，实际上用的是 new java.util.Random()。当接下来继续调用 Math.random() 方法时，就会使用这个新的伪随机数生成器。 源码如下：12345678910public static double random() &#123; Random rnd = randomNumberGenerator; if (rnd == null) rnd = initRNG(); // 第一次调用，创建一个伪随机数生成器 return rnd.nextDouble();&#125;private static synchronized Random initRNG() &#123; Random rnd = randomNumberGenerator; return (rnd == null) ? (randomNumberGenerator = new Random()) : rnd; // 实际上用的是new java.util.Random()&#125; initRNG() 方法是 synchronized 的，因此在多线程情况下，只有一个线程会负责创建伪随机数生成器（使用当前时间作为种子），其他线程则利用该伪随机数生成器产生随机数。Java生成随机数的几种高级用法，这篇推荐看一下。 因此 Math.random() 方法是线程安全的。什么情况下随机数的生成线程不安全？ 线程1在第一次调用 random() 时产生一个生成器 generator1，使用当前时间作为种子。 线程2在第一次调用 random() 时产生一个生成器 generator2，使用当前时间作为种子。 碰巧 generator1 和 generator2 使用相同的种子，导致 generator1 以后产生的随机数每次都和 generator2 以后产生的随机数相同。 什么情况下随机数的生成线程安全？： Math.random() 静态方法使用 线程1在第一次调用 random() 时产生一个生成器 generator1，使用当前时间作为种子。 线程2在第一次调用 random() 时发现已经有一个生成器 generator1，则直接使用生成器 generator1。 12345678910111213public class JavaRandom &#123; public static void main(String args[]) &#123; new MyThread().start(); new MyThread().start(); &#125;&#125;class MyThread extends Thread &#123; public void run() &#123; for (int i = 0; i &lt; 2; i++) &#123; System.out.println(Thread.currentThread().getName() + ": " + Math.random()); &#125; &#125;&#125; 结果：1234Thread-1: 0.8043581595645333 Thread-0: 0.9338269554390357 Thread-1: 0.5571569413128877 Thread-0: 0.37484586843392464 2. java.util.Random 工具类 基本算法：linear congruential pseudorandom number generator (LGC) 线性同余法伪随机数生成器缺点：可预测 使用： 12345Random random = new Random();for (int i = 0; i &lt; 5; i++) &#123; System.out.println(random.nextInt());&#125; 结果：12345-24520987-96094681-9526224273002604191489256498 Random类默认使用当前系统时钟作为种子: 12345678910111213public Random() &#123; this(seedUniquifier() ^ System.nanoTime());&#125;public Random(long seed) &#123; if (getClass() == Random.class) this.seed = new AtomicLong(initialScramble(seed)); else &#123; // subclass might have overriden setSeed this.seed = new AtomicLong(); setSeed(seed); &#125;&#125; Random类提供的方法：API nextBoolean() - 返回均匀分布的 true 或者 false nextBytes(byte[] bytes) nextDouble() - 返回 0.0 到 1.0 之间的均匀分布的 double nextFloat() - 返回 0.0 到 1.0 之间的均匀分布的 float nextGaussian() - 返回 0.0 到 1.0 之间的高斯分布（即正态分布）的 double nextInt() - 返回均匀分布的 int nextInt(int n) - 返回 0 到 n 之间的均匀分布的 int （包括 0，不包括 n） nextLong() - 返回均匀分布的 long setSeed(long seed) - 设置种子 只要种子一样，产生的随机数也一样： 因为种子确定，随机数算法也确定，因此输出是确定的！ 123456Random random1 = new Random(10000);Random random2 = new Random(10000);for (int i = 0; i &lt; 5; i++) &#123; System.out.println(random1.nextInt() + " = " + random2.nextInt());&#125; 结果：12345-498702880 = -498702880-858606152 = -8586061521942818232 = 1942818232-1044940345 = -10449403451588429001 = 1588429001 3. java.util.concurrent.ThreadLocalRandom 工具类ThreadLocalRandom 是 JDK 7 之后提供，也是继承至 java.util.Random。 123456private static final ThreadLocal&lt;ThreadLocalRandom&gt; localRandom = new ThreadLocal&lt;ThreadLocalRandom&gt;() &#123; protected ThreadLocalRandom initialValue() &#123; return new ThreadLocalRandom(); &#125;&#125;; 每一个线程有一个独立的随机数生成器，用于并发产生随机数，能够解决多个线程发生的竞争争夺。效率更高！ ThreadLocalRandom 不是直接用 new 实例化，而是第一次使用其静态方法 current() 得到 ThreadLocal 实例，然后调用 java.util.Random 类提供的方法获得各种随机数。 使用：12345678910111213public class JavaRandom &#123; public static void main(String args[]) &#123; new MyThread().start(); new MyThread().start(); &#125;&#125;class MyThread extends Thread &#123; public void run() &#123; for (int i = 0; i &lt; 2; i++) &#123; System.out.println(Thread.currentThread().getName() + ": " + ThreadLocalRandom.current().nextDouble()); &#125; &#125;&#125; 结果：1234Thread-0: 0.13267085355389086Thread-1: 0.1138484950410098 Thread-0: 0.17187774671469858 Thread-1: 0.9305225910262372 4. java.Security.SecureRandom也是继承至 java.util.Random。 Instances of java.util.Random are not cryptographically secure. Consider instead using SecureRandom to get a cryptographically secure pseudo-random number generator for use by security-sensitive applications.SecureRandom takes Random Data from your os (they can be interval between keystrokes etc - most os collect these data store them in files - /dev/random and /dev/urandom in case of linux/solaris) and uses that as the seed. 操作系统收集了一些随机事件，比如鼠标点击，键盘点击等等，SecureRandom 使用这些随机事件作为种子。 SecureRandom 提供加密的强随机数生成器 (RNG)，要求种子必须是不可预知的，产生非确定性输出。SecureRandom 也提供了与实现无关的算法，因此，调用方（应用程序代码）会请求特定的 RNG 算法并将它传回到该算法的 SecureRandom 对象中。 如果仅指定算法名称，如下所示：SecureRandom random = SecureRandom.getInstance(“SHA1PRNG”); 如果既指定了算法名称又指定了包提供程序，如下所示：SecureRandom random = SecureRandom.getInstance(“SHA1PRNG”, “SUN”); 使用： 123456SecureRandom random1 = SecureRandom.getInstance("SHA1PRNG");SecureRandom random2 = SecureRandom.getInstance("SHA1PRNG");for (int i = 0; i &lt; 5; i++) &#123; System.out.println(random1.nextInt() + " != " + random2.nextInt());&#125; 结果：12345704046703 != 2117229935 60819811 != 107252259 425075610 != -295395347 682299589 != -1637998900 -1147654329 != 1418666937 5. 随机字符串可以使用 Apache Commons-Lang 包中的 RandomStringUtils 类。Maven 依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;commons-lang&lt;/groupId&gt; &lt;artifactId&gt;commons-lang&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt; API 参考：https://commons.apache.org/proper/commons-lang/javadocs/api-2.6/org/apache/commons/lang/RandomStringUtils.html 示例： 123456789101112131415161718192021public class RandomStringDemo &#123; public static void main(String[] args) &#123; // Creates a 64 chars length random string of number. String result = RandomStringUtils.random(64, false, true); System.out.println("random = " + result); // Creates a 64 chars length of random alphabetic string. result = RandomStringUtils.randomAlphabetic(64); System.out.println("random = " + result); // Creates a 32 chars length of random ascii string. result = RandomStringUtils.randomAscii(32); System.out.println("random = " + result); // Creates a 32 chars length of string from the defined array of // characters including numeric and alphabetic characters. result = RandomStringUtils.random(32, 0, 20, true, true, "qw32rfHIJk9iQ8Ud7h0X".toCharArray()); System.out.println("random = " + result); &#125;&#125; RandomStringUtils 类的实现上也是依赖了 java.util.Random 工具类： RandomStringUtils 类的定义]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>随机数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你不得不知的Spring事务失效 8 大原因]]></title>
    <url>%2F2020%2F12%2F15%2F%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E7%9F%A5%E7%9A%84Spring%E4%BA%8B%E5%8A%A1%E5%A4%B1%E6%95%88%208%20%E5%A4%A7%E5%8E%9F%E5%9B%A0%2F</url>
    <content type="text"><![CDATA[1、数据库引擎不支持事务 这里以 MySQL 为例，其 MyISAM 引擎是不支持事务操作的，InnoDB 才是支持事务的引擎，一般要支持事务都会使用 InnoDB。根据 MySQL 的官方文档： https://dev.mysql.com/doc/refman/5.5/en/storage-engine-setting.html 从 MySQL 5.5.5 开始的默认存储引擎是：InnoDB，之前默认的都是：MyISAM，所以这点要值得注意，底层引擎不支持事务再怎么搞都是白搭。 2、没有被 Spring 管理 如下面例子所示：12345678// @Servicepublic class OrderServiceImpl implements OrderService &#123; @Transactional public void updateOrder(Order order) &#123; // update order &#125;&#125; 如果此时把 @Service 注解注释掉，这个类就不会被加载成一个 Bean，那这个类就不会被 Spring 管理了，事务自然就失效了。 3、方法不是 public 的 以下来自 Spring 官方文档： When using proxies, you should apply the @Transactional annotation only to methods with public visibility. If you do annotate protected, private or package-visible methods with the @Transactional annotation, no error is raised, but the annotated method does not exhibit the configured transactional settings. Consider the use of AspectJ (see below) if you need to annotate non-public methods. 大概意思就是 @Transactional 只能用于 public 的方法上，否则事务不会失效，如果要用在非 public 方法上，可以开启 AspectJ 代理模式。 4、类内部自身调用问题 来看两个示例：123456789101112@Servicepublic class OrderServiceImpl implements OrderService &#123; public void update(Order order) &#123; updateOrder(order); &#125; @Transactional public void updateOrder(Order order) &#123; // update order &#125;&#125; update方法上面没有加 @Transactional 注解，调用有 @Transactional 注解的 updateOrder 方法，updateOrder 方法上的事务管用吗？再来看下面这个例子：12345678910111213@Servicepublic class OrderServiceImpl implements OrderService &#123; @Transactional public void update(Order order) &#123; updateOrder(order); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void updateOrder(Order order) &#123; // update order &#125;&#125; 这次在 update 方法上加了 @Transactional，updateOrder 加了 REQUIRES_NEW 新开启一个事务，那么新开的事务管用么？这两个例子的答案是：不管用！因为它们发生了自身调用，就调该类自己的方法，而没有经过 Spring 的代理类，默认只有在外部调用事务才会生效，这也是老生常谈的经典问题了。 这个的解决方案之一就是在的类中注入自己，用注入的对象再调用另外一个方法，这个不太优雅 另外一个可行的方案如下：举个简单的例子：1234567891011@Servicepublic class ServiceA &#123; @Transactional public void doSomething()&#123; 向数据库中添加数据; 调用其他系统; &#125;&#125; 这里就用伪代码来做示例了，当我们执行了“向数据库中添加数据”，我们去数据库中查询，发现并没有我们添加的数据，但是当我们的service这个方法执行完成之后，数据库中就有这条数据了，这是由于数据库的隔离性造成的。我们将代码修改一下：12345678910111213141516171819202122@Servicepublic class ServiceA &#123; @Autowired private ServiceB serviceB; @Transactional public void doSomething()&#123; serviceB.insert(); 调用其他系统; &#125;&#125;@Servicepublic class ServiceB &#123; @Transactional(propagation = Propagation.REQUIRES_NEW) public void insert()&#123; 向数据库中添加数据; &#125;&#125; 我们将要事务分离出来的方法写在另一个service中，再次测试，发现执行完插入语句之后，数据库中就已经能查到数据了，说明事务分离了，完成了我们的需求。 当然 Spring 其实也考虑这个，在 Spring 的配置中，我们只需要添加标签：1&lt;aop:aspectj-autoproxy expose-proxy="true"/&gt; 或者：1&lt;aop:config expose-proxy="true"&gt; 并且在代码的调用中要求使用代理对象去调用即可： 1((ServiceA ) AopContext.currentProxy()).insert(); 5、数据源没有配置事务管理器 1234@Beanpublic PlatformTransactionManager transactionManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource);&#125; 如上面所示，当前数据源若没有配置事务管理器，那也是白搭！ 6、不支持事务 来看下面这个例子： 12345678910111213@Servicepublic class OrderServiceImpl implements OrderService &#123; @Transactional public void update(Order order) &#123; updateOrder(order); &#125; @Transactional(propagation = Propagation.NOT_SUPPORTED) public void updateOrder(Order order) &#123; // update order &#125;&#125; Propagation.NOT_SUPPORTED： 表示不以事务运行，当前若存在事务则挂起，详细的可以参考《事务隔离级别和传播机制》这篇文章。 都主动不支持以事务方式运行了，那事务生效也是白搭！ 7、异常被吃了 这个也是出现比较多的场景： 123456789101112// @Servicepublic class OrderServiceImpl implements OrderService &#123; @Transactional public void updateOrder(Order order) &#123; try &#123; // update order &#125; catch &#123; &#125; &#125;&#125; 把异常吃了，然后又不抛出来，事务怎么回滚吧！ 8、异常类型错误 上面的例子再抛出一个异常： 123456789101112// @Servicepublic class OrderServiceImpl implements OrderService &#123; @Transactional public void updateOrder(Order order) &#123; try &#123; // update order &#125; catch &#123; throw new Exception("更新错误"); &#125; &#125;&#125; 这样事务也是不生效的，因为默认回滚的是：RuntimeException和error123public boolean rollbackOn(Throwable ex) &#123; return (ex instanceof RuntimeException || ex instanceof Error); &#125; 如果你想触发其他异常的回滚，需要在注解上配置一下，如： 1@Transactional(rollbackFor = Exception.class) 这个配置仅限于 Throwable 异常类及其子类。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统 之 分布式事务问题]]></title>
    <url>%2F2020%2F11%2F29%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%80%8E%E4%B9%88%E6%80%9D%E8%80%83%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[分布式系统 之 分布式事务问题 1、你怎么分享分布式事务？ 分布式事务问题是分布式系统绕不开的技术话题。 “谈谈你对分布式事务的理解”、“分享下你团队在分布式事务上的解决方案”、“你用过哪几种分布式事务的中间件”？在技术交流/面试中很容易讨论到这些个话题，得到的反馈大概率是这样的： “额~~ ~~ ~~ ~~”，一时语噻 《《《 平时没有梳理和认知分布式事物的问题，一时不知如何组织语言。 “我们没有使用分布式事务”《《《 分布式事务裸奔状态。 “我知道有CAP和BASE理论，分别是XXX意思” 《《《 “学院派”选手，不够接地气。 “我们没用分布式事务，但有做补偿方案，XXX” 《《《 有意识和思考，可以。 “我们在个别特殊业务上，用了XXX中间件方案” 《《《 有数据、有实践心得，可以。 etc…… 的确，分布式事务问题比中间件技术问题难回答的多，因为： 1、它是一个解决方案。而不仅仅是某个功能的技术实现解答。 2、分布式事务是一项“有损解决方案”，是一项取舍决策，背后是业务适用性。 3、解决方案要基于业务场景，以及业务场景分析。不存在一招鲜吃遍天的最佳方案。 3、分布式事务是个综合的技术问题，涉及：业务代码、RPC、幂等性、DB、并发处理、局部高可用、网络分区、一致性视图等问题。 据笔者交流反馈的经验，在多数团队中并未落地“像样”的分布式方案。分布式事务在线上系统的应用比例是很小的。相比分布式事务的学习复杂度和实际应用概率，真有点“面试造火箭，实际拧螺丝”的感觉。 但，不论线上应用比例怎样。作为对技术深度的好奇和掌握（尤其是一堆技术的协同的原理掌握），我们仍要扎实的掌握分布式事务。做到知一返三、游刃有余。 2、分布式事务的本质 分布式事务问题 如上图： 分布式事务的问题/需求是随着系统分布式化后必然产生的。 分布式事务的目的或本质是追求分布式的多个DB数据的一致性。 和本地数据库事务的本质原理是一样的。只不过是放大到一套技术栈中去实现，更多考虑因素和复杂度。 （以Mysql为例）本地数据库事务原理：undo log（原子性） + redo log（持久性） + 数据库锁（原子性&amp;隔离性） + MVCC（隔离性） 分布式事务原理：全局事务协调器（原子性） + 全局锁（隔离性） + DB本地事务（原子性、持久性） 注，“一致性” 靠 “原子性 + 持久性 + 隔离性” 三者共同完成 分布式多个DB数据变更的一致性不是瞬间一致，而是会经历一个过程。 需要考虑期间DB数据可见性和隔离性问题。 问题： 1、分布式系统中，日常研发线上发版，需要考虑分布式事务问题吗？如果要考虑，怎么应对？ 2、分布式事务相关的技术问题：RPC、幂等性、DB、并发处理、局部高可用、网络分区、一致性视图等，胸有成竹吗？ 3、CAP原则和BASE理论 下文并不会基于这两理论分解，毕竟是理论，不能解决实际的问题 但理论知识还是需要了解一些的。故，快速浏览下。 3.1、CAP原则CAP原则： 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）中的两项。 一致性（Consistency）：一致性指“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。 可用性（Availability）：可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。 分区容错性（Partition tolerance）：分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 CAP的取舍策略： 策略 解释 CA 单点集群，满足一致性，可用性的系统，通常可扩展性较差。例如传统的单机数据库。特点：故障时完全不可用。 【常选】AP 满足可用性，分区容错的系统，对一致性要求低一些，是很多分布式系统设计时的选择。 例如：Redis，HBase，Eureka。 例如：各云厂商的SLA几个9，也是牺牲了强一致性。 CP 满足一致性，分区容错的系统，通常性能不是特别高 例如：Zookeeper（通过ZAB协议达到强一致性） 3.2、BASE理论BASE理论是对CAP理论的延伸，对AP的细化。 核心思想是“即使无法做到强一致性，但应可以采用适合的方式达到最终一致性”。 BASE是指：基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。 基本可用（Basically Available） 基本可用是指分布式系统在出现故障时，为保证核心可用，允许损失部分可用性。 例如：电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。 软状态（ Soft State） 软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。 例如：分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。 最终一致性（ Eventual Consistency） 最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。 最终一致性是弱一致性的一种特殊情况。 3.3、为什么分布式系统倾向BASE理论的架构实际性问题： 工程师可以做到逻辑严密的代码，但无法确保硬件长期100%可用。 在大型分布式系统中，通信异常、网络分区、节点故障、磁盘损坏、机房掉电等等硬件问题随时都可能发生。 在商业中，越是大型的公司越是需要在线服务能力强的大型分布式系统，在线可用性和响应能力是大型公司的生命支柱（很多线上一次大故障毁掉一个公司的案例）【基本已排除CA和CP】。 且，数据最终一致的特点留给架构很多发挥的余地。即使是关键异常，也可以通过补偿的方式或人工的方式处理。 4、技术方案汇总4.1、按方案本质分类 阿里Seata：http://seata.io/zh-cn/ Hmily：https://github.com/dromara/hmily 4.2、怎么选 仅提供数据参考 一、一般业务都倾向选最终一致性 绝大部分使用“自研补偿/MQ方案 + 人工介入”。 选型取向： 方案最“轻”，可掌控性好。 方案简单易懂，团队易接受、易维护。 性能损失最少。 笔者也赞同一般团队选型此方式。毕竟分布式事务问题是小概率事件，留有补救余地就行，性能的损失可是实打实的反应在线上每一个请求上。 二、阿里Seata AT模式，平均性能会降低35%以上 笔者团队的业务实测 大家可以根据Seata AT模式下额外做的事情来感受 三、RocketMQ事务消息 听起来挺好挺简单的方案，但它比较挑业务场景，同步性强的处理链路不适合。 【重要】要求下游MQ消费方一定能成功消费消息。否则转人工介入处理。 【重要】千万记得实现幂等性。 RocketMQ 3.0.8版本前，或RocketMQ 4.3.0后 支持事务消息，中间版本事务消息被干掉过。 5、技术方案介绍5.1、【原理】2PC （理论基石）两阶段提交（Two-phase Commit，2PC） 5.1.1、运行原理 2PC通过引入协调者（Coordinator）来协调分布式事务参与者的行为，并最终决定这些参与者是否要真正执行事务。 2PC 把事务的执行分为两个阶段： 第一阶段 prepare 阶段：这个阶段实际上就是参与者对事务的投票阶段，协调者向所有参与者确认是否可以共同提交？ 第二阶段 commit阶段：只有第一阶段所有参与者都回答yes，协调者才会向所有参与者发起commit指令共同提交事务。否则向所有参与者发送abort指令共同中止事务。用以保证事务达到一致性。 【特别强调】2PC是方案原理，不是落地型方案。2PC几乎是所有分布式事务方案的基础，各分布式事务方案几乎都由此改进而来。 一阶段：准备阶段 一阶段：准备阶段 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。 二阶段：提交阶段 二阶段：提交阶段 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。 【注意】需要注意的是，在准备阶段，参与者在DB层只执行了事务，未提交事务。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。 5.1.2、方案背后的隐性要求 1、需要实现一个全局协调器。引发考虑全局协调器自身的可用性问题。 2、应用需配合协调者要求，实现多个接口。 3、需要将DB层面的事务commit分离（需要DB支持）。拖长的一致性过程，对并发情况采取的应对策略（一般往往是同步阻塞）。 4、假设阶段二的commit/rollback肯定执行成功，故二阶段的实现不能复杂。且，一旦出错就人工介入。 5.1.3、存在的问题 1、同步阻塞：所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，阻塞级别（应用级、表级、数据行级）视实现方案。 2、单点问题：协调者发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待状态，无法完成其它操作。 3、数据不一致：在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。抑或协调者发送的commit消息到达参会与者的速度不一样，抑或参与者处理commit消息的调度及时性不一样，都会出现全局数据不一致的一个时间窗口。 4、太过保守： 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。 5.2、【原理】TCC （补偿型）TCC 本质上也是一个2PC型原理，但其属于“补偿型” “柔性事务”方案。是最常用的分布式事务的思路。 理解TCC，重要的是去理解“补偿型”方案的思路。基于“补偿型”思路在实际业务场景中灵活应变。 故，要往补偿型方案上去理解，勿死记硬背！ 【敲黑板】TCC特点： TCC是属于BASE理论的柔性事务。是最终一致性的做法。 （相较于资源层DB）TCC工作于业务逻辑层，属业务逻辑层的2PC。实现：Try、Confirm、Cancel三个方法（Cancel是取消Try）。 TCC每一个接口在返回时都是直接提交本地事务的。故，TCC是牺牲了一定的隔离性和全局一致性。 TCC也有事务管理器（Coordinator 事务协调者）。事务管理器要记录分布式事务活动日志，用于事务管理器重启后的恢复。 标准的TCC，数据设计上需要支持中间态（配合try + confirm）。变种的TCC，也可以一步到位。 TCC的状态推进逻辑： 1、Try阶段：如果有1个Try失败。则发起全局Cancel。 2、Confirm阶段：假设必须成功。若有个别应用Confirm失败，则由事务管理器进行重试。若重试无效，则人工介入。 3、Cancel阶段：也是假设必须成功。Cancel失败的基本都转人工。 TCC实现注意点： 1、实现幂等：因为网络调用无法保证请求一定能到达，所以都会有重调机制，因此对于 Try、Confirm、Cancel 三个方法都需要幂等实现，避免重复执行产生错误。 2、空回滚问题：指由于网络问题，Try 方法没收到，超时了。此时事务管理器就会发出 Cancel 命令，那么需要支持 Cancel 在未执行 Try 的情况下能正常的 Cancel。 3、考虑单应用多实例架构：在单应用多实例的架构下，TCC的协调者需要保证一个事务的Try、Confirm、Cancel操作在同一个实例上。 应对方案一、单应用多实例间，针对业务数据做分布式锁。 应对方案二、放任其并发。前提是单应用级多实例架构自身能保证业务的负载均衡后的并发原子性，例如：请求负载均衡到多台机器实例进行库存操作，常见方案有：分布式锁、DB乐观锁等。因为TCC的Try会检查并锁定资源，如果遇到冲突，那么检测到冲突，Try失败的分布式事务者进行Cancel回滚。 4、防悬挂：（尤其是异步方式的TCC）是指 Try 方法由于网络阻塞，超时触发了事务管理器发出了 Cancel 命令， 但是执行了 Cancel 命令之后 Try 请求到了。 TCC应用的难度不在于实现三个方法，在于结合具体TCC工具选型和技术架构下的逻辑严密性，常思考几个问题： 这个请求失败了怎么办？ 方案执行TimeOut了怎么办？ 任何时候，网络抖动了怎么办？ 网络异常分区了，会造成什么问题？ TCC的事务管理器异常了怎么办？ 执行TCC的应用程序异常了怎么办？ 如何优雅的事务平滑的更新线上版本？ ……等等 国内开源的ByteTCC、hmily、tcc-transaction TCC的缺点： 在业务层面，完全手写回滚逻辑或者是补偿逻辑，实在太恶心了。且，这块业务代码很难维护，很容易纰漏。 因地制宜，这些也是TCC思路： 一、没有Try的TCC 例如，购买联程机票，换乘的又是不同的航空公司。比如从 A 飞到 B，再从 B 飞到 C，只有 A - B 和 B - C 都买到票了才有意义。 但有可能受限于各航空公司未必都实现TCC的接口，故为了方案的通用性，会做方案降级应对。这时候的选择就不 Try 了，直接调用航空公司的买票操作，当两个航空公司都买成功了那就直接成功了，如果某个公司买失败了，那就需要调用取消订票接口。 也就是在第一阶段直接就执行完整个业务操作了，所以要重点关注回滚操作，如果回滚失败得有提醒，需要人工介入等。 类SAGA的方案哦 二、异步方式的TCC TCC 异步其实也是一种折衷。 比如某些服务很难改造，但又不会影响主业务决策，也就是它不那么需要即时执行。这时候可以引入可靠消息服务，通过消息服务来替代个别服务来进行 Try、Confirm、Cancel 。 Try 的时候只是写入消息，消息还不能被消费，Confirm 就是真正发消息的操作，Cancel 就是取消消息的发送。 是不是有点耳熟？对！就是RocketMQ。 事务消息的方案哦 5.3、【原理】 XA （取决于数据库）XA规范 是 X/Open 组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准。 XA 规范 描述了全局的事务管理器与局部的资源管理器之间的接口。 XA规范 的目的是允许的多个资源（如数据库，应用服务器，消息队列等）在同一事务中访问，这样可以使 ACID 属性跨越应用程序而保持有效。 XA中大致分为两部分：事务管理器和本地资源管理器。 本地资源管理器：往往由数据库实现，比如Oracle、DB2这些商业数据库都实现了XA接口。 事务管理器：作为全局的调度者，负责各个本地资源的提交和回滚。 XA 规范 使用两阶段提交（2PC，Two-Phase Commit）来保证所有资源同时提交或回滚任何特定的事务 XA实现分布式事务的原理如下： 看，背后还是2PC的原理。 总的来说，XA协议比较简单，而且一旦商业数据库实现了XA协议，使用分布式事务的成本也比较低。 但是，XA也有致命的缺点，那就是性能不理想，特别是在交易下单链路，并发量高，XA无法满足高并发场景。 XA目前在商业数据库支持的比较理想，在mysql数据库中支持的不太理想，mysql的XA实现，没有记录prepare阶段日志，主备切换回导致主库与备库数据不一致。 至于实战经验/代码demo，笔者也没使用过。此章节略带“键盘侠”的感觉。 带XA能力的框架：Seata。 5.4、【框架】Seata （多种模式可选）http://seata.io/zh-cn/index.html 5.4.1、XA模式 （阻塞大，性能低）前提： 支持XA 事务的数据库。（Mysql就不行罗） Java 应用，通过 JDBC 访问数据库。 整体机制： 在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种 事务模式。 一、执行阶段： 可回滚：业务 SQL 操作放在 XA 分支中进行，由数据库对 XA 协议的支持来保证 可回滚 持久化：XA 分支完成后，执行 XA prepare，同样，由数据库对 XA 协议的支持来保证 持久化（即，之后任何意外都不会造成无法回滚的情况） 二、完成阶段： 分支提交：执行 XA 分支的 commit 分支回滚：执行 XA 分支的 rollback 工作机制： 整体运行机制 XA 模式 运行在 Seata 定义的事务框架内： 执行阶段（E xecute）：XA start/XA end/XA prepare + SQL + 注册分支 完成阶段（F inish）：XA commit/XA rollback 数据源代理 XA 模式需要 XA Connection。 获取 XA Connection 两种方式： 方式一：要求开发者配置 XADataSource 方式二：根据开发者的普通 DataSource 来创建 第一种方式，给开发者增加了认知负担，需要为 XA 模式专门去学习和使用 XA 数据源，与 透明化 XA 编程模型的设计目标相违背。 第二种方式，对开发者比较友好，和 AT 模式使用一样，开发者完全不必关心 XA 层面的任何问题，保持本地编程模型即可。 虽然第二种方式对使用者更友好，但仍优先推荐第一种自实现的方式： 为什么？ 关于第二种方式，其实是Seata来开发XA Connection，这种方法是在做数据库驱动程序要做的事情。不同的厂商、不同版本的数据库驱动实现机制是厂商私有的，Seata只保证在充分测试过的驱动程序上是正确的（无法针对使用者各色各样的驱动版本给出通用版本），开发者使用的驱动程序版本差异很可能造成机制的失效。这点在 Oracle 上体现非常明显。参见 Druid issue：https://github.com/alibaba/druid/issues/3707 。 分支注册 XA start 需要 Xid 参数。 这个 Xid 需要和 Seata 全局事务的 XID 和 BranchId 关联起来，以便由 TC 驱动 XA 分支的提交或回滚。 目前 Seata 的 BranchId 是在分支注册过程，由 TC 统一生成的，所以 XA 模式分支注册的时机需要在 XA start 之前。 XA 模式的使用 可以参考 Seata 官网的样例：https://github.com/seata/seata-samples/tree/master/seata-xa 样例场景是 Seata 经典的，涉及库存、订单、账户 3 个微服务的商品订购业务。 5.4.2、AT模式 （折中的优选）复习下Seata XA模式下的不足： 需要数据库支持XA协议。Mysql没戏。 阻塞大，性能低。 然后，Seata AT模式就是Seata XA模式的演化版本，优化了Seata XA模式下的2个不足。更灵活、性能有所提升（不绝对，建议实测比较）。 前提： 基于支持本地 ACID 事务的关系型数据库。 Java 应用，通过 JDBC 访问数据库。 整体改进原理： 1、【自动代理，插入逻辑】【低入侵】自动代理应用层的数据源，拦截并插入Seata的操作和逻辑。 2、【应用层XA Prepare】【灵活】在应用层实现 XA Prepare部分，大大提升适用面和灵活性。实际实现上，通过对数据源做代理，以此拦截应用的事务SQL，进而反向解析出undo sql log（供于rollback）。 3、【行级-全局锁】【隔离性&amp;性能】在全局TC上实现行级全局锁。全局事务在执行期间，需要先拿到全局锁，才能处理临界区逻辑。以此达到全局的读写隔离。 代码层面参照Seata-Sample，最大特点是在事务入口打上@GlobalTransactional的代理注解，让Seata能干预SQL的执行。 基本概念： TC（Transaction Coordinator） - 事务协调者：维护全局事务和分支事务的状态，驱动全局事务提交或回滚。 TM（Transaction Manager） - 事务管理器：定义全局事务的范围 RM（Resource Manager） - 资源管理器 ：管理分支事务处理的资源，与TC通信注册/报告分支事务状态，并驱动分支事务的提交或回滚。 两阶段提交： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段：提交异步化，非常快速地完成 或 回滚通过一阶段的回滚日志进行反向补偿。 写隔离： 一阶段本地事务提交前，需要确保先拿到 全局锁（数据行级） 。而全局锁的实现，在TC端。带来的优点：全局解锁就在一瞬间。 拿不到 全局锁 ，不能提交本地事务。 拿 全局锁 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。 示例： 两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000。 tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的 全局锁 ，本地提交释放本地锁。 tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。本地事务提交前，尝试拿该记录的 全局锁 ，tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待 全局锁 。 tx1 二阶段全局提交，释放 全局锁 。tx2 拿到 全局锁 提交本地事务。 如果回滚： 如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支的回滚。 此时，如果 tx2 仍在等待该数据的 全局锁，同时持有本地锁，则 tx1 的分支回滚会失败。分支的回滚会一直重试，直到 tx2 的 全局锁 等锁超时，放弃 全局锁 并回滚本地事务释放本地锁，tx1 的分支回滚最终成功。 因为整个过程 全局锁 在 tx1 结束前一直是被 tx1 持有的，所以不会发生 脏写 的问题。 读隔离： 在数据库本地事务隔离级别 读已提交（Read Committed） 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 读未提交（Read Uncommitted） 。 如果应用在特定场景下，必需要求全局的 读已提交 ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。 SELECT FOR UPDATE 语句的执行会申请 全局锁（并发阻塞的代价点） ，如果 全局锁 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 全局锁 拿到，即读取的相关数据是 已提交 的，才返回。 出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。 回滚日志表： AT模式的特点是通过代理数据源，从而能拦截SQL，并生成undo sql。这个特点在实际实战中要引起注意，要实测真实业务sql的undo sql生成正确性（担心Seata AT模式对于复杂更新sql 的解析能力）。 注，UNDO_LOG Table 一定要创建哦。 MySQL 为例： Field Type branch_id bigint PK xid varchar(100) context varchar(128) rollback_info longblob log_status tinyint log_created datetime log_modified datetime 12345678910111213-- 注意此处0.7.0+ 增加字段 contextCREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; AT模式的缺点： 1、性能损耗： 还是业务上明显感知的。 一条Update SQL，需要获取全局事务XID（与TC通信）、before image（解析SQL，查询一次数据库）、after image（查询一次数据库）、insert undo log（写一次数据库）、before commit（与TC通信，判断锁冲突/获取锁），这些操作都需要一次次的远程通信RPC，而且是同步的。 另外，undo log写入时blob字段的插入信息也是不高的。 每条写SQL都会增加这么多开销，粗略估计会增加5倍的响应时间。 笔者平台线上业务实测，Seata AT模式后，所及业务功能点整体性能下降35%。 2、特别注意应对：补偿型方式的通病： Seata已经支持的AT、TCC、SAGA都是补偿型的。 补偿型事务处理机制构建在事务资源之上，事务资源本身对分布式事务是无感知的。无法做到真正的全局一致性。 比如，一条库存记录处在补偿型事务处理过程中由100扣减为50。此时，仓库管理员链接数据库查询统计库存，查到了50。然后因事务回滚，库存由50补偿变回100。显然，仓库管理员查询统计到的50就是脏数据。 AT的锁能解决部分这类问题，故，实际应用时一定要仔细分析并发读写场景特点，做最小代价的应对方案。 5.4.3、TCC模式 （提供框架）关于原理，《5.2、TCC》章节后，此处不再详述。 但，在实际应用中务必记得考虑TCC模式下各种情况的应对。见《5.2、TCC》章节。 Seata TCC模式的执行流程原理图 根据两阶段行为模式的不同，将分支事务划分为 Automatic (Branch) Transaction Mode 和 TCC (Branch) Transaction Mode. Automatic模式 基于支持本地 ACID 事务的关系型数据库（即Seata AT模式）： 一阶段 prepare 行为：在本地事务中，一并提交业务数据更新和相应回滚日志记录。 二阶段 commit 行为：马上成功结束，自动异步批量清理回滚日志。 二阶段 rollback 行为：通过回滚日志，自动生成补偿操作，完成数据回滚。 TCC 模式，不依赖于底层数据资源的事务支持： 一阶段 prepare 行为：调用 自定义 的 prepare 逻辑。 二阶段 commit 行为：调用 自定义 的 commit 逻辑。 二阶段 rollback 行为：调用 自定义 的 rollback 逻辑。 所谓 TCC 模式，是指支持把 自定义 的分支事务纳入到全局事务的管理中。 5.4.4、Saga模式 （多系统集成）概述： Saga模式是Seata提供的长事务解决方案。 事务长不长不知道，但Saga有它存在的意义和只有它能解决的场景。 在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。 适用场景： 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口 业务流程长、业务流程多 优势： 一阶段提交本地事务，无锁，高性能 事件驱动架构，参与者可异步执行，高吞吐 补偿服务易于实现 缺点： 不保证隔离性 需要注意的是： 虽然没体现，但Seata Saga模式的背后，仍旧是对Seata框架和Saga事务管理器的依赖。 更多了解详见： Seata 官网：http://seata.io/zh-cn/docs/user/saga.html Seata 样例：https://github.com/seata/seata-samples/ 缺乏隔离性的应对： 由于 Saga 事务不保证隔离性, 在极端情况下可能由于脏写无法完成回滚操作。 比如举一个极端的例子, 分布式事务内先给用户A充值, 然后给用户B扣减余额, 如果在给A用户充值成功, 在事务提交以前, A用户把余额消费掉了, 如果事务发生回滚, 这时则没有办法进行补偿了。这就是缺乏隔离性造成的典型的问题, 实践中一般的应对方法是： 业务流程设计时遵循“宁可长款, 不可短款”的原则, 长款意思是客户少了钱机构多了钱, 以机构信誉可以给客户退款, 反之则是短款, 少的钱可能追不回来了。所以在业务流程设计上一定是先扣款。 有些业务场景可以允许让业务最终成功, 在回滚不了的情况下可以继续重试完成后面的流程, 所以状态机引擎除了提供“回滚”能力还需要提供“向前”恢复上下文继续执行的能力, 让业务最终执行成功, 达到最终一致性的目的。 5.5、【方案】事务消息 （补偿型）属TCC的方案变种。 适用于场景有限： 限于可异步处理的分布式事务场景（即分支事务不影响主业务的决策）。 市面上支持事务消息的仅：RocketMQ。见《4.2、怎么选》。 RocketMQ 中间件思路大致为： 第一阶段 Prepared消息，会拿到消息的地址 第二阶段 执行本地事务 第三阶段 通过第一阶段拿到的地址去访问消息，并修改状态（投递/撤销）。 也就是说在业务方法内要向消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了RocketMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 优点： 实现了最终一致性，不需要依赖本地数据库事务。一部分可用性保障转移给/借力MQ的能力。 缺点： 实现难度大，主流MQ不支持。 5.6、【方案】本地消息表 （最大努力通知）本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。 优点： 一种非常经典/简单的实现，避免了分布式事务，实现了最终一致性。 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，（重点）会有很多杂活需要处理。同样要考虑TCC方案下的多种技术因素，见《5.2、TCC》。在运行环境中，怀疑一切才能一切放心。 3、再谈方案选型看完上文后，大家应该有几个感觉： 日常在聊的分布式事务的一些概念或名字中，部分是原理，部分是方案，彼此之间还存在演进关系。目前应能清晰的区分。 在实现方案上，选择的余地很少。实战场景下，大多仍是根据业务场景自研一套代码为主，但自研方案的背后仍然是TCC/XA/Saga的原理。 选择开源框架的很大目的是借力开源方案的事务管理器和其框架，本质原理都是一样的。 懂分布式事务原理的基础上，更要掌握各方案背后要应对的问题 网络不可靠的问题 数据全局隔离性的问题 幂等的问题 空回滚的问题 事务管理器、应用节点不可靠的问题 监控的问题 ……等等 关于分布式事务实现方案的选型/设计，笔者的心得和倾向： 1、【价值取向】分布式事务方案在“性能”和“数据一致性”两方面是相悖的，在价值取向上，我更倾向于保障“性能”。 原因：从影响面和可恢复性角度，分布式事务问题是小概率事件，留有补救余地就行，性能的损失是实打实的反应在线上每一个请求上。 2、【编码风格】落实“宁可长款, 不可短款”的原则。优先做扣除行为。 3、【做好监控】既然允许线上分布式事务问题的发生，那么就要有兜底应对的手段。笔者会要求团队在分布式事务的流程中认真打日志。并将此类日志作为线上业务监控范围，并与公司内部邮件系统、钉钉打通。做到一个有问题，秒级感知。 4、【双重兜底】开发统计对账服务，对线上分布式事务数据做周期性巡检。对线上数据不一致情况做通知：工单、钉钉、邮件。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>事务</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文就明白Java并发编程]]></title>
    <url>%2F2020%2F11%2F15%2F%E4%B8%80%E6%96%87%E5%B0%B1%E6%98%8E%E7%99%BD%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[《一文就明白Java并发编程》一文系列 之 并发编程。 行文3万余字，包含了多线程方方面面的知识点，相信对你会有所帮助！ 黄老师 [TOC] 1、进程&amp;线程虽然大家肯定知道进程、线程的概念，但在介绍整篇文章前还是需要再陈述下，保证行文信息量的连贯性。 Linux系统中线程的位置 一些基础知识： Linux操作系统分内核态和用户态。 内核态是操作系统自己管理和控制的，是“基石”。内核态也可以开发，利用linux内核模块化技术进行模块形式加载。 用户态是开放使用的，以进程为开放使用单位。进程是在用户态资源分配的单位（以进程为单位分配内存空间），进程内的线程是用户态执行单位（进程有默认线程，以线程去执行具体的代码，作为执行单位的特点是每个线程一个调用栈）。 其实，内核态是清楚并管理用户态的进程和线程的。用户态的每个进程在内核有对应的PCB作为管理对象。用户态的每个线程在内核有对应的TCB作为管理和调度对象。 在计算机中，CPU是稀缺资源，N多待调度的线程通过操作系统的Scheduler调度器去分配CPU时间片，让各个线程能“雨露均沾”。 用户态线程的调度功能有2种实现方式： 第一种：交由操作系统去管理调度，特点：用户态线程和内核线程是一一映射的（如图）。也是JDK 1.2之后版本的实现方式。 第二种：JDK1.2之前，由开发者（对于JDK来说，是JVM自己）在进程空间实现一套进程内线程的调度算法。这种实现方式对开发者来说复杂，又难以完全控制时间片，可能部分线程会饿死，因为是否分配CPU时间片的真正权力握在操作系统内核上. 2、JUC并发包2.1、JUC包介绍JUC是 java.util.concurrent的简称，是JDK包下原生的lib。是Java 5.0 提供的并发编程包，包含了并发编程中很常用的实用工具类。 下文以JDK8为例 其实，JUC包中的内容经过归类后并不繁多、复杂。 JUC提供的能力分类： 1、Atomic原子类 2、Lock相关 几类基础锁机制 3、并发安全的Collection类、Map类 4、多种队列工具类 5、线程池机制 6、多线程协同工具类 2.2、Atomic原子类总所周知，Atomic原子类能保证在一个对象上多个操作步骤的原子性。这是Atomic机制在多线程并发环境中存在的意义。 2.2.1、Atomic原子类的细分 基本类型的原子性操作：AtomicBoolean、AtomicInteger、AtomicLong 这些类能保证在并发环境中对基础整型数字的get、set、incr、decr、add、minus等方面操作的原子性。 JDK8开始有LongAdder类，功能与AtomicLong类似。在高并发，写多读少的场景性能比AtomicLong好。 数组类型的原子性操作：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 数组级别的原子操作。提供的方法方面，只是对数组上的指定单个元素做原子操作。不具备范围型批量操作方法。 引用类型的原子性操作：AtomicReference “AtomicReference” 是AtomicReference的Class声明，即AtomicReference是存放Java对象引用的，任何对象都可以。而AtomicReference能保证多线程环境下对这个对象引用变更的一致性。 代码案例见下文 带版本标识的引用类型的原子性操作：AtomicStampedReference、AtomicMarkableReference AtomicReference无法避免ABA问题。 若业务场景对AtomicReference指向的对象的变化过程不关心，只关心当下时刻的值是多少，那么AtomicReference还是适合的。若业务场景关心对象值的变化过程，那么AtomicReference就不适合了。 AtomicStampedReference 在AtomicReference基础上，增加了一个final int stamp字段，大家可以理解为版本号+乐观锁的概念。每当对AtomicStampedReference的对象做更新时，需同时比对对象应用和stamp值，然后同时更新对象应用和stamp值 123456789101112public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) &#123; Pair&lt;V&gt; current = pair; return expectedReference == current.reference &amp;&amp; expectedStamp == current.stamp &amp;&amp; ((newReference == current.reference &amp;&amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp)));&#125; AtomicMarkableReference与AtomicStampReference的区别：相较于，AtomicStampReference新增的int stamp字段，AtomicMarkableReference增加的是boolean类型的字段。其他操作上都一样，但不能解决ABA问题。 反射方式原子操作：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater 以反射方式，对一个对象内的整型数字字段进行原子操作 要求： 此字段必须是volatile的，保证变量变更线程间立即可见 此字段必须是变量，不能是final 只能是实例变量，不能是类变量，也就是说不能加static关键字 此字段只能是int、long基础类型（不能是包装类） 段的描述类型（修饰符public/protected/default/private）是与调用者与操作对象字段的关系一致。也就是说调用者能够直接操作对象字段，那么就可以反射进行原子操作 代码案例见下文 代码案例说明 - AtomicReference 以Person POJO类为背景，Person类里含有2个字段：name、age。 构造Person对象的初始值为 name=Tom, age = 18。 计划 在 线程1 中将 name 修改为 Tom1，age + 1。 在 线程2 中将 name 修改为 Tom2，age + 2。 普通引用版本 《《《 会引发更新不一致性 123456789101112131415161718192021222324252627282930313233343536373839// 普通引用private static Person person; 《《《 全局Person对象public static void main(String[] args) throws InterruptedException &#123; person = new Person("Tom", 18); System.out.println("Person is " + person.toString()); Thread t1 = new Thread(new Task1()); Thread t2 = new Thread(new Task2()); t1.start(); 《《《 并发修改：name、age t2.start(); 《《《 并发修改：name、age t1.join(); t2.join(); System.out.println("Now Person is " + person.toString());&#125;static class Task1 implements Runnable &#123; public void run() &#123; person.setAge(person.getAge() + 1); 《《《 并发场景下，对象多个字段的赋值非原子性 person.setName("Tom1"); 《《《 System.out.println("Thread1 Values " + person.toString()); &#125;&#125;static class Task2 implements Runnable &#123; public void run() &#123; person.setAge(person.getAge() + 2); 《《《 并发场景下，对象多个字段的赋值非原子性 person.setName("Tom2"); 《《《 System.out.println("Thread2 Values " + person.toString()); &#125;&#125; 可能的输出： 1234Person is [name: Tom, age: 18] Thread2 Values [name: Tom1, age: 21] Thread1 Values [name: Tom1, age: 21]Now Person is [name: Tom1, age: 21] 原子引用版本 12345678910111213141516171819202122232425262728293031323334353637383940// 普通引用private static Person person;// 原子性引用private static AtomicReference&lt;Person&gt; aRperson;public static void main(String[] args) throws InterruptedException &#123; person = new Person("Tom", 18); aRperson = new AtomicReference&lt;Person&gt;(person); 《《《 对象的原子引用 System.out.println("Atomic Person is " + aRperson.get().toString()); Thread t1 = new Thread(new Task1()); Thread t2 = new Thread(new Task2()); t1.start(); 《《《 并发修改：name、age t2.start(); 《《《 并发修改：name、age t1.join(); t2.join(); System.out.println("Now Atomic Person is " + aRperson.get().toString());&#125;static class Task1 implements Runnable &#123; public void run() &#123; aRperson.getAndSet(new Person("Tom1", aRperson.get().getAge() + 1)); 《《《 对象多字段操作原子性 System.out.println("Thread1 Atomic References " + aRperson.get().toString()); &#125;&#125;static class Task2 implements Runnable &#123; public void run() &#123; aRperson.getAndSet(new Person("Tom2", aRperson.get().getAge() + 2)); 《《《 对象多字段操作原子性 System.out.println("Thread2 Atomic References " + aRperson.get().toString()); &#125;&#125; 输出之一： 1234Atomic Person is [name: Tom, age: 18] Thread1 Atomic References [name: Tom1, age: 19] Thread2 Atomic References [name: Tom2, age: 21]Now Atomic Person is [name: Tom2, age: 21] 代码案例说明 - AtomicIntegerFieldUpdater 123456789101112131415161718192021222324252627282930package automic;import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;public class AtomicIntegerFieldUpdaterTest &#123; private static Class&lt;Person&gt; cls; /** * AtomicIntegerFieldUpdater class说明 * 基于反射的实用工具，可以对指定类的指定 volatile int 字段进行原子更新。此类用于原子数据结构， * 该结构中同一节点的几个字段都独立受原子更新控制。 * 注意，此类中 compareAndSet 方法的保证弱于其他原子类中该方法的保证。 * 因为此类不能确保所有使用的字段都适合于原子访问目的，所以对于相同更新器上的 compareAndSet 和 set 的其他调用， * 它仅可以保证原子性和可变语义。 * @param args */ public static void main(String[] args) &#123; // 新建AtomicLongFieldUpdater对象，传递参数是“class对象”和“long类型在类中对应的名称” AtomicIntegerFieldUpdater&lt;Person&gt; personFieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Person.class, "id"); Person person = new Person(12345); personFieldUpdater.compareAndSet(person, 12345, 1000); System.out.println("id=" + person.getId()); &#125;&#125;class Person &#123; volatile int id; public Person(int id) &#123; this.id = id; &#125; ......&#125; 2.2.2、Atomic原子类的实现原理Atomic的核心操作是CAS（Compare And Set）。该操作在操作系统层面对应C语言汇编的CMPXCHG指令，该指令通过三个操作数（变量V，预期旧值O，目标新值N），能原子的完成“变量V当前值与预期旧值E的等值判断，并完成新值N的赋值”。 注，常规的Atomic存在ABA的问题。 所有Atomic类内部都会调用Unsafe类完成CAS的操作 12345public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); Unsafe内部就是C语言实现与操作系统的交互了，最终会涉及到CPU级的操作。 CMPXCHG指令介绍 Unsafe的CompareAndSwap方法最终在 hotspot 源码实现中都会调用统一的 cmpxchg 函数。 cmpxchg 函数源码： 源码地址：hotspot/src/share/vm/runtime/Atomic.cpp 1234567891011121314151617181920212223242526jbyte Atomic::cmpxchg(jbyte exchange_value, volatile jbyte*dest, jbyte compare_value) &#123; assert (sizeof(jbyte) == 1,"assumption."); uintptr_t dest_addr = (uintptr_t) dest; uintptr_t offset = dest_addr % sizeof(jint); volatile jint*dest_int = ( volatile jint*)(dest_addr - offset); // 对象当前值 jint cur = *dest_int; // 当前值cur的地址 jbyte * cur_as_bytes = (jbyte *) ( &amp; cur); // new_val地址 jint new_val = cur; jbyte * new_val_as_bytes = (jbyte *) ( &amp; new_val); // new_val存exchange_value，后面修改则直接从new_val中取值 new_val_as_bytes[offset] = exchange_value; // 比较当前值与期望值，如果相同则更新，不同则直接返回 while (cur_as_bytes[offset] == compare_value) &#123; // 调用汇编指令cmpxchg执行CAS操作，期望值为cur，更新值为new_val jint res = cmpxchg(new_val, dest_int, cur); if (res == cur) break; cur = res; new_val = cur; new_val_as_bytes[offset] = exchange_value; &#125; // 返回当前值 return cur_as_bytes[offset];&#125; 多CPU如何实现原子操作 在计算机硬件层面，CPU 处理器速度远远大于主内存，为了解决速度差异，在两者之间架设了CPU多级缓存，如 L1、L2、L3 级别的缓存，这些缓存离CPU越近就越快，将频繁操作的数据缓存到这里，加快访问速度。 现在都是多核 CPU 处理器，每个 CPU 处理器内维护各自关于内存数据的缓存，当多线程并发读写时，就会出现CPU缓存数据不一致的情况。 对于原子操作，CPU处理器提供2种方式： 总线锁定 当一个处理器要操作共享变量时，在 BUS 总线上发出一个 Lock 信号，其他处理就无法操作这个共享变量了。 缺点很明显，总线锁定在阻塞其它处理器获取该共享变量的操作请求时，也可能会导致大量阻塞，从而增加系统的性能开销。 缓存锁定 后来的处理器都提供了缓存锁定机制，当某个处理器对缓存中的共享变量进行了操作，其他处理器会有个嗅探机制，将其他处理器的该共享变量的缓存失效，待其他线程读取时会重新从主内存中读取最新的数据，基于 MESI 缓存一致性协议来实现的。 现代的处理器基本都支持和使用的缓存锁定机制。 2.3、JUC包中的锁Java中有很多种类的锁，在JUC包中也有比较多的锁类型。但不用怕难，因为归结到底层和操作系统级别，其核心原理和机制都是类似的，所以学Java的锁也只需要掌握锁背后的核心机制和扩展方向就行了，剩下的就交给举一反三吧。 JUC包中锁之间的关联 通过上图，对JUC包中的锁有个宏观认识，相信对理解和掌握JUC包中的锁会有事半功倍的效果。 2.3.1、顶层抽象类：AbstractQueuedSynchronizer（AQS）2.3.1.1、AbstractQueuedSynchronizer，简称AQS。【核心抽象类】 我们对于锁的认知，一般会有如下几个常规的认知： 1、多个线程尝试拿锁 2、拿不到锁的线程阻塞等待 3、用完锁的线程释放锁，等待线程得到锁 其实在JUC包中锁实现的本质原理也是这么回事。 有关于AQS： 1、AQS中的等待队列FIFO head：表示当前拿到锁的线程Node node：表示未拿到锁被阻塞的线程Node 2、AQS有“独占锁”和“共享锁”两种模式 独占模式（Node.EXCLUSIVE） 应用：ReentrantLock 共享模式（Node.SHARE） 应用：Semaphore 3、实现了AQS的锁有：自旋锁、互斥锁、读锁写锁、条件产量、信号量、栅栏都是AQS的衍生物 2.3.1.1.1、独占模式： 为帮助阅读，已精简剔除大量代码。 1234567891011121314151617181920212223242526272829public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer &#123; .../**重要变量*/ // 头结点，可理解为当前持有锁的线程 private transient volatile Node head; // 阻塞的尾节点，每个新的节点进来，都插入到最后，也就形成了一个链表 private transient volatile Node tail; // 代表当前锁的状态，0代表没有被占用，大于0 代表有线程持有当前锁, 大于 1 代表锁重入的次数 private volatile int state; // 当前持有独占锁的线程。继承自AbstractOwnableSynchronizer private transient Thread exclusiveOwnerThread; /**重要接口*/ // 加锁接口 public final void acquire(int arg)&#123;...&#125; boolean tryAcquire(int arg) &#123;...&#125; // 尝试加锁 Node addWaiter(Node mode) &#123;...&#125; // 拿不到锁就创建新等待节点，并添加到队列尾部 boolean acquireQueued(final Node node, int arg) &#123;...&#125; // 使线程阻塞在等待队列中，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false boolean parkAndCheckInterrupt() // 当前线程主动阻塞自己 //解锁接口 public final boolean release(int arg) &#123;...&#125; boolean tryRelease(int arg) &#123;...&#125; // 尝试解锁，一般都会成功。若跨线程解锁会抛异常 void unparkSuccessor(Node node) // 唤醒等待队列里的下一个等待节点的线程 ...&#125; AbstractQueuedSynchronizer作为JUC包中锁的顶级抽象类，以模板方式和抽象方法方式，为JUC包中锁的实现定义了框架和提供了默认/基础实现。 AQS类锁能力基础认知： 1、如上代码注释所属。其实现原理借助于关键变量：head、tail、state、exclusiveOwnerThread，和关键方法：acquire和release，以及内部的子方法。 2、总体上实现：加锁、判断锁、阻塞等待队列、可重入锁、解锁等框架能力 AQS关键代码解读： acquireQueued(Node, int) 拿不到锁时，线程阻塞挂起 123456789101112131415161718192021222324252627final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true;//标记是否成功拿到资源 try &#123; boolean interrupted = false;//标记等待过程中是否被中断过 //“自旋”！ for (;;) &#123; final Node p = node.predecessor();//拿到前驱 //如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源（可能是老大释放完资源唤醒自己的，当然也可能被interrupt了）。 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node);//拿到资源后，将head指向该结点。所以head所指的标杆结点，就是当前获取到资源的那个结点或null。 p.next = null; // setHead中node.prev已置为null，此处再将head.next置为null，就是为了方便GC回收以前的head结点。也就意味着之前拿完资源的结点出队了！ failed = false; // 成功获取资源 return interrupted;//返回等待过程中是否被中断过 &#125; //如果自己可以休息了，就通过park()进入waiting状态，直到被unpark()。如果不可中断的情况下被中断了，那么会从park()中醒过来，发现拿不到资源，从而继续进入park()等待。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true;//如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true &#125; &#125; finally &#123; if (failed) // 如果等待过程中没有成功获取资源（如timeout，或者可中断的情况下被中断了），那么取消结点在队列中的等待。 cancelAcquire(node); &#125; &#125; unparkSuccessor(Node node) 解锁时唤醒下一个等待节点线程 12345678910111213141516private void unparkSuccessor(Node node) &#123; //这里，node一般为当前线程所在的结点。 int ws = node.waitStatus; if (ws &lt; 0)//置零当前线程所在的结点状态，允许失败。 compareAndSetWaitStatus(node, ws, 0); Node s = node.next;//找到下一个需要唤醒的结点s if (s == null || s.waitStatus &gt; 0) &#123;//如果为空或已取消 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) // 从后向前找。 if (t.waitStatus &lt;= 0)//从这里可以看出，&lt;=0的结点，都是还有效的结点。 s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒 &#125; 2.3.1.1.2、共享模式： 查看带 xxxShared 字眼的方法 相比独占模式，共享模式的差异如下： 1、state 初始值大于1，代表可被共享的次数 2、共享模式加锁时，对state做减法操作，只要剩余state够就能加锁成功。加锁成功时不再记录加锁的Thread信息。 3、加锁失败时，与共享模式一样，添加等待节点到等待队列尾部。 4、解锁时，做state做加法操作。然后循环唤醒等待队列中的阻塞线程。 关键代码解读： tryAcquireShared 123456789101112final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; //获取AQS中资源个数 int available = getState(); int remaining = available - acquires; //如果remaining小于0，说明没有可用的资源了，如果大于0，执行CAS操作获取资源，最后返回剩余的资源数 //如果返回的剩余资源数小于或者等于0，说明没有可用资源了，如果大于0，说明还有可用资源 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; releaseShared 12345678910111213141516171819public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;//Semaphore中的实现protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error("Maximum permit count exceeded"); if (compareAndSetState(current, next)) // 释放资源占用 return true; &#125;&#125; doReleaseShared 1234567891011121314151617181920212223242526272829private void doReleaseShared() &#123; for (;;) &#123; //获取首节点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; //获取首节点状态 int ws = h.waitStatus; //如果首节点状态是SIGNAL，说明首节点后面还有节点，唤醒他们 if (ws == Node.SIGNAL) &#123; //先把首节点状态改成0，0可以看成首节点的中间状态，只有在唤醒第二个节点的时候才会存在，当第二个节点唤醒之后，首节点 //就会被干掉 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases //这个方法就是唤醒首节点之后第一个处于非取消状态的节点 unparkSuccessor(h); &#125; //判断ws == 0，这个是中间状态，就是说有一个线程正在唤醒第二个节点，这个时候，又有一个线程释放了资源，也要来唤醒第二个节点，但是他发现 //有别的线程在处理，他就把这个状态改成PROPAGATE = -3,而这个状态正是上一个方法需要判断的，上一个方法判断h.waitStatus &lt; 0，会成立就是这里设置的 //当然，h.waitStatus &lt; 0会成立，还有别的原因，这个只是其中一个，下面会分析 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 至此，你已经掌握了AQS抽象类的主要原理，相信在看具体锁实现时会事半功倍（AbstractQueuedSynchronizer中还有很多的具体实现，但不打紧，掌握这几个核心原理就可以了）。 2.3.2、顶层抽象类：AbstractOwnableSynchronizer此类特别简单，可直接看代码。 123456789101112131415public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; // 锁独占模式下，当前独占锁的线程 private transient Thread exclusiveOwnerThread; //set操作 protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; //get操作 protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125;&#125; 2.3.3、顶层抽象类：AbstractQueuedLongSynchronizer一句话：64位版本的AQS 2.3.4、锁分类Java中有哪些常见的锁？ 见本文后面章节《Java中的锁》。进行了分类和详细的介绍。 2.3.5、ReentrantLock 假设你已经先读了： AQS 本文的锁分类介绍 那么，在此基础上我们差异性的陈述一些要点： ReentrantLock是独享锁 ReentrantLock底层是基于AQS ReentrantLock支持公平锁模式和非公平锁模式，默认是非公平锁（即尝试加锁时是抢占式的） 老生常谈 之 ReentrantLock vs synchronized 既然与ReentrantLock相比，那么就从ReentrantLock特点的视角对比下： 锁类型 底层技术 是否公平锁 是否可重入 ReentrantLock 独享锁 CAS + AQS 均支持。可指定 可重入 synchronized 独享锁 CAS + Monitor 非公平锁 可重入 关于ReentrantLock的可重入，还记得上文的AbstractOwnableSynchronizer不，每次加锁时拿出来判断下即可，发现是同一个线程，重入。 另外，两者在性能层面没有明显区别。 所以，选择哪一种就要看具体代码场景了 适合ReentrantLock的场景 细粒度的锁范围控制 细粒度的阻塞线程唤醒。ReentrantLock提供了Condition类，用来实现分组唤醒需要唤醒的线程们。 ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。 所以，一般情况下常规加锁需求用synchronized先，有更进一步的加锁要求时ReentrantLock更适合。 2.3.6、ReentrantReadWriteLock上来先讲结论，然后再酌情看代码加深理解： （参考下图） ReentrantReadWriteLock是读写锁 ReentrantReadWriteLock内部持有两把锁来实现读写锁：ReadLock、WriteLock ReadLock&amp;WriteLock共用一个Sync（即共享同一个AQS），正因为是共用一个Sync，才能在读写锁的时候分别感知对方的状态。 ReentrantReadWriteLock的读写锁标记维护在同一个AQS的state上，为了记录ReadLock和WriteLock的次数， 通过EXCLUSIVE_MASK将32位的state拆成两段：高16位给ReadLock用，低16位给WriteLock用。 读锁状态：可多个线程同时拿锁，且均可各自重入。（见：Sync内部类HoldCounter和ThreadLocalHoldCounter） 写锁状态：独享锁状态。 ReentrantReadWriteLock支持锁降级：写锁状态进入，读锁状态退出 ReentrantReadWriteLock类依赖关系 ReentrantReadWriteLock内部的两把锁： 共用一个Sync（AQS）： Sync里有哪些重要信息呢？ 将AQS state字段复用为读锁、写锁计数位的SHARED_SHIFT ThreadLocalHoldCounter控制读锁重入 其他均继承自AQS state 记录锁的状态 exclusiveOwnerThread 记录锁被哪个线程独占 等待队列 线程阻塞 &amp; 等待线程唤醒方法 共享模式（读锁的场景） ReentrantReadWriteLock分段使用AQS的锁计数state： 锁降级： 概念： 以写锁进入临界区，但以读锁结束。（加锁顺序：写锁-加锁 ==&gt; 读锁加锁 ==&gt; 写锁-解锁 ==&gt; 读锁-解锁） 相关代码 12345678public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; ... public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) //若tryAcquireShared返回&gt;=0。代表拿读锁成功 doAcquireShared(arg); //执行拿读锁的逻辑 &#125; ...&#125; 1234567891011121314151617181920212223242526272829303132333435public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; ... abstract static class Sync extends AbstractQueuedSynchronizer &#123; ... protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); //注解说明：当前时刻存在写锁，而且如果自己这个获取读锁的线程和当前持有写锁的线程是同一个线程的话，就不会返回-1。也就是说可以继续获取读锁。 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current); &#125; ... &#125; ...&#125; 2.3.7、StampedLock在 JDK 1.8 引入 StampedLock，可以理解为对 ReentrantReadWriteLock 在某些方面的增强，在原先读写锁的基础上新增了一种叫乐观读（Optimistic Reading）的模式。该模式并不会加锁，所以不会阻塞线程，允许多个度线程和1个写线程并发执行，故有更高的吞吐量和更高的性能。尤其适合读多写少的场景。 2.3.7.1、特性 它的设计初衷是作为一个内部工具类，用于开发其他线程安全的组件，提升系统性能，并且编程模型也比ReentrantReadWriteLock 复杂，所以用不好就很容易出现死锁或者线程安全等莫名其妙的问题。 三种访问数据模式： Writing（独占写锁）：writeLock 方法会使线程阻塞等待独占访问，可类比ReentrantReadWriteLock 的写锁模式，同一时刻有且只有一个写线程获取锁资源； Reading（悲观读锁）：readLock方法，允许多个线程同时获取悲观读锁，悲观读锁与独占写锁互斥，与乐观读共享。 Optimistic Reading（乐观读）：这里需要注意了，是乐观读，并没有加锁。也就是不会有 CAS 机制并且没有阻塞线程。仅当当前未处于 Writing 模式 tryOptimisticRead才会返回非 0 的邮戳（Stamp），如果在获取乐观读之后没有出现写模式线程获取锁，则在方法validate返回 true ，允许多个线程获取乐观读以及读锁。同时允许一个写线程获取写锁。《《《《《【重点】【重点】【重点】 支持读写锁相互转换 ReentrantReadWriteLock： 当线程获取写锁后可以降级成读锁，但是反过来则不行。 StampedLock：提供了读锁和写锁相互转换的功能，使得该类支持更多的应用场景。 2.3.7.2、详解乐观读带来的性能提升 StampedLock 性能比 ReentrantReadWriteLock 好，关键在于StampedLock 提供的乐观读。 我们知道ReentrantReadWriteLock 的读锁和写锁是互斥的，当有读锁的时候，写锁线程是阻塞等待的。 而，StampedLock 的乐观读允许一个写线程获取写锁，所以不会导致所有写线程阻塞，也就是当读多写少的时候，写线程有机会获取写锁，减少了线程饥饿的问题，吞吐量大大提高。 这里可能你就会有疑问，竟然同时允许多个乐观读和一个先线程同时进入临界资源操作，那读取的数据可能是错的怎么办？ 是的，乐观读不能保证读取到的数据是最新的，所以将数据读取到局部变量的时候需要通过 lock.validate(stamp) 校验是否被写线程修改过，若是修改过则需要上悲观读锁，再重新读取数据到局部变量。 同时由于乐观读并不是锁，所以没有线程唤醒与阻塞导致的上下文切换，性能更好。 2.3.7.3、使用场景和注意事项 对于读多写少的高并发场景 StampedLock的性能很好！ 通过乐观读模式很好的解决了写线程“饥饿”的问题，我们可以使用StampedLock 来代替ReentrantReadWriteLock ，但是需要注意的是 StampedLock 的功能仅仅是 ReadWriteLock 的子集，在使用的时候，还是有几个地方需要注意一下。 StampedLock是不可重入锁，如果当前线程已经获取了写锁，再次重复获取的话就会死锁。使用过程中一定要注意； 悲观读、写锁都不支持条件变量 Conditon ，当需要这个特性的时候需要注意； 如果线程阻塞在 StampedLock 的 readLock() 或者 writeLock() 上时，此时调用该阻塞线程的 interrupt() 方法，会导致 CPU 飙升。所以，使用 StampedLock 一定不要调用中断操作，如果需要支持中断功能，一定使用可中断的悲观读锁 readLockInterruptibly() 和写锁 writeLockInterruptibly()。这个规则一定要记清楚。 对比： 锁模式 是否可重入 CAS后的ABA问题 锁转换 ReentrantReadWriteLock 悲观读 可重入 无法避免ABA问题 锁降级 StampedLock 悲观读/乐观读 不可重入 通过版本号解决ABA问题 锁降级/锁升级 2.3.7.4、代码例子 官方例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class StampedLockDemo &#123; // 成员变量 private double x, y; // 锁实例 private final StampedLock sl = new StampedLock(); // 排它锁-写锁（writeLock） void move(double deltaX, double deltaY) &#123; long stamp = sl.writeLock(); try &#123; x += deltaX; y += deltaY; &#125; finally &#123; sl.unlockWrite(stamp); &#125; &#125; // 乐观读锁 double distanceFromOrigin() &#123; // 尝试获取乐观读锁（1） long stamp = sl.tryOptimisticRead(); // 将全部变量拷贝到方法体栈内（2） double currentX = x, currentY = y; // 检查在（1）获取到读锁票据后，锁有没被其他写线程排它性抢占（3） if (!sl.validate(stamp)) &#123; // 如果被抢占则获取一个共享读锁（悲观获取）（4） stamp = sl.readLock(); try &#123; // 将全部变量拷贝到方法体栈内（5） currentX = x; currentY = y; &#125; finally &#123; // 释放共享读锁（6） sl.unlockRead(stamp); &#125; &#125; // 返回计算结果（7） return Math.sqrt(currentX * currentX + currentY * currentY); &#125; // 使用悲观锁获取读锁，并尝试转换为写锁 void moveIfAtOrigin(double newX, double newY) &#123; // 这里可以使用乐观读锁替换（1） long stamp = sl.readLock(); try &#123; // 如果当前点在原点则移动（2） while (x == 0.0 &amp;&amp; y == 0.0) &#123; // 尝试将获取的读锁升级为写锁（3） long ws = sl.tryConvertToWriteLock(stamp); // 升级成功，则更新票据，并设置坐标值，然后退出循环（4） if (ws != 0L) &#123; stamp = ws; x = newX; y = newY; break; &#125; else &#123; // 读锁升级写锁失败则释放读锁，显示获取独占写锁，然后循环重试（5） sl.unlockRead(stamp); stamp = sl.writeLock(); &#125; &#125; &#125; finally &#123; // 释放锁（6） sl.unlock(stamp); &#125; &#125;&#125; 2.3.8、SemaphoreSemaphore是一种计数信号量，用于管理一组资源，内部是基于AQS的共享模式。它相当于控制使用公共资源的活动线程的数量。 使用场景的比喻：停车场车位滚动使用；卫生间坑位的滚动使用。 主要结构： 1234567891011121314151617181920212223public class Semaphore implements java.io.Serializable &#123; abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 基于AQS。那么天然可重入。 ... &#125; static final class NonfairSync extends Sync &#123; // 非公平锁。 ... &#125; static final class FairSync extends Sync &#123; // 公平锁。 ... &#125; public void acquire() throws InterruptedException &#123;&#125; public boolean tryAcquire() &#123;&#125; public void release() &#123;&#125; public int availablePermits() &#123;&#125; ...&#125; 主要方法： 12345678910111213Semaphore(int permits):构造方法，创建具有给定许可数的计数信号量并设置为非公平信号量。Semaphore(int permits,boolean fair):构造方法，当fair等于true时，创建具有给定许可数的计数信号量并设置为公平信号量。void acquire():从此信号量获取一个许可前线程将一直阻塞。相当于一辆车占了一个车位。void acquire(int n):从此信号量获取给定数目许可，在提供这些许可前一直将线程阻塞。比如n=2，就相当于一辆车占了两个车位。void release():释放一个许可，将其返回给信号量。就如同车开走返回一个车位。void release(int n):释放n个许可。int availablePermits()：当前可用的许可数。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class SemaphoreDemo &#123; //构建一个信号量，并发度为3 private static final Semaphore SEMAPHORE = new Semaphore(3); //线程池 private static final ThreadPoolExecutor THREAD_POOL = new ThreadPoolExecutor(5, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); public static void main(String[] args) &#123; //起多个线程竞争 for (int i = 1; i &lt; 6; i++) &#123; THREAD_POOL.execute(new Car(i)); &#125; &#125; private static class Car extends Thread &#123; private final Integer number; public Car(Integer number) &#123; this.number = number; &#125; @Override public void run() &#123; try &#123; System.out.println((new Date()).getSeconds() + "second Car" + this.number + " waiting ..."); //拿到锁 SEMAPHORE.acquire(); //让拿到锁的线程稍作等待，等全部线程启动并都尝试拿锁 Thread.sleep(2000); System.out.println((new Date()).getSeconds() + "second Car" + this.number + " In . Remaining parking spaces=" + SEMAPHORE.availablePermits()); //释放锁 SEMAPHORE.release(); System.out.println((new Date()).getSeconds() + "second Car" + this.number + " Out. Remaining parking spaces=" + SEMAPHORE.availablePermits()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;运行结果：12second Car1 waiting ...12second Car3 waiting ...12second Car5 waiting ...12second Car2 waiting ...12second Car4 waiting ... 14second Car5 In . Remaining parking spaces=014second Car3 In . Remaining parking spaces=014second Car1 In . Remaining parking spaces=014second Car3 Out. Remaining parking spaces=214second Car1 Out. Remaining parking spaces=314second Car5 Out. Remaining parking spaces=316second Car4 In . Remaining parking spaces=116second Car4 Out. Remaining parking spaces=216second Car2 In . Remaining parking spaces=116second Car2 Out. Remaining parking spaces=3 2.4、并发安全集合类2.4.1、AbstractMapAbstractMap 提供了 Map 的基本实现，使得我们以后要实现一个 Map 不用从头开始。 AbstractMap提供了哪些基础能力呢？ 【反过来讲】极端情况下，开发者只需要实现entrySet()抽象方法和重载put()方法，就能自定义一个Map类。 2.4.2、ConcurrentHashMap HashMap结构由两级构成 一级：数组结构，俗称Segment 二级：链表/红黑树结构 2.4.2.1、知识点概要 读不涉及锁操作：get(Object key)不涉及锁操作。 写涉及锁操作：put、remove、clear方法使用锁。 ConcurrentHashMap为了减少锁征用，将锁加在数组节点上，俗称Segment。 ConcurrentHashMap允许一边更新、一边遍历。故Iterator对象使用时，获得的对象可能是更新前的对象。若希望遍历到当前全部数据的话，要么以ConcurrentHashMap变量为锁进行同步(synchronized该变量)，要么使用CopiedIterator包装iterator，使其拷贝当前集合的全部数据。 ConcurrentHashMap冲突域上有两种实现方法，最终是为了提高遍历查找的速度。 默认链表结构。 当链表节点超过8个时，自动升级成红黑树 当红黑树节点减少，少于6个时，会自动退化成链表 ConcurrentHashMap数组空间默认是16，resize是翻倍（左移一位） 为什么是16？参考：泊松分布 Poisson distribution (http://en.wikipedia.org/wiki/Poisson_distribution) ConcurrentHashMap实现同步的锁：synchronized 样例代码截取：我们可以看到在ConcurrentHashMap里锁的都是设计好的代码段位置 12345678910111213141516171819202122232425262728293031323334final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 在这 if (tabAt(tab, i) == f) &#123; .... &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null; &#125; 1234567891011121314151617181920212223242526272829final V replaceNode(Object key, V value, Object cv) &#123; int hash = spread(key.hashCode()); for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; boolean validated = false; synchronized (f) &#123; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 在这 if (tabAt(tab, i) == f) &#123; ... &#125; &#125; if (validated) &#123; if (oldVal != null) &#123; if (value == null) addCount(-1L, -1); return oldVal; &#125; break; &#125; &#125; &#125; return null; &#125; ConcurrentHashMap的空间为什么是2的幂次方？ 2的幂次方：ConcurrentHashMap内部用于计算hash值的spread方法（扰动函数）就能用位移操作进行快速计算，远比取模、加减乘除效率高 2的幂次方：在resize时，需要挪动Map节点，而2的幂次方递增，保持了规律性。只需要对最高位不一致的几个节点进行挪动即可，且挪动的步长是固定的老空间大小 例如：old size 16（占用尾部4个二进制位表达），new size 32（占用尾部5个二进制位表达） 此时resize时，遍历每个节点，判断节点的尾部5位的第5位是否为1，为1说明节点hash值是超出old size的，需要挪动。同理，第5位为0的，不需要挪动。 那么，挪到哪个位置呢？在原数组的位置基础上加上原数组的整体长度（16），这个值就是在新数组中的位置。 Hashtable和ConcurrentHashMap的不同点？ HashTable的同步级别是对象对象级。ConcurrentHashMap的同步级别是代码块级。ConcurrentHashMap吞吐能力好。 HashTable在iterator遍历的时候，不支持其他线程进行put，remove等更新操作，否则会抛出ConcurrentModificationException异常。而ConcurrentHashMap是支持的。 2.4.2.2、Java8 的新方法： compute方法 1234//key的value值，取自于remappingFunction的计算结果public V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction)public V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction)public V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) merge方法 123456//key的value值，取自于key下oldValue和newValue的计算结果，通过remappingFunction计算public V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) - 当key为尚未存在，直接插入对应value，remappingFunction不会被调用；- 否则，对oldValue与value做remappingFunction函数，结果作为新的newValue插入到map中。- 同样null结果会删除对应的k-v。 reduce方法 123456789//遍历map，对key或value值应用过滤函数和累加函数，最终得到一个累加值public &lt;U&gt; U reduce(long parallelismThreshold, BiFunction&lt;? super K, ? super V, ? extends U&gt; transformer, BiFunction&lt;? super U, ? super U, ? extends U&gt; reducer)public V reduceValues(long parallelismThreshold, BiFunction&lt;? super V, ? super V, ? extends V&gt; reducer)public K reduceKeys(long parallelismThreshold, BiFunction&lt;? super K, ? super K, ? extends K&gt; reducer)... compute方法示例： 123456789101112131415161718192021222324252627public void demo() &#123; final Map&lt;String, Integer&gt; count = new ConcurrentHashMap&lt;&gt;(); // key = b, 值为4不变 count.put("b", 4); // key = a, 用回调方法，不断累加 for (int i = 0; i &lt; 50; i++) &#123; count.compute("a", new BiFunction&lt;String, Integer, Integer&gt;() &#123; @Override public Integer apply(String k, Integer v) &#123; return v == null ? 1 : v + 1; &#125; &#125;); &#125; //回调里可做业务操作 System.out.println(count.compute("b", (k, v) -&gt; &#123; System.out.println(k + " --- " + v); return null; &#125;)); System.out.println(count.compute("a", (k, v) -&gt; v == null ? 1 : v + 1)); //此时count里只有a有value了 System.out.println(count);&#125; reduce方法示例： 123456789101112131415public void reduceDemo()&#123; ConcurrentHashMap&lt;String, Integer&gt; map = new ConcurrentHashMap&lt;&gt;(); map.put("1", 1); map.put("2", 2); map.put("3", 3); map.put("4", 4); map.put("5", 5); //无过滤器场景 Integer value1 = map.reduceValues(1, Integer::sum); //有过滤器场景 Integer value2 = map.reduceValues(1, v-&gt;0 == v%2?null:v, Integer::sum); System.out.println(value1); &lt;&lt;&lt; print 15 System.out.println(value2); &lt;&lt;&lt; print 9 &#125; 2.4.3、ConcurrentSkipListMap 一句话：key保序的ConcurrentHashMap。 第二句话：非多线程情况下，用TreeMap。 ConcurrentSkipListMap是线程安全的有序的哈希表，适用于高并发的场景。 ConcurrentSkipListMap是通过跳表实现的 并发且保序的需求时 低并发：使用Collections.synchronizedSortedMap 高并发：使用ConcurrentSkipListMap 关于跳表 ConcurrentSkipListMap的数据结构 以数据“7,14,21,32,37,71,85”序列为例，来对跳表进行简单说明。 跳表分为许多层(level)，每一层都可以看作是数据的索引，这些索引的意义就是加快跳表查找数据速度。每一层的数据都是有序的，上一层数据是下一层数据的子集，并且第一层(level 1)包含了全部的数据；层次越高，跳跃性越大，包含的数据越少。 跳表包含一个表头，它查找数据时，是从上往下，从左往右进行查找。现在“需要找出值为32的节点”为例，来对比说明跳表和普遍的链表。 情况1：链表中查找“32”节点路径如下图所示： 需要4步(红色部分表示路径)。 情况2：跳表中查找“32”节点路径如下图所示 忽略索引垂直线路上路径的情况下，只需要2步(红色部分表示路径)。 2.5、队列 Queue 是否有界 数据结构 排序 入队出队并发 特点 ArrayBlockingQueue 有界 数组 FIFO 否 无 LinkedBlockingQueue 可选 链表 FIFO 是 常用若不指定容量，默认无界 LinkedTransferQueue 无界 链表 FIFO 可选 有4种模式选择队列的行为表现 DelayQueue 无界 优先级队列 按时间排序 否 延时 PriorityBlockingQueue 无界 优先级队列 比较结果 否 入队列的元素必须实现Comparable接口 SynchronousQueue 容量0 N/A N/A 否 进一个出一个出一个进一个 ConcurrentLinkedQueue 无界 链表 FIFO 否 非阻塞 注： 关于公平性：ArrayBlockingQueue默认情况下不保证线程公平地访问队列，即阻塞的线程，不一定按阻塞的先后顺序访问队列，非公平性也是为了提高吞吐率 2.5.1、AbstractQueue 看到没，大部分的实现类都依赖：AbstractQueue 和 BlockingQueue。 AbstractQueue定义队列的方法集，用extends BlockingQueue定义了阻塞的个性功能，用implements 2.5.2、BlockingQueueBlockingQueue即阻塞队列，它是基于ReentrantLock。最常用的是用于实现生产者与消费者模式，大致如下图所示： 在Java中，BlockingQueue是一个接口，它的实现类有ArrayBlockingQueue、DelayQueue、 LinkedBlockingDeque、LinkedBlockingQueue、PriorityBlockingQueue、SynchronousQueue等，它们的区别主要体现在存储结构上或对元素操作上的不同，但是对于take与put操作的原理，却是类似的 入队 12345678offer(E e)：如果队列没满，立即返回true； 如果队列满了，立即返回false--&gt;不阻塞put(E e)：如果队列满了，一直阻塞，直到队列不满了或者线程被中断--&gt;阻塞offer(E e, long timeout, TimeUnit unit)：在队尾插入一个元素，如果队列已满，则进入等待，直到出现以下三种情况：--&gt;阻塞1、被唤醒2、等待时间超时3、当前线程被中断 出队 12345678poll()：如果没有元素，直接返回null；如果有元素，出队take()：如果队列空了，一直阻塞，直到队列不为空或者线程被中断--&gt;阻塞poll(long timeout, TimeUnit unit)：如果队列不空，出队；如果队列已空且已经超时，返回null；如果队列已空且时间未超时，则进入等待，直到出现以下三种情况：1、被唤醒2、等待时间超时3、当前线程被中断 2.5.3、LinkedBlockingQueue见总结表格 2.5.4、DelayQueue见总结表格 2.5.5、ArrayBlockingQueue虽是数组，但在逻辑上要把它想象成环，持续重复使用。 2.5.6、LinkedTransferQueue见总结表格 2.5.7、PriorityBlockingQueue见总结表格 2.5.8、SynchronousQueue见总结表格 2.5.9、ConcurrentLinkedQueue 基于链接节点可并发的无界双端队列。 并发插入，删除和访问操作安全执行。 因为这些deques的异步性质，例如确定当前的数量，元素需要遍历元素等操作是不可信的，因为在遍历期间可并发修改此集合。 也是使用cas来保证线程安全，这个类不仅可以操控头部，也可以操控尾部 2.6、线程池机制 JUC包中有关线程池的类 2.6.1、主要类介绍2.6.1.1、【Interface】顶层Executor 对，就是这么短。 定义了线程池最基本的动作：提交、执行。 123public interface Executor &#123; void execute(Runnable command);&#125; 2.6.1.2、【Interface】ExecutorService ExecutorService继承于Executor。它是”执行者服务”接口，它是为”执行者接口Executor”服务而存在的；准确的话，ExecutorService提供了”将任务提交给执行者的接口(submit方法)”，”让执行者执行任务(invokeAll, invokeAny方法)”的接口等等。 ExecutorService的函数列表 1234567891011121314151617181920212223242526272829303132333435// 请求关闭、发生超时或者当前线程中断，无论哪一个首先发生之后，都将导致阻塞，直到所有任务完成执行。boolean awaitTermination(long timeout, TimeUnit unit)// 执行给定的任务，当所有任务完成时，返回保持任务状态和结果的 Future 列表。&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)// 执行给定的任务，当所有任务完成或超时期满时（无论哪个首先发生），返回保持任务状态和结果的 Future 列表。&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit)// 执行给定的任务，如果某个任务已成功完成（也就是未抛出异常），则返回其结果。&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)// 执行给定的任务，如果在给定的超时期满前某个任务已成功完成（也就是未抛出异常），则返回其结果。&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit)// 如果此执行程序已关闭，则返回 true。boolean isShutdown()// 如果关闭后所有任务都已完成，则返回 true。boolean isTerminated()// 启动一次顺序关闭，执行以前提交的任务，但不接受新任务。void shutdown()// 试图停止所有正在执行的活动任务，暂停处理正在等待的任务，并返回等待执行的任务列表。List&lt;Runnable&gt; shutdownNow()// 提交一个返回值的任务用于执行，返回一个表示任务的未决结果的 Future。&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task)// 提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future。Future&lt;?&gt; submit(Runnable task)// 提交一个 Runnable 任务用于执行，并返回一个表示该任务的 Future。&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) 2.6.1.3、【Class】AbstractExecutorService AbstractExecutorService是一个抽象类，它实现了ExecutorService接口。 AbstractExecutorService存在的目的是为ExecutorService中的函数接口提供了默认实现。 AbstractExecutorService函数列表和ExecutorService一样。 2.6.1.4、【Class】ThreadPoolExecutor ThreadPoolExecutor就是大名鼎鼎的”线程池”。它继承于AbstractExecutorService抽象类。 2.6.1.5、【Interface】ScheduledExecutorService ScheduledExecutorService是一个接口，它继承于于ExecutorService。 它相当于提供了”延时”和”周期执行”功能的ExecutorService。 ScheduledExecutorService提供了相应的函数接口，可以安排任务在给定的延迟后执行，也可以让任务周期的执行。 ScheduledExecutorService函数列表 1234567891011// 创建并执行在给定延迟后启用的 ScheduledFuture。&lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit)// 创建并执行在给定延迟后启用的一次性操作。ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit)// 创建并执行一个在给定初始延迟后首次启用的定期操作，后续操作具有给定的周期；也就是将在 initialDelay 后开始执行，然后在 initialDelay+period 后执行，接着在 initialDelay + 2 * period 后执行，依此类推。ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)// 创建并执行一个在给定初始延迟后首次启用的定期操作，随后，在每一次执行终止和下一次执行开始之间都存在给定的延迟。ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) 2.6.1.6、【Class】ScheduledThreadPoolExecutor 是ScheduledExecutorService的实现类。记住特点：”延时”和”周期执行”。ScheduledThreadPoolExecutor类似于Timer，但是在高并发程序中，ScheduledThreadPoolExecutor的性能要优于Timer。 2.6.1.7、【Class】Executors Executors是个静态工厂类。它通过静态工厂方法返回ExecutorService、ScheduledExecutorService、ThreadFactory 和 Callable 等类的对象 2.6.2、重点详解ThreadPoolExecutor【敲黑板】线程池的“池”，就是在ThreadPoolExecutor中。 ThreadPoolExecutor特点： 线程池和任务队列可定制 运行前后可扩展 从源码角度认识ThreadPoolExecutor 构造方法 123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ... &#125; （重要知识点）ThreadPoolExecutor构造方法参数解读： corePoolSize：核心线程数。线程池在初始构造后，线程池里的线程是0个，待有任务进来时，开始创建线程，直到达到corePoolSize。当任务数多于corePoolSize时，不再创建线程，而是把任务放入workQueue排队。 maxPoolSize：corePoolSize说到，任务数多于corePoolSize时，任务是进workQueue等待的。那什么时候突破corePoolSize继续创建线程呢？（重点）只有在workQueue满了时，再有新任务进来就会额外的创建线程，直到总线程数到达maxPoolSize。故，maxPoolSize是线程池的线程个数上限。 keepAliveTime：如果线程池当前线程数多余corePoolSize，那么多余的线程的空闲时间超过keepAliveTime，它们就会被终止。 unit：与keepAliveTime搭配，表示时间的单位，JUC包下的TimeUnit类。 threadFactory：线程工厂，用来创建线程。默认使用Executors.defaultThreadFactory()，Executors.defaultThreadFactory创建出来的线程都在同一个线程组，拥有同样的NORM_PRIORITY优先级（默认5）并且都不是守护线程。如果自己指定ThreadFactory，那么就可以改变线程名、线程组、优先级、是否为守护线程等。 workQueue：任务队列。必须是BlockingQueue的实现类，有三种常见的队列类型： 直接交接：SynchronousQueue 无界队列：LinkedBlockingQueue 《《《 鉴于maxPoolSize的工作机制，要特别注意无界队列的情况 有界队列：ArrayBlockingQueue handler：在maxPoolSize了解到，当workQueue满了后会创建新线程，直到maxPoolSize。那么此时线程个数最大且workQueue满了，此时还来新任务。对于线程池来说，就没地方存放这个任务了，就会做拒绝逻辑处理。 JUC有提供四种拒绝策略: AbortPolicy（默认的）：就是直接抛出异常 CallerRunsPolicy：把任务留给调用方线程去执行 DiscardPolicy：啥都不敢，丢弃。 DiscardOldestPolicy：当任务被拒绝添加时，抛弃workQueue里最旧的任务（即最先进入队列的那个） 自定义：实现RejectedExecutionHandler Interface。 重要变量 1234567891011121314151617181920212223242526public class ThreadPoolExecutor extends AbstractExecutorService &#123; // 任务队列 private final BlockingQueue&lt;Runnable&gt; workQueue; // 线程池 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // 线程工厂 private volatile ThreadFactory threadFactory; //构造方法里的一些参数 private volatile RejectedExecutionHandler handler; private volatile long keepAliveTime; private volatile int corePoolSize; private volatile int maximumPoolSize; //表示是否允许核心线程在空闲状态下自行销毁 private volatile boolean allowCoreThreadTimeOut; // 线程池已完成的任务数 private long completedTaskCount; // 表示线程池从创建到现在，池中线程的最大数量 private int largestPoolSize; //主要用于同步访问（或者说改变）线程池的状态以及线程池的各项参数，比如completedTaskCount和workers等 private final ReentrantLock mainLock = new ReentrantLock();&#125; worker 12345678910111213141516171819202122private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; // 线程 final Thread thread; // 任务 Runnable firstTask; // 完成任务个数 volatile long completedTasks; Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; ...&#125; ThreadPoolExecutor扩展 ThreadPoolExecutor扩展主要是围绕beforeExecute()、afterExecute()和terminated()三个接口实现的， 1、beforeExecute：线程池中任务运行前执行 2、afterExecute：线程池中任务运行完毕后执行 3、terminated：线程池退出后执行 2.6.3、ExecutorService的三种线程池机制 一、newFixedThreadPool 123public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; FixedThreadPool 的核心线程数和最大线程数都是指定值且相同，也就是说当线程池中的线程数超过核心线程数后，任务都会被放到阻塞队列中。且，这里选用的阻塞队列是LinkedBlockingQueue，使用的是默认容量 Integer.MAX_VALUE，相当于没有上限。 那么此线程池的逻辑是：按固定线程数执行任务，超过的任务都放任务队列排队。 用途：FixedThreadPool 用于负载比较大的服务器，为了资源的合理利用，需要限制当前线程数量 二、newCachedThreadPool 123public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; CachedThreadPool 里线程池中的线程具有缓存的效果：创建后会keepalive 60秒。 它的执行流程如下： 如果有空闲线程，就去取出任务执行；如果没有空闲线程，就新建一个。 执行完任务的线程有 60 秒生存时间，如果在这个时间内可以接到新任务，就可以继续活下去，否则就被回收 三、newSingleThreadExecutor 1234public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 2.6.4、如何优雅的关闭线程池 见下文《多线程场景》编码举例&amp;详解 2.6.5、如何合理配置线程池的大小如何合理配置线程池大小，线程池大小不是靠猜，也不是说越多越好。 在遇到这类问题时，需要分析 需要分析线程池执行的任务的特性： CPU 密集型还是 IO 密集型 每个任务执行的平均时长大概是多少，这个任务的执行时长可能还跟任务处理逻辑是否涉及到网络传输以及底层系统资源依赖有关系 如果是 CPU 密集型： 主要是执行计算任务，这种任务 cpu的利用率很高，那么线程数的配置应该根据 CPU 核心数来决定。 CPU 核心数 = 最大同时执行线程数。过多的线程会导致上下文切换反而使得效率降低。那线程池的最大线程数可以配置为 cpu 核心数+1 如果是 IO 密集型： 主要是进行 IO 操作，执行 IO 操作的时间较长，这时 cpu 经常会处于空闲等待状态，导致 cpu 的利用率不高，这种情况下可以增加线程池的大小。 这种情况下可以结合线程的等待时长来做判断，等待时间越高，那么线程数也相对越多。 一般可以配置 cpu 核心数的 2 倍。 一个公式： 线程池设定最佳线程数目 = （（线程池设定的线程等待时间 + 线程CPU执行时间）/ 线程CPU执行时间 ）* CPU 数目 这个公式的线程 cpu 执行时间是预估的程序单个线程在 cpu 上运行的时间（通常使用 压测工具测试大量运行次数求出平均值） 例如： 高并发、任务执行时间短的任务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换 但，这对于真实的并发场景来说，这只是根据CPU核数的计算。实际情况中，专业全面一点，还要根据具体任务的内存占用情况、数据库并发情况、外部交互的服务的并发情况等来微调线程池大小。 对！高并发是个系统、全面、整体性的工作。 最终线程池设多大最合理，建议进行压测获取任务吞吐量，然后综合评定。 其他，一些关于连接池的系统资源数据参考 1234567891011121314151617181920212223Linux方面- 系统最大文件打开数：65535- 最大TCP连接：20000- TCP连接建议值：10240JVM方面- 最大连接个数：1024Tomcat方面- 最大连接个数：maxConnections 10000， maxThreads 200Dubbo方面- 默认最大连接个数：200Mysql方面- 客户端：SpringBoot最大连接个数：100- 服务端：阿里云RDS 300~64000Redis方面- 客户端： - SpringBoot2.0 - lettuce 没有池 - jedis客户端默认有池：8- 服务端：默认10000 2.6.6、线程池的监控（感知线程池的运行情况）如果在项目中大规模的使用了线程池，那么必须要有一套监控体系，来感知当前线程池的状态，当出现问题的时候可以快速定位到问题。 线程池提供了相应的扩展方法，我们通过重写线程池的 beforeExecute、afterExecute 和 shutdown 等方式就可以收集线程运行状态信息，实现对线程池的监控。 一个简单案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Demo1 extends ThreadPoolExecutor &#123; // 保存任务开始执行的时间,当任务结束时,用任务结束时间减去开始时间计算任务执行时间 private ConcurrentHashMap&lt;String, Date&gt; startTimes; public Demo1(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); this.startTimes = new ConcurrentHashMap&lt;&gt;(); &#125; @Override public void shutdown() &#123; System.out.println("已经执行的任务数："+this.getCompletedTaskCount()+", " + "当前活动线程数:" + this.getActiveCount() + ",当前排队线程数:"+ this.getQueue().size()); System.out.println(); super.shutdown(); &#125; //任务开始之前记录任务开始时间 @Override protected void beforeExecute(Thread t, Runnable r) &#123; startTimes.put(String.valueOf(r.hashCode()), new Date()); super.beforeExecute(t, r); &#125; @Override protected void afterExecute(Runnable r, Throwable t) &#123; Date startDate = startTimes.remove(String.valueOf(r.hashCode())); Date finishDate = new Date(); long diff = finishDate.getTime() - startDate.getTime(); // 统计任务耗时、初始线程数、核心线程数、正在执行的任务数量、 // 已完成任务数量、任务总数、队列里缓存的任务数量、 // 池中存在的最大线程数、最大允许的线程数、线程空闲时间、线程池是否关闭、线程池是否终止 System.out.print("任务耗时:" + diff + "\n"); System.out.print("初始线程数:" + this.getPoolSize() + "\n"); System.out.print("核心线程数:" + this.getCorePoolSize() + "\n"); System.out.print("正在执行的任务数量:" + this.getActiveCount() + "\n"); System.out.print("已经执行的任务数:"+this.getCompletedTaskCount()+"\n "); System.out.print("任务总数:" + this.getTaskCount() + "\n"); System.out.print("最大允许的线程数:" + this.getMaximumPoolSize() + "\n"); System.out.print("线程空闲时间:"+this.getKeepAliveTime(TimeUnit.MILLISECONDS)+"\n "); System.out.println(); super.afterExecute(r, t); &#125; public static ExecutorService newCachedThreadPool() &#123; return new Demo1(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue()); &#125; 2.7、多线程协同工具类2.7.1、Fork / Join 分治机制JUC包中Fork / Join 机制的功能，简单来说： 可并行处理的大任务 拆分成一个个的小任务 并发执行 然后逐步归集任务结果 Fork / Join 用分治法解决问题。典型的应用比如快速排序算法。 要点在于，ForkJoinPool需要使用相对少的线程(默认系统自带cpu核数)来处理大量[有依赖关系]的任务。 2.7.1.1、ForkJoinPool &amp; ForkJoinTask 类 Fork / Join 主要由JUC包中的ForkJoinPool 和 ForkJoinTask类实现。 ForkJoinTask 是任务执行的基本单位 开发者需实现两部分功能 1、切分任务为更小的任务，并join子任务的结果。（见上图效果） 2、作为最小的任务，完成计算逻辑，并返回结果。 ForkJoinTask是抽象类，需要被实现：exec、setRawResult、getRawResult。在JUC包中，有提供继承了ForkJoinTask的RecursiveTask（已有ForkJoinTask待继承方法的默认实现，开发者只需要实现compute方法就行），推荐开发者用RecursiveTask。 ForkJoinTask vs ForkJoinAction ForkJoinTask有返回值，分解后可归并 ForkJoinAction无返回值，分解后纯执行 RecursiveTask源码： 12345678910111213141516171819public abstract class RecursiveTask&lt;V&gt; extends ForkJoinTask&lt;V&gt; &#123; V result; protected abstract V compute(); public final V getRawResult() &#123; return result; &#125; protected final void setRawResult(V value) &#123; result = value; &#125; protected final boolean exec() &#123; result = compute(); return true; &#125;&#125; ForkJoinPool 是任务的执行核心 几个要点： 内含 ForkJoinTask数组（任务） 内含ForkJoinWorkerThread数组（执行线程） 每个工作线程都有维护一份待执行的ForkJoinTask等待队列。用于存储在本线程中被拆分的若干子任务。 Thread个数可配。Thread工厂由默认DefaultForkJoinWorkerThreadFactory提供。 JVM加载ForkJoinPool类时，会初始创建一个commonPool，lambda表达式默认情况下共享这个commonPool：只要是共享工作线程Workers，连带的就共享workder下的Task队列了。 commonPool默认线程数是机器的CPU数 - 1（例如16核的CPU，线程数15个） 故，大家共享的情况下，使用Java 8 并行流（parallel stream），冷不丁就会对整体性能造成了严重影响，使用lambda parallelStream时需要尤其注意使用场景，CPU密集型是合适的。 代码中new ForkJoinPool()的都是独立的pool。 怎么办呢？特殊场景就自定义ForkJoinPool，不要用commonPool 12//代码很简单，设定想要的并发度就行了ForkJoinPool forkJoinPool = new ForkJoinPool(8); fork( ) 做些什么？ 12345678public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this;&#125; 当前线程不是个ForkJoinWorkerThread的时候，则加入到ForkJoinPool线程池(基于ExecutorService实现)，最终会归到某个workerThread的workQueue里去； 如果当前线程已经是个ForkJoinWorkerThread了，则把这个任务加入到当前线程的workQueue; 这是和普通线程池不同的地方，task并不是交给线程池中的queue，而是放到线程本地的workQueue ForkJoinPool中的Task如何运行？ a）线程以LIFO先进后出方式从本地队列获取任务，执行，直到自己的队列为空； b）查看其他ForkJoinWorkerThread是否有未执行task，有的话通过work−stealing窃取,窃取方式为FIFO先进先出，减少竞争；优先看曾今从自己那里窃取任务的thread，如果有的话； C）任务运行完成时，返回结果； join( )做些什么？ 12345678public final V join() &#123; int s; //调用doJoin方法阻塞等待的结果不是NORMAL,说明有异常或取消.报告异常 if ((s = doJoin() &amp; DONE_MASK) != NORMAL) reportException(s); //等于NORMAL,正常执行完毕,返回原始结果 return getRawResult();&#125; 它首先调用doJoin方法，由doJoin()完成复杂的逻辑处理 1、检查调用join()的线程是否是ForkJoinThread线程。如果不是（例如main线程），则阻塞当前线程，等待任务完成。如果是，则不阻塞。 2、查看任务的完成状态，如果已经完成，直接返回结果。 3、如果任务尚未完成，但处于自己的工作队列内，则完成它。 4、如果任务已经被其他的工作线程偷走，则窃取这个小偷的工作队列内的任务（以FIFO方式），执行之，以期帮助它早日完成欲join的任务。 5、如果偷走任务的小偷也已经把自己的任务全部做完，正在等待需要join的任务时，则找到小偷的小偷，帮助它完成它的任务。 6、递归的执行第5步。 ForkJoinPool框架单个任务运行流程 从队列中获取任务图解 ForkJoinPool的默认线程数 ForkJoinPool同ThreadPoolExecutor一样，也实现了Executor和ExecutorService接口。它使用了一个无限队列来保存需要执行的任务，而线程的数量则是通过构造函数传入，如果指明线程数量，那么默认取值于当前计算机可用的CPU数。 注意点 ForkJoinPool在执行过程中，会创建大量的子任务，导致GC，这些是需要注意的。 代码示例 示例一个分段加法计算的例子 123456789101112131415161718192021222324252627282930313233343536373839public class SumTask extends RecursiveTask&lt;Long&gt; &#123; long[] data; int start; int end; public SumTask(long[] data, int start, int end)&#123; this.data = data; this.start = start; this.end = end; &#125; //只需实现compute逻辑 @Override protected Long compute() &#123; long sum = 0; // 切分任务。 if (end - start &lt; 1000)&#123; //最小任务，就做计算 for (int i = start; i &lt; end; i++)&#123; sum += data[i]; &#125; &#125;else&#123; int middle = (start + end) / 2; SumTask left = new SumTask(data, start, middle); SumTask right = new SumTask(data, middle + 1, end); invokeAll(left, right); // 这个技巧很重要，是的当前线程fork后能接着compute。默认是不compute了 left.fork(); right.fork(); sum = left.join() + right.join(); &#125; ... return sum; &#125;&#125; 1234567891011121314151617181920public class Demo &#123; public static void main(String[] args)&#123; long[] data = new long[1024*100]; Arrays.setAll(data, i-&gt;i); Date startTime = new Date(); SumTask sumTask = new SumTask(data,0, data.length - 1); long sum = new ForkJoinPool().invoke(sumTask); Date finishTime = new Date(); SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); System.out.println("开始时间：" + sf.format(startTime)); System.out.println("结束时间：" + sf.format(finishTime)); System.out.println("最终结果 sum = " + sum); &#125;&#125; 执行结果： 123456789101112131415161718...略Thread = ForkJoinPool-1-worker-5; start = 75200 end = 75999; sum = 60403601Thread = ForkJoinPool-1-worker-1; start = 0 end = 51199; sum = 1309030464Thread = ForkJoinPool-1-worker-2; start = 74400 end = 75199; sum = 59764401Thread = ForkJoinPool-1-worker-7; start = 76000 end = 76799; sum = 61042801Thread = ForkJoinPool-1-worker-4; start = 73600 end = 75199; sum = 118889602Thread = ForkJoinPool-1-worker-5; start = 75200 end = 76799; sum = 121446402Thread = ForkJoinPool-1-worker-4; start = 73600 end = 76799; sum = 240336004Thread = ForkJoinPool-1-worker-2; start = 70400 end = 76799; sum = 470444808Thread = ForkJoinPool-1-worker-6; start = 64000 end = 76799; sum = 899980816Thread = ForkJoinPool-1-worker-2; start = 51200 end = 76799; sum = 1636326432Thread = ForkJoinPool-1-worker-2; start = 51200 end = 102399; sum = 3927193664Thread = ForkJoinPool-1-worker-1; start = 0 end = 102399; sum = 5236224128 开始时间：2020-11-07 15:54:40结束时间：2020-11-07 15:54:58 最终结果 sum = 5236224128 2.7.2、CountDownLatch vs CyclicBarrier 2.7.2.1、CountDownLatch的用法 CountDownLatch典型用法1：某一线程A等待N个线程执行完毕后，再执行。 线程A将CountDownLatch的计数器初始化为n new CountDownLatch(n) ，做完该做的事情后，就countDownLatch.await() 每当一个任务线程执行完毕，就将计数器减1 countdownlatch.countDown() 当计数器的值变为0时，在CountDownLatch上 await() 的线程就会被唤醒。 一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行 1234567891011121314151617181920212223public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch = new CountDownLatch(10); for (int i=0; i&lt;9; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + " 运行"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; latch.countDown(); &#125; &#125; &#125;).start(); &#125; System.out.println("等待子线程运行结束"); latch.await(10, TimeUnit.SECONDS); System.out.println("子线程运行结束");&#125; CountDownLatch典型用法2：实现多个任务线程阻塞后同时执行 类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。 做法是主线程A初始化一个共享的CountDownLatch(1)，将其计数器初始化为1 多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒。 12345678910111213141516171819202122232425262728293031323334353637class MyRunnable implements Runnable &#123; private CountDownLatch countDownLatch; private CountDownLatch await; public MyRunnable(CountDownLatch countDownLatch, CountDownLatch await) &#123; this.countDownLatch = countDownLatch; this.await = await; &#125; @Override public void run() &#123; try &#123; countDownLatch.await(); System.out.println("子线程" +Thread.currentThread().getName()+ "处理自己事情"); Thread.sleep(1000); await.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(1); CountDownLatch await = new CountDownLatch(5); for (int i=0; i&lt; 5; i++) &#123; new Thread(new MyRunnable(countDownLatch, await)).start(); &#125; System.out.println("主线程处理自己事情"); Thread.sleep(3000); countDownLatch.countDown(); System.out.println("主线程处理结束"); await.await(); System.out.println("子线程处理完毕啦"); &#125; 2.7.2.2、CyclicBarrier代码示例 以装箱打包为例 1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) throws Exception&#123; /** * CyclicBarrier 有两个构造方法 parties 总计数，runnable是 现在执行前先执行的方法 * CyclicBarrier barrier = new CyclicBarrier(5); */ CyclicBarrier barrier = new CyclicBarrier(5, () -&gt; &#123; System.out.println("开始货物打包"); &#125;); ExecutorService executorPool = Executors.newCachedThreadPool(); /** * await提供了两个方法 * 1、await() * 2、await(long timeout, TimeUnit unit) 超时写法，且需捕获异常 TimeOutException */ for (int i = 0; i &lt; 11; i++) &#123; int num = i; Thread.sleep(1000); executorPool.execute(() -&gt; &#123; try &#123; System.out.println(num + "号货物，已准备好，等待打包"); //barrier2.await(2, TimeUnit.SECONDS); barrier.await(); System.out.println(num + "号货物，打包完成"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; executorPool.shutdown(); &#125; 2.7.3、CountedCompleter第一次看CountedCompleter，并不好理解。建议大家先掌握Fork / Join机制的ForkJoinTask和ForkJoinPool的工作原理后，再增量的补充CountedCompleter的差异点。 简单来说，相比ForkJoinTask： ForkJoinTask需阻塞的等待子任务完成，CountedCompleter不需要。主子任务的执行无顺序依赖，遵守Count计数即可。 CountedCompleter对于所有子任务执行完毕的感知更为快速（比ForkJoinTask的join()方法要简单、高效），对于 对于子任务结果合并，提供机制支持：每个任务结束时调用tryComplete，内部调用onCompletion合并结果。（前提，子任务节点本身要记录计算结果）。合并逻辑onCompletion可自定义。 即任务分解、计算、合并三者分离。 Java8的lambda并行流（findAny，mapReduce，foreach）就行基于Fork/Join框架实现的。CountedCompleter就是其中一个重要基类。 CountedCompleter是怎么执行的 ForkJoinPool会调用ForkJoinTask的doExec来执行任务，doExec方法如下： 123456789101112131415//ForkJoinPool.classfinal int doExec() &#123; int s; boolean completed; if ((s = status) &gt;= 0) &#123; try &#123; //CountedCompleter重载了exec方法，内部就是调用CountedCompleter的compute方法 completed = exec(); &#125; catch (Throwable rex) &#123; return setExceptionalCompletion(rex); &#125; if (completed) s = setCompletion(NORMAL); &#125; return s; &#125; 12345//CountedCompleter.classprotected final boolean exec() &#123; compute(); return false; &#125; 这样compute的逻辑就是任务的核心计算逻辑，会最终被pool调用 CountedCompleter的运行过程 我们把最开始new出来的任务称为根任务，根任务在执行过程中，又fork出2个子任务，子任务可能会fork出自己的子任务。一层层fork下去后，最终一定有一个任务是不会再fork的，这个任务称为叶子任务。整个任务体系就是一颗完全二叉树。 整个执行过程，最核心的属性是： pending：表示等待执行的任务 completer：表示任务的上级，即父任务 核心方法是tryComplete： 12345678910111213141516public final void tryComplete() &#123; CountedCompleter&lt;?&gt; a = this, s = a; for (int c;;) &#123; if ((c = a.pending) == 0) &#123; //如果当前任务完成(pending==0),执行完当前任务的完成动作(onCompletion)，传递到父任务 a.onCompletion(s); if ((a = (s = a).completer) == null) &#123; s.quietlyComplete(); return; &#125; &#125; //当前任务没有完成(pending!=0)，将pending-1 else if (U.compareAndSwapInt(a, PENDING, c, c - 1)) return; &#125;&#125; 整个执行过程如下图： 每个子任务都尝试tryComplete() 叶子任务的pending = 0，所以Complete是成功的，调用onCompletion方法终结自己任务。并取它的父任务，对父任务的pending做减1操作。减1操作会有2种情况 1、父任务减1后，父任务的pending仍大于0，那么就不做任何事，结束了 2、父任务建1后，父任务的pending等于0了，那么会继续取父任务的父任务进行减1操作，一直往上递归。 代码示例 另外可参看官方举例：https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/CountedCompleter.html foreach型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class CountedCompleterDemo &#123; interface Applier&lt;E&gt; &#123; void apply(E e); &#125; static class ForEach&lt;E&gt; extends CountedCompleter&lt;Void&gt; &#123; public static &lt;E&gt; void forEach(E[] array, Applier&lt;E&gt; op) &#123; new ForEach&lt;&gt;(null, array, op, 0, array.length).invoke(); &#125; final E[] array; final Applier&lt;E&gt; op; final int lo, hi; //p是父任务 ForEach(CountedCompleter&lt;?&gt; p, E[] array, Applier&lt;E&gt; op, int lo, int hi) &#123; super(p); this.array = array; this.op = op; this.lo = lo; this.hi = hi; &#125; @Override public void compute() &#123; if (hi - lo &gt;= 2) &#123; int mid = (lo + hi) &gt;&gt;&gt; 1; setPendingCount(2); // must set pending count before fork new ForEach(this, array, op, mid, hi).fork(); // right child new ForEach(this, array, op, lo, mid).fork(); // left child &#125; else if (hi &gt; lo)&#123; op.apply(array[lo]); &#125; //compute返回前，必然调tryComplete tryComplete(); &#125; &#125; public static void main(String[] args) throws Exception &#123; AtomicInteger sum = new AtomicInteger(); //自定义狗子方法就是是(element)-&gt;&#123;&#125; 这个函数式方法 ForEach.forEach(new Integer[]&#123;1, 2, 3, 4, 5, 6&#125;, (element) -&gt; &#123; sum.addAndGet(element); &#125;); System.out.println("相加之和：" + sum.get()); &#125;&#125; find one 型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class SearcherDemoTest &#123; @Test public void testSearchDemo()&#123; Integer[] array = new Integer[10000000]; for(int i = 0; i &lt; array.length; i++)&#123; array[i] = i; &#125; AtomicReference&lt;Integer&gt; result = new AtomicReference&lt;&gt;(); Integer find = new SearcherDemoTest.Searcher&lt;&gt;(null, array, result, 0, array.length - 1, this::match).invoke(); System.out.printf("查找结束，结果返回：%d, result:%d", find, result.get()); &#125; static class Searcher&lt;E&gt; extends CountedCompleter&lt;E&gt; &#123; final E[] array; final AtomicReference&lt;E&gt; result; final int lo, hi; final Function&lt;E, Boolean&gt; matcher; Searcher(CountedCompleter&lt;?&gt; p, E[] array, AtomicReference&lt;E&gt; result, int lo, int hi, Function&lt;E, Boolean&gt; matcher)&#123; super(p); this.array = array; this.result = result; this.lo = lo; this.hi = hi; this.matcher = matcher; &#125; @Override public void compute() &#123; int l = this.lo; int h = this.hi; while (result.get() == null &amp;&amp; h &gt;= l)&#123; if ((h - l) &gt;= 2)&#123; int mid = (l + h) &gt;&gt;&gt; 1; addToPendingCount(1); new SearcherDemoTest.Searcher&lt;E&gt;(this, array, result, mid, h, matcher).fork(); h = mid; &#125;else&#123; E x = array[l]; if (matcher.apply(x) &amp;&amp; result.compareAndSet(null, x))&#123; super.quietlyCompleteRoot(); &#125; break; &#125; &#125; if (null == result.get())&#123; tryComplete(); &#125; &#125; &#125; private boolean match(Integer x)&#123; boolean matchResult = x &gt; 2000000 &amp;&amp; x%2 == 0 &amp;&amp; x%3 == 0 &amp;&amp; x%5 == 0 &amp;&amp; x%7 == 0; return matchResult; &#125;&#125; 3、CAS学锁之前，必须先学CAS 3.1.1、CAS原理CAS操作在操作系统层面对应C语言汇编的CMPXCHG指令，该指令通过三个操作数（变量V，预期旧值O，目标新值N），能原子的完成“变量V当前值与预期旧值E的等值判断，并完成新值N的赋值”。 所有Atomic类内部都会调用Unsafe类完成CAS的操作 12345public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); Unsafe内部就是C语言实现与操作系统的交互了，最终会涉及到CPU级的操作。 CMPXCHG指令介绍 Unsafe的CompareAndSwap方法最终在 hotspot 源码实现中都会调用统一的 cmpxchg 函数。 cmpxchg 函数源码： 源码地址：hotspot/src/share/vm/runtime/Atomic.cpp 1234567891011121314151617181920212223242526jbyte Atomic::cmpxchg(jbyte exchange_value, volatile jbyte*dest, jbyte compare_value) &#123; assert (sizeof(jbyte) == 1,"assumption."); uintptr_t dest_addr = (uintptr_t) dest; uintptr_t offset = dest_addr % sizeof(jint); volatile jint*dest_int = ( volatile jint*)(dest_addr - offset); // 对象当前值 jint cur = *dest_int; // 当前值cur的地址 jbyte * cur_as_bytes = (jbyte *) ( &amp; cur); // new_val地址 jint new_val = cur; jbyte * new_val_as_bytes = (jbyte *) ( &amp; new_val); // new_val存exchange_value，后面修改则直接从new_val中取值 new_val_as_bytes[offset] = exchange_value; // 比较当前值与期望值，如果相同则更新，不同则直接返回 while (cur_as_bytes[offset] == compare_value) &#123; // 调用汇编指令cmpxchg执行CAS操作，期望值为cur，更新值为new_val jint res = cmpxchg(new_val, dest_int, cur); if (res == cur) break; cur = res; new_val = cur; new_val_as_bytes[offset] = exchange_value; &#125; // 返回当前值 return cur_as_bytes[offset];&#125; 多CPU如何实现原子操作 在计算机硬件层面，CPU 处理器速度远远大于主内存，为了解决速度差异，在两者之间架设了CPU多级缓存，如 L1、L2、L3 级别的缓存，这些缓存离CPU越近就越快，将频繁操作的数据缓存到这里，加快访问速度。 现在都是多核 CPU 处理器，每个 CPU 处理器内维护各自关于内存数据的缓存，当多线程并发读写时，就会出现CPU缓存数据不一致的情况。 对于原子操作，CPU处理器提供2种方式： 总线锁定 当一个处理器要操作共享变量时，在 BUS 总线上发出一个 Lock 信号，其他处理就无法操作这个共享变量了。 缺点很明显，总线锁定在阻塞其它处理器获取该共享变量的操作请求时，也可能会导致大量阻塞，从而增加系统的性能开销。 缓存锁定 后来的处理器都提供了缓存锁定机制，当某个处理器对缓存中的共享变量进行了操作，其他处理器会有个嗅探机制，将其他处理器的该共享变量的缓存失效，待其他线程读取时会重新从主内存中读取最新的数据，基于 MESI 缓存一致性协议来实现的。 现代的处理器基本都支持和使用的缓存锁定机制。 那若遇到V的值不等于A，怎么办？ 答：自旋循环 一般CAS的代码逻辑 1234567for(;;)&#123; current_value = get(); new_value = do something/nothing with current_value if (compareAndSet(current_value, new_value))&#123; return new_value; &#125;&#125; 若长时间不成功，CPU开销很大哦。 3.1.2、ABA问题ABA问题： CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。 解决思路： ABA问题的解决思路就是在value中添加版本号。例如：每次变量更新的时候都把版本号加1，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。 JDK从1.5开始提供了AtomicStampedReference（也是版本号思路）类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 3.1.3、原子性操作多个变量操作虽然原理很简单，但值得单列一章节 常规的Atomic原子变量，只能保证单个变量的原子性操作。但对于多个变量原子性操作的场景怎么应对呢？ 答案： Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 举例： 如果使用普通的对象引用，在多线程情况下进行对象的更新可能会导致不一致性。例如： 一个对象的初始状态为 name=Tom, age = 18。 在 线程1 中将 name 修改为 Tom1，age + 1。 在 线程2 中将 name 修改为 Tom2，age + 2。 123456789101112131415class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; ... //省去get/set方法 public String toString() &#123; return "[name: " + this.name + ", age: " + this.age + "]"; &#125;&#125; 普通引用版本 123456789101112131415161718192021222324252627282930313233343536// 普通引用private static Person person;public static void main(String[] args) throws InterruptedException &#123; person = new Person("Tom", 18); System.out.println("Person is " + person.toString()); Thread t1 = new Thread(new Task1()); Thread t2 = new Thread(new Task2()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println("Now Person is " + person.toString());&#125;static class Task1 implements Runnable &#123; public void run() &#123; person.setAge(person.getAge() + 1); person.setName("Tom1"); System.out.println("Thread1 Values " + person.toString()); &#125;&#125;static class Task2 implements Runnable &#123; public void run() &#123; person.setAge(person.getAge() + 2); person.setName("Tom2"); System.out.println("Thread2 Values " + person.toString()); &#125;&#125; 可能的结果输出： 1234Person is [name: Tom, age: 18]Thread2 Values [name: Tom1, age: 21]Thread1 Values [name: Tom1, age: 21]Now Person is [name: Tom1, age: 21] 原子对象引用版本 12345678910111213141516171819202122232425262728293031323334353637// 普通引用private static Person person;// 原子性引用private static AtomicReference&lt;Person&gt; aRperson;public static void main(String[] args) throws InterruptedException &#123; person = new Person("Tom", 18); aRperson = new AtomicReference&lt;Person&gt;(person); System.out.println("Atomic Person is " + aRperson.get().toString()); Thread t1 = new Thread(new Task1()); Thread t2 = new Thread(new Task2()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println("Now Atomic Person is " + aRperson.get().toString());&#125;static class Task1 implements Runnable &#123; public void run() &#123; aRperson.getAndSet(new Person("Tom1", aRperson.get().getAge() + 1)); System.out.println("Thread1 Atomic References " + aRperson.get().toString()); &#125;&#125;static class Task2 implements Runnable &#123; public void run() &#123; aRperson.getAndSet(new Person("Tom2", aRperson.get().getAge() + 2)); System.out.println("Thread2 Atomic References " + aRperson.get().toString()); &#125;&#125; 4、Java中的锁4.1、那些“锁”的分类如上文所述，Java中提供了种类丰富的锁，每种锁各有特性和适用的场景。 Java中的是根据其是否表现为某一特性来定义锁，下图是一张很棒的分类图： 故，我们能得到Java中常见的锁分类名称： 悲观锁 vs 乐观锁 自旋锁 偏向锁 vs 轻量级锁 vs 重量级锁 公平锁 vs 非公平锁 可重入锁 排他锁 vs 共享锁 4.2、乐观锁 vs 悲观锁乐观锁与悲观锁是一种线程并发竞争资源的态度和策略。 对于同一个临界数据的并发操作： 悲观锁 认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 乐观锁 认为自己在使用数据时比较小概率会有其他线程并发修改数据，所以不添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 乐观锁在Java中是通过使用无锁编程来实现的，最常采用的是CAS算法。 根据从上面两者的特点我们可以发现： 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 4.3、自旋锁 vs 适应性自旋锁在介绍自旋锁前，需要先铺垫一点前提知识： 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费CPU时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。 而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。 这就是自旋锁。 注意： 自旋等待虽然避免了线程切换的开销，但它要占着CPU。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，那么自旋的线程只会白浪费处理器资源。 所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。 自适应自旋锁 自旋锁在JDK1.4中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。 如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 4.4、偏向锁 vs 轻量级锁 vs 重量级锁这四种锁是指锁的状态，专门针对synchronized的。 按照惯例，在介绍这四种锁状态之前需要介绍一些额外的知识铺垫。 4.4.1、为什么Synchronized能实现线程同步在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。 【Java对象头】 —— 放锁的 synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就存在Java对象头里的，那Java对象头又是什么呢？ 以Hotspot为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。 Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 【Monitor】 —— 实现线程间同步 Monitor其实是一种同步工具，也可以说是一种同步机制，它通常被描述为一个对象，主要特点是： Monitor对象的所有方法都被“互斥”的执行。好比一个Monitor只有一个运行“许可”，任一个线程进入任何一个方法都需要获得这个“许可”，离开时把许可归还。 通常提供singal机制：允许正持有“许可”的线程暂时放弃“许可”，等待某个谓词成真（条件变量），而条件成立后，当前进程可以“通知”正在等待这个条件变量的线程，让他可以重新去获得运行许可。 Monitor对象可以被多线程安全地访问。 重点：synchronized通过Monitor来实现线程同步。Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。 这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。 这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。 JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前synchronized一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 四种锁状态对应的的Mark Word内容： 锁状态 存储内容 存储内容 无锁 对象的hashCode、对象分代年龄、是否是偏向锁（0） 01 偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 通过上面对synchronized的加锁机制以及相关知识的铺垫，下面我们分别讲解四种锁状态的思路以及特点： 4.4.2、JDK1.6对synchronized的优化JDK1.6中对synchronized的实现引入了大量的优化来减少锁操作的开销： 锁粗化（Lock Coarsening）：将多个连续的锁扩展成一个范围更大的锁，用以减少频繁互斥同步导致的性能损耗。 锁消除（Lock Elimination）：JVM及时编译器在运行时，通过逃逸分析，如果判断一段代码中，堆上的所有数据不会逃逸出去从来被其他线程访问到，就可以去除这些锁。 偏向锁（Biased Locking）：JDK1.6引入。目的是消除数据再无竞争情况下的同步原语。使用CAS记录获取它的线程。下一次同一个线程进入则偏向该线程，无需任何同步操作。 轻量级锁（Lightweight Locking）：JDK1.6引入。在没有多线程竞争的情况下避免重量级互斥锁，只需要依靠一条CAS原子指令就可以完成锁的获取及释放。 适应性自旋（Adaptive Spinning）：为了避免线程频繁挂起、恢复的状态切换消耗。产生了忙循环（循环时间固定），即自旋。JDK1.6引入了自适应自旋。自旋时间根据之前锁自旋时间和线程状态，动态变化，用以期望能减少阻塞的时间。 锁升级：偏向锁–》轻量级锁–》重量级锁 4.4.3、无锁无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。 如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。 上面我们介绍的CAS原理及应用即是无锁的一种实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 4.4.4、偏向锁为了优化synchronized的性能，Hotspot的作者经过研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。 当一个线程访问同步块并获取锁时，会在对象头的Mark Word里记录锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。 偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着 如果线程不处于活动状态，则将对象头设置成无锁状态， 如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，进而使用轻量级锁，最后唤醒暂停的线程。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 4.4.5、轻量级锁 当锁是偏向锁的时，被另外的线程所访问，偏向锁就会升级为轻量级锁。其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而（不切换CPU）提高性能。 轻量级锁-加锁： 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录（Lock Record）的空间，并将对象头中的Mark Word复制到锁记录中（官方称为Displaced Mark Word）。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。 【加锁成功】如果成功，当前线程获得锁 【加锁失败】如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。而当自旋一定条件后还未获得锁，这个竞争线程就会把对象的锁状态改成“重量级锁”。 轻量级锁-解锁： 轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 如上图所示，加锁和锁升级逻辑： 第二步，如果Mark Word不是自己的ThreadId,锁升级，这时候，用CAS来执行切换，新的线程根据Mark Word里面现有的ThreadId，通知之前线程暂停，之前线程将Mark Word的内容置为空。 第三步，两个线程都把对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作，把共享对象的Mark Word的内容修改为自己新建的记录空间的地址的方式竞争Mark Word. 第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋. 第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于轻量级锁的状态，如果自旋失败进入第六步 第六步，进入重量级锁的状态，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己. 4.4.6、重量级锁升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 重量级锁通过对象内部的Monitor实现（上文有铺垫），其中Monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。 4.4.7、综上JVM对Synchronized的优化，简单来说解决三种场景： 1）只有一个线程进入临界区：偏向锁。 通过test Mark Word解决加锁问题，无需执行CAS操作 2）多个线程交替进入临界区：轻量级锁。 通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能 3）多线程同时进入临界区：重量级锁 4.5、公平锁 vs 非公平锁公平锁 公平锁是指多个线程按照申请锁的顺序逐序获取到锁 原理：暂未获取到锁的线程直接进入队列（FIFO）中排队，然后按排队顺序逐个传递着获取到锁。 优点：等待锁的线程不会饿死。 缺点：整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁 非公平锁是多个线程加锁时直接尝试竞争获取锁，若获取到锁，此线程可以无需阻塞直接执行同步代码，获取不到锁时会到等待队列（FIFO）的队尾等待。 优点：因为部分节省CPU切换的损耗，相比公平锁吞吐量较好。 缺点：处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 关于等待队列，回忆下前文介绍的JUC中的AQS机制（AbstractQueuedSynchronizer），就是它提供的实现 接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。 ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。 它有公平锁FairSync和非公平锁NonfairSync两个子类。 ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。 下面我们来看一下公平锁与非公平锁的加锁方法的源码: 通过上图中的源代码对比，我们可以明显的看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。 再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。 综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。 4.6、独享锁(排他锁) vs 共享锁独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。获得排它锁的线程即能读数据又能修改数据。 JDK中的synchronized、JUC中Lock的都是独享锁。 共享锁是指该锁可被多个线程所持有。获得共享锁的线程只能读数据，不能修改数据。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 下图为ReentrantReadWriteLock的部分源码： 我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。因为读锁和写锁是分离的，更细粒度的控制，使得ReentrantReadWriteLock的并发性相比一般的独享锁有了很大提升。 那读锁和写锁的具体加锁方式有什么区别呢？ 在上文AQS提及的state字段（int类型，32位），该字段用来描述有多少线程获持有锁。 在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数） 在共享锁中state就是持有锁的数量。 但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量，于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示： 了解了概念之后我们再来看代码 先看写锁的加锁源码： 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); // 取到当前锁的个数 int w = exclusiveCount(c); // 取写锁的个数w if (c != 0) &#123; // 如果已经有线程持有了锁(c!=0) // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；或者如果通过CAS增加写线程数失败也返回失败。 return false; setExclusiveOwnerThread(current); // 如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者 return true;&#125; 这段代码首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁(c!=0)，则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败。 如果c=0,w=0或者c&gt;0,w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！ 接着是读锁的代码： 123456789101112131415161718192021222324252627protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。 如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。 4.7、锁消除JVM会加锁的代码进行逃逸分析，当发现是单线程时，会去掉代码所加的锁，以达到优化的目的。 synchronized采取了此策略。 5、多线程场景编码5.1、常见线程创建写法5.1.1、（推荐）利用ThreadPoolExecutor 使用ThreadPoolExecutor，按具体场景细细琢磨下线程池的各个参数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Testpublic void demoThreadPoolExecutor()&#123; //细细琢磨下各个参数设置 ThreadPoolExecutor threadPool = new ThreadPoolExecutor( 3, 5, 30, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(20), (new ThreadFactoryBuilder()).setNameFormat("child-request-thread-%d").build(), new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 0; i &lt; 50; i++)&#123; threadPool.execute(() -&gt; &#123; // 注意点： //1、execute里是个Runable方法，简单的可以这么函数式的写。复杂的就单独实现Runnable类。 //2、execute负责将任务提交到队列，就返回了 System.out.println("线程名：" + Thread.currentThread().getName()); &#125;); &#125; System.out.println("关闭线程池"); threadPool.shutdown();&#125;运行结果：线程名：child-request-thread-0线程名：child-request-thread-1线程名：child-request-thread-2线程名：child-request-thread-0线程名：child-request-thread-2线程名：child-request-thread-0线程名：child-request-thread-1线程名：child-request-thread-0线程名：child-request-thread-2 《《《 CorePoolSize 是3个线程名：child-request-thread-0线程名：child-request-thread-1线程名：child-request-thread-0线程名：child-request-thread-0线程名：child-request-thread-0线程名：child-request-thread-2线程名：child-request-thread-0线程名：child-request-thread-4 《《《 当队列满了后，增加线程到MaxPoolSize5个线程名：child-request-thread-1线程名：child-request-thread-3线程名：child-request-thread-1线程名：child-request-thread-4线程名：child-request-thread-0线程名：main 《《《队列满了，线程最大了，还有任务进来，采取的是CallerRun策略线程名：child-request-thread-2线程名：main线程名：child-request-thread-0线程名：child-request-thread-4线程名：child-request-thread-1线程名：child-request-thread-3线程名：child-request-thread-3线程名：child-request-thread-1线程名：child-request-thread-4线程名：child-request-thread-0关闭线程池线程名：child-request-thread-2线程名：child-request-thread-0线程名：child-request-thread-4线程名：child-request-thread-1线程名：child-request-thread-3线程名：child-request-thread-1线程名：child-request-thread-4线程名：child-request-thread-0线程名：child-request-thread-2线程名：child-request-thread-0线程名：child-request-thread-4线程名：child-request-thread-1线程名：child-request-thread-3线程名：child-request-thread-1线程名：child-request-thread-4线程名：child-request-thread-0线程名：child-request-thread-2 ThreadFactoryBuilder 用的是google guava的实现类 5.1.2、利用Executors 12345678910111213141516171819202122232425262728293031323334public class ExecutorsDemo &#123; @Test public void demo()&#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++)&#123; // 注意点： //1、execute里是个Runable方法，简单的可以这么函数式的写。复杂的就单独实现Runnable类。 //2、execute负责将任务提交到队列，就返回了 fixedThreadPool.execute(() -&gt; &#123; System.out.println("线程名：" + Thread.currentThread().getName()); &#125;); &#125; System.out.println("关闭线程池"); //shutdown()方法解释 //1、不会立即结束，当方法返回时并不一定真的完全关闭了 //2、此时不再接收新任务 //3、尝试关闭线程，但仅会关闭1个。当shutdown返回后，线程池里可能还会存在worker fixedThreadPool.shutdown(); &#125;&#125;运行结果：线程名：pool-1-thread-1关闭线程池 《《《 这个就是shutdown()方法特点的证明线程名：pool-1-thread-1线程名：pool-1-thread-3线程名：pool-1-thread-2线程名：pool-1-thread-3线程名：pool-1-thread-1线程名：pool-1-thread-3线程名：pool-1-thread-2线程名：pool-1-thread-3线程名：pool-1-thread-1 其他Executors类里的newSingleThreadExecutor、newCachedThreadPool、newScheduledThread，写法都一样。 5.2、等待所有线程结束 / 优雅关闭线程池经典关闭线程池代码 123456ExecutorService executorService = Executors.newFixedThreadPool(10);executorService.shutdown();while (!executorService.awaitTermination(10, TimeUnit.SECONDS)) &#123; System.out.println("线程池中还有任务在处理");&#125; 结论：【重点】【重点】【重点】shutdown()只会尝试终止1个worker，方法就返回了。当执行shutdown()时，线程池里有多个worker时，待shutdown()返回时，其实线程池里还是有worker在运行着。 为什么shutdown()不够？ 看看shutdown做了什么 123456789101112131415161718public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 线程安全性检查 checkShutdownAccess(); // 更新线程池状态为 SHUTDOWN advanceRunState(SHUTDOWN); // 尝试关闭空闲线程 interruptIdleWorkers(); // 空实现 onShutdown(); &#125; finally &#123; mainLock.unlock(); &#125; // 尝试中止线程池 tryTerminate();&#125; tryTerminate 做了什么？ 这个只是尝试将线程池的状态置为 TERMINATE 态，如果还有worker在执行，则尝试关闭一个worker。 1234567891011121314151617181920212223242526272829303132333435final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); if (isRunning(c) || // 是运行态 runStateAtLeast(c, TIDYING) || // 是 TIDYING 或者 TERMINATE 态 (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) // SHUTDOWN 态且队列中有任务 return; if (workerCountOf(c) != 0) &#123; // 还存在 worker，则尝试关闭一个worker interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 通过CAS，先置为 TIDYING 态 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; // TIDYING 态 try &#123; // 空方法 terminated(); &#125; finally &#123; // 最终更新为 TERMINATED 态 ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; 通过如下的方法简单做一些过滤。因为状态是从 TIDYING 态往后才到 TERMINATE 态。从这个过滤条件，可以看出如果是STOP态也是会通过的。不过如果线程池到了STOP应该就不会再使用了吧，所以也是不会有什么影响。 1234if (isRunning(c) || // 是运行态runStateAtLeast(c, TIDYING) || // 是 TIDYING 或者 TERMINATE 态(runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) // SHUTDOWN 态且队列中有任务 return; 如果该线程池中有worker，则中止1个worker。通过上面的过滤条件，到了这一步，那么肯定是 SHUTDOWN 态（忽略 STOP 态），并且任务队列已经被处理完成。 12345if (workerCountOf(c) != 0) &#123; // 还存在 worker，则尝试关闭一个worker interruptIdleWorkers(ONLY_ONE); return;&#125; 如果该线程池中有多个worker，终止1个worker之后 tryTerminate() 方法就返回了，那么剩下的worker在哪里被处理的呢？（看后面的解答） 假设线程池中的worker都已经关闭并且队列中也没有任务，那么后面的代码将会将线程池状态置为 TERMINATE 态。terminate() 是空实现，用于有需要的自己实现处理，线程池关闭之后的逻辑。 awaitTermination 做了什么 这个方法只是判断当前线程池是否为 TERMINATED 态，如果不是则睡眠指定的时间，如果睡眠中途线程池变为终止态则会被唤醒。这个方法并不会处理线程池的状态变更的操作，纯粹是做状态的判断，所以得要在循环里边做判断。 1234567891011121314151617public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (;;) &#123; if (runStateAtLeast(ctl.get(), TERMINATED)) // 是否为 TERMINATED 态 return true; if (nanos &lt;= 0) return false; nanos = termination.awaitNanos(nanos); // native 方法，睡一觉 &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; 问题 从 shutdown() 方法源码来看有很大概率没有完全关闭线程池，而awaitTermination() 方法则只是判断线程池状态，并没有关闭线程池状态，那么剩下的worker什么时候促发关闭呢？ 关键代码逻辑在一个worker被关闭之后，触发了哪些事情。 runWorker 123456789101112131415161718192021222324final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // 省略其他不需要的代码 try&#123; task.run(); &#125; finally &#123; task = null; w.unlock(); &#125; &#125; // 用于标识是否是task.run报错 completedAbruptly = false; &#125; finally &#123; // 线程关闭的时候调用 processWorkerExit(w, completedAbruptly); &#125;&#125; completedAbruptly：用于标识是否是task.run报错，如果值为 TRUE，则是task.run 异常；反之，则没有发生异常 从上面的核心代码来看，当一个worker被关闭之后会调用 processWorkerExit() 方法。看看它做了什么。 processWorkerExit 做了什么 对一个worker退出之后做善后工作，比如统计完成任务数，将线程池的关闭态传播下去，根据条件补充 worker。 123456789101112131415161718192021222324252627private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 如果有worker则尝试关闭一个，否则置为TERMINATE态 tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125;&#125; 线程池关闭的关键就在于一个worker退出之后，会调用 tryTerminate() 方法，将退出的信号传递下去，这样其他的线程才能够被依次处理，最后线程池会变为 TERMINATE 态。 5.3、获取线程执行结果5.3.1、Callable &amp; Future一个例子同时说明：Future、FutureTask、Callable 【Interface】Callable：与Runnable对比，具有返回值能力。 【Interface】Future：与Callable搭配，是装线程返回结果的接口类，是个Interface。注意：future.get()是阻塞方法，直到对应的线程任务运行结束。 【Class】FutureTask：Future Interface的实现类。 代码例子： 12345678910111213141516171819202122232425262728293031323334@Testpublic void demoCallable() throws ExecutionException, InterruptedException &#123; ThreadPoolExecutor threadPool = new ThreadPoolExecutor(3, 5, 30, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(20), (new ThreadFactoryBuilder()).setNameFormat("child-request-thread-%d").build(), new ThreadPoolExecutor.CallerRunsPolicy()); //提交任务 List&lt;Future&lt;Integer&gt;&gt; resultList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 50; i++) &#123; //submit是异步提交 Future&lt;Integer&gt; result = threadPool.submit(new IntegerCallable(i)); resultList.add(result); &#125; //等待线程池执行完所有任务 threadPool.shutdown(); while (!threadPool.awaitTermination(10, TimeUnit.SECONDS)) &#123; System.out.println("线程池中还有任务在处理"); &#125; //获取执行完成的结果 for (int i = 0; i &lt; resultList.size(); i++) &#123; Future&lt;Integer&gt; result = resultList.get(i); if (result.isDone())&#123; System.out.printf("Task %d is done. value = %d \n", i, result.get()); &#125;else&#123; System.out.printf("Task %d is not execute \n", i); &#125; &#125;&#125; 5.4、【重点】CompletableFuture从Future模式的缺点说起： Future虽然可以实现获取异步执行结果的需求，但是它没有提供通知的机制，我们无法得知Future什么时候完成。 要么使用阻塞，在future.get()的地方等待future返回的结果，这时又变成同步操作。要么使用isDone()轮询地判断Future是否完成，这样会耗费CPU的资源。 Java 8新增的CompletableFuture类正是吸收了所有Google Guava中ListenableFuture和SettableFuture的特征，还提供了其它强大的功能，让Java拥有了完整的非阻塞编程模型：Future、Promise 和 Callback(在Java8之前，只有无Callback 的Future)。 回调执行方面： CompletableFuture能将回调放到与主任务线程外的其他线程中异步的执行 CompletableFuture也能将回调放在主任务线程汇总继续同步的执行。 它避免了传统回调最大的问题，那就是能够将控制流分离到不同的事件处理器中。 结果等待方面： CompletableFuture弥补了Future模式的缺点。在异步的任务完成后，无需等待。可以直接通过thenAccept、thenApply、thenCompose等方式将前面异步处理的结果交给另外一个异步事件处理线程来处理。 CompletableFuture 处理非阻塞调用的传统方法是使用事件处理器，程序员为任务完成之后要出现的动作注册一个处理器。但是，要尝试在一组事件处理器中实现一个控制流会很困难。 CompletableFuture提供了一种候选方法，与事件处理器不同，CompletableFuture可以组合。利用CompletableFuture，可以指定希望做什么，以及希望以什么顺序执行这些工作。这些动作不会立即发生，不过重要的是将所有代码放在一起。 CompletableFuture提供了非常强大的 Future 的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合 CompletableFuture 的方法。 对于阻塞或者轮询方式，依然可以通过 CompletableFuture 类的 CompletionStage 和 Future 接口方式支持。 CompletableFuture 类声明了 CompletionStage 接口，CompletionStage 接口实际上提供了同步或异步运行计算的舞台，所以我们可以通过实现多个 CompletionStage 命令，并且将这些命令串联在一起的方式实现多个命令之间的触发。 CompletableFuture的特性： 方法名 描述 runAsync(Runnable runnable) 使用ForkJoinPool.commonPool()作为它的线程池执行异步代码。 runAsync(Runnable runnable, Executor executor) 使用指定的thread pool执行异步代码。 supplyAsync(Supplier supplier) 使用ForkJoinPool.commonPool()作为它的线程池执行异步代码，异步操作有返回值 supplyAsync(Supplier supplier, Executor executor) 使用指定的thread pool执行异步代码，异步操作有返回值 runAsync 和 supplyAsync 方法的区别是runAsync返回的CompletableFuture是没有返回值的。 而supplyAsync返回的CompletableFuture是有返回值的，下面的代码打印了future的返回值。 代码示例： 5.4.1、【回调型】thenApply、thenApplyAsync、以及子任务串联1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Testpublic void demoSupplyAsync() throws ExecutionException, InterruptedException &#123; //不指定线程池，默认使用ForkJoinPool里的commonPool CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(new Supplier&lt;String&gt;() &#123; @Override public String get() &#123; //延长2秒，观察阻塞点 TimeUnit.SECONDS.sleep(2); String name = Thread.currentThread().getName(); System.out.println("子线程名字： " + name); return name + " hello"; &#125; &#125;); System.out.println("......mark 1......"); //【细节】子任务与子任务的串联。future2依赖future1的结果再执行。 CompletableFuture&lt;String&gt; future2 = future1.thenApplyAsync(new Function&lt;String, String&gt;() &#123; //thenApplyAsync是在线程池中异步执行 @Override public String apply(String s) &#123; String name = Thread.currentThread().getName(); System.out.println("线程名字： " + name + " 入参：" + s); return s + " world"; &#125; &#125;).thenApply(new Function&lt;String, String&gt;() &#123; //thenApply是在主线程中执行 @Override public String apply(String s) &#123; String name = Thread.currentThread().getName(); System.out.println("线程名字： " + name + "线程. 入参：" + s); return s + " Oh!"; &#125; &#125;); //观察阻塞点 TimeUnit.SECONDS.sleep(5); System.out.println("......mark 2......"); System.out.println("主线程：" + future2.get());&#125;运行结果：......mark 1......子线程名字： ForkJoinPool.commonPool-worker-1线程名字： ForkJoinPool.commonPool-worker-1 入参：ForkJoinPool.commonPool-worker-1 hello线程名字： ForkJoinPool.commonPool-worker-1线程. 入参：ForkJoinPool.commonPool-worker-1 hello world......mark 2......主线程：ForkJoinPool.commonPool-worker-1 hello world Oh! 《《《 注：future2是thenApply，在主线程上执行，因为此时主线程sleep中，故是在主线程sleep(5)后执行。 5.4.2、【消费型】thenAcceptthenAccept只对结果执行Action，而不返回新的计算值。 123456789public CompletableFuture&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action) &#123; return uniAcceptStage(null, action); &#125;public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBoth( CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action) &#123; return biAcceptStage(null, other, action); &#125; 代码例子： 12345678910111213141516171819@Testpublic void demoThenAccept() throws ExecutionException, InterruptedException &#123; CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; &#123; return "hello";&#125;); CompletableFuture&lt;Void&gt; future2 = future1.thenAccept(new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println("future2 线程名字： " + Thread.currentThread().getName()); System.out.println("future2 accept input： " + s); &#125; &#125;); System.out.println("future 2 get() = " + future2.get());&#125;运行结果：future2 线程名字： mainfuture2 accept input： hellofuture 2 get() = null 5.4.3、【消费型】thenRunthenRun更彻底地，下面一组方法当计算完成的时候会执行一个Runnable，与thenAccept不同，Runnable并不使用CompletableFuture计算的结果。 1234567891011public CompletableFuture&lt;Void&gt; thenRun(Runnable action) &#123; return uniRunStage(null, action); &#125;public CompletableFuture&lt;Void&gt; runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action) &#123; return biRunStage(null, other, action); &#125;public CompletableFuture&lt;Void&gt; runAfterEither(CompletionStage&lt;?&gt; other, Runnable action) &#123; return orRunStage(null, other, action); &#125; 5.4.4、【批量】allOf / anyOf将一堆CompletableFuture放一个集合中，然后等待整个集合的Future全部结束的方法 1234567public static CompletableFuture&lt;Void&gt; allOf(CompletableFuture&lt;?&gt;... cfs) &#123; return andTree(cfs, 0, cfs.length - 1); &#125;public static CompletableFuture&lt;Object&gt; anyOf(CompletableFuture&lt;?&gt;... cfs) &#123; return orTree(cfs, 0, cfs.length - 1); &#125; 代码例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243@Testpublic void demoAllOf() throws ExecutionException, InterruptedException &#123; CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(new Supplier&lt;String&gt;() &#123; @Override public String get() &#123; TimeUnit.SECONDS.sleep(1); String name = Thread.currentThread().getName(); System.out.println("子线程名字： " + name); return name; &#125; &#125;); CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(new Supplier&lt;String&gt;() &#123; @Override public String get() &#123; TimeUnit.SECONDS.sleep(2); String name = Thread.currentThread().getName(); System.out.println("子线程名字： " + name); return name; &#125; &#125;); CompletableFuture&lt;String&gt; future3 = CompletableFuture.supplyAsync(new Supplier&lt;String&gt;() &#123; @Override public String get() &#123; TimeUnit.SECONDS.sleep(4); String name = Thread.currentThread().getName(); System.out.println("子线程名字： " + name); return name; &#125; &#125;); //三个future打成一个集合 CompletableFuture futureAll = CompletableFuture.allOf(future1, future2, future3); System.out.println("...waiting..."); //等待所有结合统一结束 futureAll.get(); System.out.println("...done...");&#125; 5.4.5、【总览】CompletableFuture有多强大CompletableFuture有多强大，查看它全部方法就知道了。 前几个章节介绍了CompletableFuture的常见用法，其余的能力靠大家按需去挖掘了。 总的来说，CompletableFuture是优选、第一选择！有什么多线程编程方面的需要，优先在这里查找能力。 5.5、Guava提供的那些Future价值：Future同步等待获取结果的写法更优雅，响应更及时了。免去了low low的while自旋等待。 ListenableFuture 类 123public interface ListenableFuture&lt;V&gt; extends Future&lt;V&gt; &#123; void addListener(Runnable var1, Executor var2);&#125; 类名 特点 ListenableFuture 支持Listener形式，处理任务的执行结果 SettableFuture 异步执行时的同步等待执行结果。主子线程的优雅协同。支持Listener CheckedFuture 支持get方法抛出异常 ForwardingListenableFuture （Forwarding）装饰者模式，支持Future链式传递 ForwardingCheckedFuture （Forwarding）装饰者模式，支持Future链式传递 5.5.1、SettableFutureSettableFuture可以认为是一种异步转同步的工具。 代码示例： 1234567891011121314151617181920212223242526272829303132@Testpublic void SettableFutureDemo()&#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); //创建SettableFuture final SettableFuture settableFuture = SettableFuture.create(); fixedThreadPool.submit(() -&gt; &#123; String threadName = Thread.currentThread().getName(); System.out.println("线程内 sleep 5秒"); TimeUnit.SECONDS.sleep(5); System.out.println("线程内 sleep 结束"); //任务线程内手动设置结果 settableFuture.set(threadName); return threadName; &#125;); try &#123; System.out.println("main线程开始 future.get()"); //任务线程内的SettableFuture未被set()前，get()会阻塞等待。 String threadName = (String) settableFuture.get(); System.out.println("main线程打印任务线程名称： " + threadName); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; fixedThreadPool.shutdown();&#125; 5.5.2、ListenableFuture1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Testpublic void ListenableFutureDemo() throws InterruptedException &#123; ListeningExecutorService listeningExecutor = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(3)); final ListenableFuture&lt;String&gt; listenableFuture = listeningExecutor.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; System.out.println("任务线程执行..."); TimeUnit.SECONDS.sleep(1); return Thread.currentThread().getName(); &#125; &#125;); //2种方法执行回调处理 //方法一 listener型// listenableFuture.addListener(new Runnable() &#123;// @Override// public void run() &#123;// try &#123;// System.out.println("任务线程返回的结果： " + listenableFuture.get());// &#125; catch (InterruptedException e) &#123;// e.printStackTrace();// &#125; catch (ExecutionException e) &#123;// e.printStackTrace();// &#125;// &#125;// &#125;, listeningExecutor); //【推荐】方法二 callback型 Futures.addCallback(listenableFuture, new FutureCallback&lt;String&gt;() &#123; @Override public void onSuccess(String result) &#123; System.out.println("callback success, result = " + result); &#125; @Override public void onFailure(Throwable t) &#123; System.out.println("callback failure, error = " + t.getMessage()); &#125; &#125;); //等待任务执行完毕。 TimeUnit.SECONDS.sleep(5); listeningExecutor.shutdown();&#125; 5.5.3、同步+监听123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Testpublic void SettableListenFutureDemo() throws InterruptedException &#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5); //还是settableFuture，因为其实现了ListenableFuture final SettableFuture settableFuture = SettableFuture.create(); //设置listener settableFuture.addListener(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println("listen success, result = " + settableFuture.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, fixedThreadPool); //提交任务 fixedThreadPool.submit(() -&gt; &#123; System.out.println("任务线程执行..."); String name = Thread.currentThread().getName(); settableFuture.set(name); TimeUnit.SECONDS.sleep(1); return name; &#125;); //同步等待任务执行完毕，然后会自动执行listener try &#123; System.out.println("main线程开始 future.get()"); settableFuture.get(); System.out.println("main线程开始 future.get() 完毕"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; fixedThreadPool.shutdown();&#125;代码运行结果：main线程开始 future.get()任务线程执行...main线程开始 future.get() 完毕listen success, result = pool-1-thread-1 5.5.4、AsyncFunction再进一步，拿到执行结果后，异步的处理（非main线程） 我们调用ListenableFuture.get方法取回AsyncFunction接口处理后的结果。当我们想要异步地执行转换逻辑，而不是阻塞的调用(虽然任务还没有完成的时候调用Future.get方法会阻塞)的时候，可以使用AsyncFunction接口。但是AsyncFunction接口并不会异步的执行转换逻辑；而只是返回一个Future实例。 看看下面代码例子： 123456789101112131415161718192021public class AsyncFuntionSample implements AsyncFunction&lt;Long,String&gt; &#123; private ConcurrentMap&lt;Long,String&gt; map = Maps.newConcurrentMap(); private ListeningExecutorService listeningExecutorService; @Override public ListenableFuture&lt;String&gt; apply(final Long input) throws Exception &#123; if(map.containsKey(input)) &#123; SettableFuture&lt;String&gt; listenableFuture = SettableFuture.create(); listenableFuture.set(map.get(input)); return listenableFuture; &#125;else&#123; return listeningExecutorService.submit(new Callable&lt;String&gt;()&#123; @Override public String call() throws Exception &#123; String retrieved = service.get(input); map.putIfAbsent (input,retrieved); return retrieved; &#125; &#125;); &#125;&#125; 我们这个类实现AsyncFunction接口，并且包含一个ConcurrentHashMap实例。当我们调用apply方法时，我们会首先查看下map中有没有这个值，输入对象作为key。如果我们在map中找到值，我们使用SettableFuture类构造出Future对象，并且设置为从map中取出的对象。否则，我们返回提交Callable给ExecutorService放回的Future对象。同样也会放置返回的值到map中去。 5.6、“分治”机制 见上文 2.7章节的“Fork / Join 机制”]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术团队该有的工作观]]></title>
    <url>%2F2020%2F10%2F19%2F%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E8%AF%A5%E6%9C%89%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%A7%82%2F</url>
    <content type="text"><![CDATA[即使是技术类工作，除了“专业能力过硬”，以下软素质同样重要！ 1. 认真负责 不把“出了问题谁负责”挂在嘴边，相反，“就这么干，出了事我负责”更具备leader的潜质 交给ta的任何事情，能够拿到结果，如果每件小事都能让人放心。就问你，你踏实不踏实？ 不推三阻四，很少下意识的“找借口”，如果每次沟通都反馈“不是我”、“我没有”。就问你，你气不气？ 2. 自驱力强 不事事等别人交代，不是“要我做xxxx”，而是“我要做xxxx” 主动承担分外的事情，能提高整体效率的事情，例如：将一些每次都手动执行的查找bug命令脚本化，其实并没有人要求ta这么做。就问你，你暖不暖？ 不简单只为“工资”工作，不“一个经验用N年”，而是主动学习，积极进取 3. 主动沟通 碰到困难，主动和团队同学沟通，不是一股脑闷头干，每次到deadline才反馈有问题的同事。就问你，你怕不怕？ 沟通讲究“主动”，带着方案，当面沟通 沟通讲究“高效”，每次邮件来来回回，一个问题低效讨论。就问你，你急不急？ 4. 团队精神 不管个人能力多强，永远把集体的利益放在首位，接受公司调动，愿意离开自己舒适区的同事，永远受团队喜欢 铭记团队目标，当自己成为项目的关键路径时，会主动拼一拼，冲一冲，当自己成为团队的“短板”时，会主动学习，积极提升 虽然个人有不同意见，但团队一旦达成一致，就积极支持集体决议，而不是故意对抗 5. 结果导向 不但软素质过硬，工作有成果，而非强调苦劳 办法永远比问题多，遇事不是一味强调困难，畏首畏尾，而是想办法拿结果 偶尔，给人惊喜，超出预期 不看关系，不看资历，出了成绩，你就上。]]></content>
      <categories>
        <category>管理</category>
      </categories>
      <tags>
        <tag>工作观</tag>
        <tag>研发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM实战 之 奇怪FullGC定位]]></title>
    <url>%2F2020%2F10%2F15%2FJVM%E5%AE%9E%E6%88%98%20%E4%B9%8B%20%E5%A5%87%E6%80%AAFullGC%E5%AE%9A%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[一、背景 图1 真线环境abc-center 堆使用率 图2 真线环境 abc-center 非堆使用率 由图1、图2 可见heap和permGen使用率都不高，但是abc-center 2台机器基本上每天会进行2次规律性的FullGC； 二、问题排查在线询价真线环境JVM参数配置12345678910111213141516-Xms2g-Xmx2g-Xmn448m-XX:SurvivorRatio=5-XX:+UseParNewGC-XX:+UseConcMarkSweepGC-XX:+CMSClassUnloadingEnabled-XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction=0-XX:+ExplicitGCInvokesConcurrent-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses-XX:CMSInitiatingOccupancyFraction=75-XX:+UseCMSInitiatingOccupancyOnly-XX:+HeapDumpOnOutOfMemoryError-XX:MetaspaceSize=300M-XX:MaxMetaspaceSize=300M 查看真线JVM配置参数CMSInitiatingOccupancyFraction=75，配置的内存是2G，实际堆内存维持在570M左右，老年代内存1.5G，老年代内存使用率也低于75%，达不到触发FullGC的条件；基本上每次FullGC前后，堆内存也无明显变化； 团队内部分析讨论后，怀疑可能由于System.gc 引起的FullGC。根据pinpoint 触发FullGC的时间点，查看对应时间段的gc-log，确实是由于System.gc引起的FullGC； 图3 真线环境 -center gc日志 排除掉ABC项目中的程序调用System.gc, 开始猜测二方SDK，三方SDK引入的可能，例如nio包，但是没有找到具有参考价值的日志, 无法定位到具体的调用方法； 通过反复观察gc日志，发现这些fullgc日志都是周期性的，且周期为10小时，如图3所示；根据GC日志分析可知，应用每10小时触发Full GC的现象大概率是外部组件调用引起的，根据这个线索，开始索骥Google资料，了解到tomcat、nio、cxf部分版本可能会有类似周期性FullGC问题。有价值博客只有:https://blog.csdn.net/qq_35963057/article/details/85236268，同样的也是每隔10小时FullGC一次；因此大概率判断是由于apache的cxf包引起的FullGC； 三、定位分析 根据上述分析，查看ABC的maven依赖，如图4，果然在ABC中找到了间接引入了apache-cxf的二方SDK包 图4 inquiry项目maven依赖树 由于在apache-cxf下的JDKBugHacks利用反射调用了sun.misc.GC中的requestLatency方法如图5所示，调用该方法会创建一个守护线程如图6； 图5 JDKBugHacks类的doHacks方法 图6 GC类中创建守护线程 图7 run方法 由图7可知，正是由于在守护线程的run方法中调用了System.gc方法导致了FullGC，同时由GC.lock.wait可知，var1是图5 反射调用传入的36000000ms即10小时，当一次FullGC后，var4会变成0， 因此锁的等待时间是10小时，到这里就基本确定了ABC应用真线是就是由于Apache的cxf包下的JDKBugHacks反射调用导致的；这个GC线程是为了预防部分组件造成的内存泄露问题 (如javax.management.remote.rmi.RMIConnectorServer等会分配堆外内存)，通过调用sun.misc.GC类中requestLatency创建周期为10小时的GC守护线程，定期通知JVM去回收垃圾。 这个线程会先判断是否已有其他组件通过requestLatency来创建了GC线程，如果创建了就跳过，否则新建守护进程。根据类名JDKBugHacks，也能猜测这个类是为了修复一些JDK或组件已有的问题，但这个定期FGC在本应用并不需要； 由于是依赖的二方包引入的，ABC项目中没有显式的调用相关类，需要继续排查是什么地方调用了JDKBugHacks这个类； 排查发现是由于spring框架在初始化的时候进行了调用，如图8、图9所示(中间省略了几个调用节点) 图8 PostProcessorRegistrationDelegate类 图9 LogUtils类 四、解决方案方案1、由图5可知，可以通过控制判断条件，让其不执行if 里面的逻辑 直接在启动项目的JVM参数中加入-Dorg.apache.cxf.JDKBugHacks.gcRequestLatency=true 来使JDKBugHacks中的判断为false，然后跳过这段逻辑。 方案2、由于二方SDK引入的，实际二方包本身并没有使用到cxf包，maven将Apache-cxf包排除即可,如图10所示； 本次修改采用第二种解决方案； 图11 真线堆内存 优化发布上线后，观察近三天确实不在出现FullGC；]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM实战 之 一次内存溢出排查经历]]></title>
    <url>%2F2020%2F10%2F15%2FJVM%E5%AE%9E%E6%88%98%20%E4%B9%8B%20%E4%B8%80%E6%AC%A1%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E6%8E%92%E6%9F%A5%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[源于线上应用事件某天团队同学收到线上系统报警，web-abc真线有一台机down掉了。 为保留事故现场，做剩余应用做了dump。 然后开始分析 问题排查1、 经过对线上出问题周期内的应用日志逐条排查，未发现明显异常。 2、分析当时的dump快照，发现有两个类的实例数和总大小异常，这两个类是跟poi解析excel有关!这个很关键。 3、再翻事发时间的真线日志，有所发现，16点11分51秒的时候，确实有流量请求一个上传excel的接口 4、对比常规接口的日志，事发情况下，只有start没有finish，说明这个请求僵住了，而自这个请求之后的时间，机器才出现不断fullgc的情况 5、伪造一个excel大文件，在test环境上传，把test服务器搞挂，dump文件分析，与真线类似 6、通过以上几点证据，判定为本次事件是由于用户上传excel文件出现的极端情况（文件过大，或者一直尝试），具体的情况日志已分析不出。 8、排查代码中POI读取Excel的方式，发现使用的是用户模式，这样会占用大量的内存；POI提供了2中读取Excel的模式，分别是： 用户模式：poi下的usermodel有关包，它对用户友好，有统一的接口在ss包下，但是它是把整个文件读取到内存中的，对于大量数据很容易内存溢出，所以只能用来处理相对较小量的数据； sax模式：poi下的eventusermodel包下，相对来说实现比较复杂，但是它处理速度快，占用内存少，可以用来处理海量的Excel数据。 POI sax模式只是改善，并不能完全解决这个问题，所以采用阿里开源easyexcel解决优化。 修改优化1、poi解析excel的方式改为easyexcel方式 2、排查后端文件上传、下载的场景，进行大文件极端场景测试 整改方案Java领域解析、生成Excel比较有名的框架有Apache poi、jxl等。但他们都存在一个严重的问题就是非常的耗内存。如果并发量大或excel文件过大，则会OOM或者JVM频繁的full gc。POI的SAX模式虽有改善，但相对比较复杂，excel有03和07两种版本，两个版本数据存储方式截然不同，sax解析方式也各不一样。而阿里开源的easyexcel很好地解决了解析excel大量消耗内存的问题，而且使用简单，功能上也可以覆盖我们的业务需求。 easyexcel核心原理1、文件解压文件读取通过文件形式 2、观察者模式按行解析easyExcel采用一行一行的解析模式，并将一行的解析结果以观察者的模式通知处理（AnalysisEventListener） 3、抛弃不重要数据Excel解析时候会包含样式，字体，宽度等数据，但这些数据是我们不关心的，如果将这部分数据抛弃可以大大降低内存使用。Excel中数据如下Style占了相当大的空间。 easyexcel的使用：请自行百度 推荐读物：https://alibaba-easyexcel.github.io/quickstart/faq.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文就让你精通JVM]]></title>
    <url>%2F2020%2F10%2F04%2F%E4%B8%80%E6%96%87%E5%B0%B1%E8%AE%A9%E4%BD%A0%E7%B2%BE%E9%80%9AJVM%2F</url>
    <content type="text"><![CDATA[《一文就让你精通JVM》网上有关JVM的知识贴多如牛毛，其中有纷杂的零碎知识贴，也有整理优秀的长贴。信息量非常充分。 但作为复习或整理JVM知识的而言，还可以有更好的学习用户体验和高效的方式。因此，就想尝试写一篇有关JVM知识点的“秘籍”，让初学者仅读此文就能快速精通JVM的知识脉络以及关键知识，也能让复习着快速反查知识和经验之谈。 黄老师 1、背景知识铺垫1.1、JRE、JVM、JDK先讲讲JVM、JRE、JDK是什么 JVM (Java Virtual Machine) JVM有自己的规范，所有的JVM版本都必须按此规范实现。 JVM是一个抽象、虚拟、不物理存在的”机器”。是通过在真实的计算机上仿真模拟各种计算机功能来实现的。JVM有自己完善的硬件架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。 JVM负责执行Java代码 JRE (Java Runtime Environment) JRE包含JVM JRE是一个运行环境容器，提供诸多Java运行需要的libs。包括：标准、非标准的Java组件；Java规范要求、Java规范未要求的组件。 JRE为JVM服务 rt.jar(contains: lang, util, awt, swing, math, runtime libraries) JDK (Java Development Kit) 从Kit单词上可预知JDK会包含很多东西，的确，JDK包含：JVM、JRE，以及Java语言和工具包。 JDK比JRE多的部分：Development, debugging tools Oracle 官方Java概念图 1.2、HotSpot Client/Server模式为什么要铺垫下 HotSpot Client/Server模式？因为后续GC章节默认收集器在不同模式下不同。 HotSpot JVM具有两种模式：Client模式和Server模式。可以理解为针对不同的硬件环境和软件场景做的JVM优化版本。 Java HotSpot Client VM(-client)：轻量级。为在客户端环境中减少启动时间而优化，使用的策略和功能都是较简单版本。 Java HotSpot Server VM(-server)：重量级。为在服务器环境中最大化程序执行速度而设计，使用的策略和功能是为了最大化的发挥硬件优势，提升吞吐量。《《《 作为服务端Java开发，大多数情况下默认Server模式。 HotSpot的安装的模式，32位的hotspot都是client模式；64位的都是server模式的。 可通过java -version查看 若想要修改模式，则需变更JVM的配置文件。32位的虚拟机在 “%JAVA_HOME%/jre/lib/i386/jvm.cfg”；64位的虚拟机在“%JAVA_HOME%/jre/lib/amd64/jvm.cfg”； 2、JVM体系结构 JVM体系结构图 操作系统视角 2.1、Class文件 Class 文件是一种特定的二进制文件格式的文件。格式紧凑，包含了JVM指令集和符号表以及若干其他辅助信息，其编码结构风格被称为“字节码”。 在JVM体系里，不同的硬件(主要是CPU)和操作系统环境下的JVM是不同版本的实现，而Java语言的平台无关性，主要体现在“Class文件”上。Java代码一次编译成Class文件，可以在不同体系的JVM版本下运行。 其他语言只要其代码能被编译成符合Class文件规范的Class文件，就能在JVM上运行。 2.2、内存区 之 虚拟机栈区 见上图《JVM体系结构图》 在JVM里有一块专门为Java线程分配栈空间的内存区，叫”虚拟机栈区”。 每个Java线程创建时都会分配一个“虚拟机栈”，此虚拟机栈的生命周期与其所绑定的线程生命周期一致。 而当线程执行Java代码时，JVM会为每个Java方法创建一个固定结构的内存模型：栈帧。 此“栈帧”结构是线程虚拟机栈入栈/出栈操作的基本单位（入栈/出栈的时机对应Java方法的调用和返回） 栈帧是用于支持JVM进行方法调用和方法执行的数据结构 2.2.1、栈帧(Stack Frame)结构 局部变量表： 编译期确定局部变量表大小。一组变量存储空间， 容量以slot为最小单位，而slot的大小随硬件体系而定，以此来适应硬件体系的差异。 虚拟机规范中未明确指明一个Slot应占用的内存空间大小，只是导向性的说到每个Slot都应该存放一个boolean、byte、char、char、short、int、float、reference或returnAddress类型的数据，这8种数据类型都可以使用32位或更小的物理内存来存放，Slot的长度可以随着处理器、操作系统或虚拟机的不同而发生变化。 操作栈：编译期确定操作数栈最大深度。是一个后入先出栈（LIFO）。操作数栈可类比CPU的寄存器，协助JVM完成Java方法内的调用传值，计算操作。 例如：整数加法的字节码指令iadd再运行的时候操作数栈中最接近栈顶的两个元素已经存入了两个int类型的数值，当执行这个指令时，会将这两个int值出栈并相加，然后将相加的结果入栈。 动态连接： 指向运行时常量池中该栈帧所属Java方法的引用，这样才能找到真正&amp;完整的代码片段。 Class文件中关于方法调用，存的是符号引用。字节码在运行期，需要将符号引用转化为带具体内存地址的代码片段的直接引用。 方法返回地址：方法退出的过程实际上等同于把当前栈帧出栈，并恢复上层方法的局部变量表和操作数栈，把返回值（如果有）压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。 方法返回地址里一般存的是调用者当时的PC计数器的值。当方法正常返回时，就返回这个地址。而当方法异常退出时，返回地址要通过异常处理器表来确定。 额外附加信息：预留的扩展区域，由JVM实现方按需使用。 2.3、内存区 之 本地方法栈区本地方法栈是JVM为Native方法提供的内存空间。 本地方法栈里的基本元素结构取决于本地方法接口的具体实现机制。若其使用C连接模型,那么本地方法栈就是C栈。 Java方法栈和本地方法栈之间可以灵活交叉切换。 有些虚拟机的实现直接把本地方法栈和虚拟机栈合二为一，比如典型的Sun HotSpot虚拟机。 2.4、内存区 之 堆内存区 Java堆，是JVM管理的最大的一块内存，也是GC的主战场。里面存放的是几乎所有的对象实例和数组数据。 JIT编译器有栈上分配、标量替换等优化技术的实现导致部分对象实例数据不存在Java堆，而是栈内存。 从内存回收角度：Java堆为分代回收机制，分为年轻代和老年代。这样划分的好处是为了更快的回收内存（每次回收的内存范围相对小） 从内存分配角度：Java堆可以划分出线程私有的分配缓冲区(Thread Local Allocation Buffer,TLAB)；这样划分的好处是为了更快的分配内存； 关联知识点： 1、标量替换：允许将对象打散分配在栈上，比如若一个对象拥有两个字段，会将这两个 字段视作局部变量进行分配。 2.4.1、各内存区默认配比 年轻代：老年代 默认 1：2（将堆空间分为3份） Eden ：from ：to 默认 8：1：1 相关JVM参数 -Xms：初始堆大小。默认物理内存的1/64。 -Xmx：最大堆大小。默认物理内存的1/4。 -Xmn：年轻代大小 -XX:NewRatio：年轻代与老年代的比值 -XX:SurvivorRatio：Eden区域Survivor区的大小比值。默认8:1:1。 2.4.2、TLAB全称 Thread Local Allocation Buffer，线程本地分配缓冲区。 默认是开始的。JVM命令 -XX:+UseTLAB。 由于堆是全局共享的，因此存在同一时间会有多个线程在堆上申请空间的并发情况。为保证堆内存分配操作的原子性，JVM采用“CAS+失败重试”的方式，但这种方式在并发竞争激烈的情况下效率会进一步下降。 因此，JVM额外设计了TLAB 来避免多线程分配对象内存时的冲突处理。 大致原理： JVM在内存年轻代Eden Space中开辟了一小块线程私有的区域，称作TLAB。默认设定为占用Eden Space的1%。 Java中每个线程都会有自己的缓冲区称作TLAB。 由于TLAB是线程私有的，所以内存分配没有锁开销，效率高。 在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上。 故，对象仍旧是在堆上被分配的，只不过分配的方式变了而已。 2.4.3、逃逸分析 关联知识点：逃逸分析只在JVM运行在server模式时才能启用。 逃逸分析 是一种可以有效减少Java 中堆内存分配压力的分析算法。JVM默认开启。 通过逃逸分析，Java Hotspot编译器能够分析出一个即将新创建对象的引用的使用范围，从而决定通过哪种方式分配对象内存（栈上标量替换；TLAB分配；堆分配；）。 2.4.4、对象内存分配的两种方法为对象分配内存空间的任务等同于把一块确定大小的内存从Java堆中划分出来。 指针碰撞 (Serial、ParNew等带Compact过程的收集器)假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump the Pointer）。 空闲列表 (CMS这种基于Mark-Sweep算法的收集器)如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。 2.4.5、对象实例的具体结构 对于填充数据不是一定存在的，仅仅是为了字节对齐。 2.5、内存区 之 方法区当JVM使用类装载器装载某个类时，它首先要定位对应的class文件，然后读入这个class文件，最后，JVM提取该文件的内容信息，并将这些信息存储到方法区，最后返回一个class实例。 注：方法区 是 JVM规范的一部分，并不是实际的实现。实际实现有JDK7以前的永久代，以及JDK8的元空间。 方法区的特点： 1、方法区是线程安全的。假如同时有两个线程都企图访问方法区中的同一个类，而这个类还没有被装入JVM，那么只允许一个线程去装载它，而其它线程必须等待。 2、方法区的大小不是固定的，JVM可根据应用运行期的需要动态调整。其内存也不一定是连续的。 3、方法区也可被垃圾收集（GC），当某个类不在被使用(不可触及)时，JVM将卸载这个类，进行垃圾收集。 方法区主要存放的是已被虚拟机加载的类信息、常量、静态变量、编译器编译后的代码等数据。 常量池分解 2.5.1、静态常量池： 即class文件中的常量池，是文件级、静态级的。class文件中的常量池不仅仅包含字符串(数字)字面量，还包含类、方法的信息，占用class文件绝大部分空间。 2.5.2、运行时常量池： 运行时常量池是方法区的一部分，可以理解为一块专门存放常量的内存。包括装载class文件而放入的常量，也包括代码运行时动态生成的常量（String类的intern()方法）。 静态常量池和运行时常量池的差别在于，一个是存在文件中，是“静”的，一个是存在内存中，是“动”的。 而我们常说的常量池，一般是指在方法区中的动态常量池。 2.6、内存区 之 堆外内存区讲堆外内存前，首先带大家从操作系统视角看堆外内存所处的位置。相信看了直观的图示后能立马有清晰的记忆和理解。 助读说明： 1、先着眼操作系统进程视角，每个进程都拥有自己独占的进程级内存空间。每个进程看到的机器内存大小是一样的，且内存范围也是一样的。为什么？因为用户态进程看到的是逻辑内存地址，并不是真实的物理内存地址。 2、用户态进程的内存地址都是逻辑地址，用malloc分配，故物理上不连续。 3、堆内存在JVM内。受JVM管理，参与GC。 4、堆外内存处于进程内存空间，但属于JVM堆内存之外。 5、堆外内存不受JVM管理，不参与GC。编码时需要主动释放。 2.6.1、直接内存（Direct Buffer） Direct Buffer是堆外内存的一种具体类型，常出现于NIO模型中。 NIO模型中为什么要用Direct Buffer？ 答：NIO需要进行socket连接的收包和发包，这个操作最终要从操作系统用户态进入到内核态进行操作。而内核态调用要求内存地址必须可靠（即在一次完整调用周期内内存地址是不会变的）。但Java堆里的内存会受GC影响而移动整理，地址会变。故NIO不能用堆里的内存。 即使代码层面非要用Java堆内存区做NIO操作，JVM仍会自动将堆内存对象转换为直接内存对象，然后再进行内核态操作。 故Direct Buffer对于JVM来说有如下优点： 1、对于NIO操作,直接用Direct Buffer比用Java堆内存,免去一次内存拷贝，相比之下效率高了。 2、GC压力更小。因Direct Buffer是堆外内存，是代码者自行管理，不用JVM额外操心,GC的范围就缩小了。 其他须知： 1、Direct Buffer创建是比较耗时的，高性能或高频场景下，建议池化。 3、JVM垃圾收集器JVM垃圾回收是继掌握内存模型后，必须进阶更进一步掌握的JVM内存知识。 全世界的程序员都知道：“Java的内存是会自动回收的”。这背后会有哪些知识点呢，请看下文。 3.1、垃圾回收原理3.1.1、垃圾分析策略 引用计数 策略 比较古老的回收算法。原理是额外维护对象上的引用计数。当发生GC时，回收引用计数为0的对象的内存。 此算法的缺点：无法处理循环引用的问题。 ​ 那怎么破解呢？用Java里的弱引用（Weak Reference）破开强引用关系。 可达性分析 策略（主流JVM用的都是这种） 从GC ROOT开始，遍历引用关系节点，当所有的引用节点遍历完毕之后，剩余未遍历到的节点则被认为是没有被引用到的节点，即可被回收的对象节点。 GC Root 示例 需要知晓的是： 1、会有一些列的“GC Roots”且同时工作，在Java中可作为GC Root的对象包括： ​ a）虚拟机栈中引用的对象（栈帧中的本地变量表） ​ b）方法区中类静态属性引用的对象 ​ c）方法区中常量引用的对象 ​ d）本地方法栈中JNI（Native）引用的对象 2、基于GC Root做可达性分析时，需要STW（Stop The World），必须记住此知识点，对于了解后续垃圾回收算法有帮助。 3.1.2、垃圾回收算法 一、引用计数 算法 略 二、标记-清除 算法（Mark-Sweep） 最基础的垃圾回收算法，思想简单且容易实现。 工作上分为两个阶段： 一、标记阶段：从GC Roots开始标记被引用对象； 二、清除阶段：遍历整个堆，把未标记的对象清除； 缺点：会有内存碎片。导致下一次GC的提前到来。 三、复制 算法（Copying） 为了解决Mark-Sweep算法的缺陷，Copying算法就被提了出来。 它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把此内存区域空间一次清空，这样一来就不容易出现内存碎片的问题。 优点：不会出现内存碎片。 缺点：需要两倍的内存空间。 适合对象生命周期短的内存区域，一次能回收绝大部分内存。例如：年轻代 四、标记-整理 算法（Mark-Compact） 此算法结合了“标记-清除”和“复制”两个算法的优点。 分为三个阶段：（我更喜欢划分为三个阶段） 第一阶段：从GC Root开始标记所有被引用对象 第二阶段：遍历整个堆，将存活对象往集中的一片内存区域移动。 第三阶段：基于内存整理后的指针边界，清除整理区域以外的内存空间。 再强调下特殊点：时序上是“标记-&gt;整理-&gt;清理”。 3.1.3、小结一下 堆内存区 垃圾分析策略 常用垃圾回收算法 年轻代 GC Root可达性分析 1、复制算法 老年代 GC Root可达性分析 1、标记-清除算法2、标记-整理算法 衍生的知识点： GC Roots的可达性分析，会衍生到图论的算法。有一个比较经典的有向图的问题：有向图检测是否存在环。 这也是调用引擎，规则引擎经常会遇到的算法问题（新加入一个节点时预检测是否构成环） 考虑简单环，所谓的简单环，即除了第一个和最后一个顶点，其余所有顶点在路径中只出现一次。 实现思路一：DFS 时间复杂度O(V+E) 做DFS（深度优先搜索）遍历时，每深入遍历一个的节点就把节点都压入栈，每退回一层遍历就把节点从栈中退出，且每次压入前都检测当前节点在栈中是否已存在。如果已存在，就表明曾经经过此节点，说明已构成环。 参考之一 实现思路二：拓扑排序 时间复杂度O(n^2) 从有向图的末梢逐步往上砍叶子节点。 出度和入度的概念。一张有向图是有顶点和带有方向的边组成的。对于一个顶点，如果有n边从其他顶点指向此顶点，则这个顶点的入度就是n。相应的，如果有n条边从这个顶点指向其他顶点，则这个顶点的出度就是n。 拓扑排序的一般流程： 1.初始化各个顶点的出度。 2.移除出度为0的顶点和与此顶点相连的边。 3.更新出度。 4.重复步骤2和3，直到不存在出度为0的顶点或者顶点已经全部被移除了。 5.判断是否存在剩余顶点，若存在则存在环，若不存在则无环。 参考 3.2、分代收集策略分代收集策略的目的本质是为了更高效效率的进行内存回收。 核心思想是根据对象存活生命周期的特点，将JVM内存划分为若干个区域，不同内存区域按其对象生命周期的特点采用不同的回收频率和回收算法。常见的分代方式：年轻代、老年代、永久代。 反过来试想，假设JVM在一次垃圾回收窗口时，要对整个JVM内存区对垃圾回收分析和清除，Stop The World会持续很长时间。 与垃圾回收策略的匹配 堆内存区 内存区特点 垃圾分析策略 常用垃圾回收算法 年轻代 对象生命周期短，每次回收量大 GC Root可达性分析 1、复制算法 老年代 对象生命周期长，每次回收量小 GC Root可达性分析 1、标记-清除算法2、标记-整理算法 3.3、JVM触发GC的时机3.2.1、JVM自动触发GC的时机 触发YoungGC： 新建对象时，发现eden space满了（或者因内存碎片找不到足够连续的内存），JVM会触发一次YoungGC 触发FullGC： 升到老年代的对象空间大于老年代剩余空间，JVM会触发一次FullGC。或者被HandlePromotionFailure参数强制FullGC。 3.2.2、手动触发GC 代码System.gc()。但只是像JVM提交了一次GC请求，至于何时会真正执行GC，未知。 12345678910111213141516171819/** * Indicates to the VM that it would be a good time to run the * garbage collector. Note that this is a hint only. There is no guarantee * that the garbage collector will actually be run. */ public static void gc() &#123; boolean shouldRunGC; synchronized(lock) &#123; shouldRunGC = justRanFinalization; if (shouldRunGC) &#123; justRanFinalization = false; &#125; else &#123; runGC = true; &#125; &#125; if (shouldRunGC) &#123; Runtime.getRuntime().gc(); &#125;&#125; 只有在justRanFinalization=true的时候才会执行。 强制执行GC的方式 123System.gc();runtime.runFinalizationSync();System.gc(); 3.4、“Stop The World”是怎么执行的（SafePoint）我们知道JVM GC是需要”Stop The World”的，“Stop The World”代表着所有Java线程需要全部暂停。在JVM Java线程高频并发运行的状态下，怎么让所有Java线程全部都进入安全的暂停状态呢？答案：SafePoint机制。 3.4.1、【概念】 从线程角度看，safepoint可以理解成在代码执行过程中的一些特殊位置，当线程执行到这些位置的时候，说明虚拟机当前的状态是安全的，如果有需要，可以在这个位置暂停。比如：GC时需要暂停所以Java线程的需求。 safepoint的特性可以用在不同的地方：GC、Deoptimization。 常见的safepoint位置： 循环的末尾 (防止大循环的时候一直不进入 safepoint，而其他线程在等待它进入 safepoint) 方法返回前 调用方法的call之后 抛出异常的位置 3.4.2、【Safepoint放在代码什么位置】 以Hotspot为例说明一下什么地方会放置safepoint 1、理论上，在解释器的每条字节码的边界都可以放一个Safepoint，但挂载Safepoint的调试符号信息（为GC生成的符号信息是OopMap）要占用内存空间，如果每条机器码后面都加safepoint的话，需要保存大量的运行时数据，所以在放置Safepoint方面会取折中适用的策略。 2、HotSpot JVM在通过JIT编译时，会在所有方法返回之前以及循环跳转、异常跳转之前放置Safepoint，为了防止发生GC需要STW时，该线程一直不能暂停。并且，在每个Safepoint都生成一些信息存储哪些地方是引用（OopMap），以便JVM能找到需要的引用。 3.4.3、【线程如何被挂起】 有两种方法：抢占式中断(Preemptive Suspension)和主动式中断(Voluntary Suspension)。 （线程被）抢占式中断： 抢占式中断不需要线程的执行代码去主动配合。当触发GC时，JVM会中断所有线程，然后依次检查每个线程中断的位置是否为Safepoint，如果不是则恢复线程，让它执行至Safepoint再进行终端。 （线程）主动式中断：《《《 HotSpot JVM的实现方式 即GC需要中断线程的时候，它仅仅简单地设个标志，每个Java线程会在进入Safepoint时主动轮询这个标志位，如果标志位就绪的话就自行中断。 如果触发GC动作，VM thread会在VMThread::loop()方法中调用SafepointSynchronize::begin()方法，最终使所有的线程都进入到safepoint。 123456789// Roll all threads forward to a safepoint and suspend them allvoid SafepointSynchronize::begin() &#123; Thread* myThread = Thread::current(); assert(myThread-&gt;is_VM_thread(), "Only VM thread may execute a safepoint"); if (PrintSafepointStatistics || PrintSafepointStatisticsTimeout &gt; 0) &#123; _safepoint_begin_time = os::javaTimeNanos(); _ts_of_current_safepoint = tty-&gt;time_stamp().seconds(); &#125; 3.4.4、【线程如何恢复】 有了begin方法，自然有对应的end方法，在SafepointSynchronize::end()中，会最终唤醒所有挂起等待的线程。 思考题： 1、GC时最大的影响就是STW周期，本文讲的所有线程都进入safepoint的也是有个周期，且此周期受并发线程个数和safepoint距离影响。问：线程池配的越多，对GC的耗时有明显的影响吗？ 3.5、垃圾收集器3.5.1、垃圾收集器类型HotSpot JVM里有7种垃圾收集器，你是怎么记忆它们的呢？ 上图解读： （A）图中展示了7种收集器：Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS、G1； （B）图中它们所处区域，表明其是属于年轻代收集器还是老年代收集器： 年轻代收集器**：Serial、ParNew、Parallel Scavenge； 老年代收集器：Serial Old、Parallel Old、CMS； 整堆收集器：G1； （C）两个收集器间的连线，表明它们可以搭配使用： - Serial 配 ：Serial Old 或 CMS； - ParNew 配 ：Serial Old 或 CMS； - Parallel Scavenge 配 ：Serial Old 或 Parallel Old； （D）CMS与Serial Old的连线表示Serial Old是作为CMS出现“Concurrent Mode Failure”失败的后备预案。 3.5.2、常见垃圾收集器对比 GC时STW的停顿时长的排行：G1 &lt; CMS &lt; Parallel收集器 &lt; Serial收集器 JVM默认收集器 怎么查看？ 怎么切换？ 例子：-XX:+UseConcMarkSweepGC 参数 描述 UseSerialGC JVM运行下Client模式下的默认收集器，打开此开关后，使用Serial+Serial Old的收集器组合。 UseParNewGC 使用ParNew+Serial Old的收集器组合。 UseConcMarkSweepGC 使用ParNew+CMS的收集器组合。 UseParallelGC 虚拟机运行在Server模式下的默认收集器，打开此开关后：- JDK 7u4版本前：使用Parallel Scavenge + Serial Old的收集器组合。也是Java书上的说法。- JDK 7u4版本后：使用Parallel Scavenge + Parallel Old的收集器组合，此时的Parallel已经很成熟了。求证过程：Link UseParallelOldGC 使用Parallel Scavenge + Parallel Old的收集器组合 3.5.3、常见垃圾收集器及原理1、（年轻代）Serial ​ Serial（串行）垃圾收集器是最基本、发展历史最悠久的收集器；JDK1.3.1前是HotSpot年轻代收集的唯一选择； ​ 特点： ​ 1、针对年轻代； ​ 2、采用复制算法；单线程收集；全程STW； ​ 3、HotSpot Client模式下的默认年轻代收集器； Serial/Serial Old组合收集器运行示意图 ​ 适用场景：小内存（小于200M），单CPU的环境。 2、 （年轻代）ParNew ​ ParNew垃圾收集器是Serial收集器的多线程版本。 ​ 特点： ​ 1、除了多线程外，其余的行为、特点和Serial收集器一样（两者还共用了不少代码）。 ​ 2、也是针对年轻代，也是复制算法。 ​ 3、”-XX:+UseConcMarkSweepGC”：指定使用CMS后，会默认使用ParNew作为年轻代收集器； ​ 4、”-XX:ParallelGCThreads”：指定垃圾收集的线程数量，ParNew默认开启的收集线程与CPU的数量相同； ParNew/Serial Old组合收集器运行示意图 ​ 适用场景： ​ 在HotSpot Server模式下，ParNew收集器是一个非常重要的收集器，因为除了Serial外，只有它能与CMS收集器配合工作。 3、 （年轻代）Parallel Scavenge ​ （Java8 默认的收集器）Parallel Scavenge又称为吞吐量优先收集器，特点是多线程回收，以吞吐量优先，高效率的利用CPU时间。 ​ 特点： ​ 1、Java8 默认的收集器； ​ 2、年轻代收集器；复制算法；多线程收集； ​ 3、Parallel Scavenge收集器的目标是以高吞吐量为目标，达一个可控制的吞吐量。 吞吐量： 吞吐量 = 运行用户代码时间 /（运行用户代码时间+垃圾收集时间） 高吞吐量即减少垃圾收集时间，让用户代码获得更长的运行时间 ​ 适用场景： ​ Parallel Scavenge收集器的高吞吐量可以最高效率的利用CPU时间，尽快的完成程序的运算任务等，主要适合在后台运算而不是太多交互的任务（其不适合需要与用户交互的程序，良好的响应速度能提升用户的体验，此种场景CMS效果更好）。 4、 （老年代）Serial Old ​ Serial Old是 Serial收集器的老年代版本。是JDK 7u4版本前的老年代默认收集器。 ​ 特点： ​ 1、采用标记整理法； ​ 2、单线程； Serial/Serial Old组合收集器运行示意图 ​ 适用场景： ​ 1、主要用于HotSpot的Client模式。 5、 （老年代）Parallel Old ​ Parallel Old垃圾收集器是Parallel Scavenge收集器的老年代版本；目前已经很成熟了，是JDK 7u4版本后的老年代默认收集器（JDK8的老年代默认收集器）。 ​ 特点： ​ 1、标记-整理 算法； ​ 2、多线程收集； Parallel Scavenge/Parallel Old收集器运行示意图 6、 （老年代）CMS ​ CMS收集器也称为并发低停顿收集器（或低延迟垃圾收集器），以获取最短回收停顿时间为目标。 ​ CMS并不是等内存不足了才进行FullGC，而是基于设定的GC阈值，当超过阈值时主动进行CMS GC，因为CMS GC是与用户线程并发的，故用户线程对于CMS GC的停顿感知是很少的。 CMS的GC阈值： 1、设定了CMSInitiatingOccupancyFraction时，以此为阈值，区间：0~100。 2、CMSInitiatingOccupancyFraction默认为-1，则按“((100 - MinHeapFreeRatio) + (double)( CMSTriggerRatio * MinHeapFreeRatio) / 100.0) / 100.0 ”的值决定，其中MinHeapFreeRatio默认值40，CMSTriggerRatio默认值80，那么阈值为92%。 为什么要通过阈值留有一部分空闲内存时进行GC？因为CMS GC时可能会遇到“浮动垃圾”，见下文。 ^敲黑板： 需要注意：CMS GC不是FullGC！！！ HotSpot VM里对concurrent collection和full collection有明确的区分。所有带有“FullCollection”字样的VM参数都是跟真正的full GC相关，而跟CMS并发GC无关的，cms收集算法只是清理老年代。 CMS收集器运作过程 第一步：初始标记（CMS initial mark）： 仅标记一下GC Roots能直接关联到的对象。需要STW，但速度很快。 第二步：并发标记（CMS concurrent mark）：进行GC Roots Tracing的过程，标出存活对象。因与用户线程并发运行，不能保证标记出所有存活对象。 第三步：重新标记（CMS remark）：多线程。修正并发标记期的标记结果。需要STW，相对也不长。 第四步：并发清除（CMS concurrent sweep）：回收所有垃圾对象。 整个过程中耗时最长的并发标记和并发清除都可以与用户线程一起工作；所以总体上说，CMS收集器的内存回收过程与用户线程一起并发执行； CMS收集器运行示意图 ​ 特点： ​ 1、并发收集（与用户线程并发执行），低停顿。 ​ 2、标记-清除算法，会产生内存碎片。 ​ 缺点： ​ 1、对CPU资源非常敏感 CMS的默认收集线程数量 = (ParallelGCThreads + 3) / 4 ParallelGCThreads = （ncpus &lt;= 8）? ncpus : (3 + （(ncpus * 5) / 8))。CPU数量小于8时，ParallelGCThreads为CPU数量。 并发收集线程占用一部分CPU资源，当CPU数量多于4个，收集线程占用的CPU资源多于25%，对用户程序影响可能较大；不足4个时，影响更大，可能无法接受。 ​ ​ 2、无法处理浮动垃圾，可能出现“Concurrent Mode Failure” ​ a）浮动垃圾（Floating Garbage） 在并发清除时，用户线程新产生的垃圾，称为浮动垃圾； 这使得并发清除时需要预留一定的内存空间，CMS所需要的空间比其他垃圾收集器大； “-XX:CMSInitiatingOccupancyFraction”：用于设置CMS预留内存空间比例； ​ b）”Concurrent Mode Failure”失败 如果CMS预留内存空间无法满足程序需要，就会出现一次”Concurrent Mode Failure”失败； 这时JVM启用后备预案：临时启用Serail Old收集器，而导致另一次FullGC的产生； 这样的代价是很大的，所以CMSInitiatingOccupancyFraction不能设置得太大。 ​ 3、产生内存碎片 解决方法： （1）”-XX:+UseCMSCompactAtFullCollection + -XX:+CMSFullGCsBeforeCompaction” 设置CMS执行N次FullGC后，进行一次带整理的FullGC。默认未开启。 （2）降低-XX:CMSInitiatingOccupancyFraction参数，以提早执行CMS GC动作，虽然CMS GC不会进行内存碎片的压缩整理，但它会合并老年代中相邻的free空间。这样就可以容纳更多的年轻代晋升行为。 适用场景： ​ 1、与用户交互多的场景，注重服务的响应速度，常见于WEB、B/S系统的服务器上的应用。系统停顿时间最短，给用户带来较好的体验。 7、 （整堆）G1 G1收集器运作过程： 第一步、初始标记（Initial Marking）：仅标记一下GC Roots能直接关联到的对象；且修改TAMS（Next Top at Mark Start）,让下一阶段并发运行时，用户程序能在正确可用的Region中创建新对象；需要”Stop The World”，但速度很快； 第二步、并发标记（Concurrent Marking）： 进行GC Roots Tracing的过程； 刚才产生的集合中标记出存活对象；耗时较长，但应用程序也在运行；并不能保证可以标记出所有的存活对象； 第三步、最终标记（Final Marking）： 为了修正并发标记期间因用户程序继续运作而导致标记变动的那一部分对象的标记记录； 上一阶段对象的变化记录在线程的Remembered Set Log；这里把Remembered Set Log合并到Remembered Set中； 需要”Stop The World”，且停顿时间比初始标记稍长，但远比并发标记短；采用多线程并行执行来提升效率。 第四步、筛选回收（Live Data Counting and Evacuation）： 首先排序各个Region的回收价值和成本； 然后根据用户期望的GC停顿时间来制定回收计划； 最后按计划回收一些价值高的Region中垃圾对象； 回收时采用”复制”算法，从一个或多个Region复制存活对象到堆上的另一个空的Region，并且在此过程中压缩和释放内存； 可以并发进行，降低停顿时间，并增加吞吐量； ​ 特点： ​ 1、充分利用多CPU的硬件优势，通过并行缩短STW时间，通过并发让用户线程同时进程。 ​ 2、能独立管理整个堆（年轻代和老年代） ​ 3、结合多种垃圾收集算法，整体上基于标记-整理算法，局部Region间基于复制算法。不会产生内存碎片。 ​ 4、可预测的停顿，低停顿，高吞吐。 ​ ​ 适用场景： ​ 针对具有大内存、多处理器机器的服务端应用。可提供低GC停顿的能力。 4、GC调优4.1、GC调优的目标内存区 一般都针对年轻代、老年代调优，尤其是老年代。 方法区可以进行GC，但一般不操心方法区的GC，因为GC的性价比太低，主要回收“废弃常量和无用的类”。如果内存不够就扩大吧。JDK8方法区的实现为元空间，元空间使用的是本地内存（非堆内存），默认情况下元空间的大小是无限的。 4.2、GC调优的策略 常见的招数，一招招使 注：一定是先找1台机器进行试验，对比，然后再做出选择，发布生产环境。 4.3.1、大多数的Java应用不需要GC调优 大部分需要GC调优的，不是JVM参数问题，是代码问题。 在实际情况中，基于GC情况优化代码比优化GC参数要多得多。 4.2.2、（选择合适的GC收集器）互联网Web应用考虑CMS收集器，提升交互响应性能 GC低停顿：CMS收集器是与用户线程并发的内存垃圾收集器； 大幅减少FullGC：CMS GC是concurrent GC，是周期性主动的回收内存。大幅减少FullGC的发生。 4.2.3、（选择合适的堆大小） 去设置堆大小，别不设置用默认的 拍脑袋定初始参数 -&gt; 运行JVM -&gt; 查监控 -&gt; 调整JVM -&gt; 查监控 -&gt; 反复试验 -&gt; 确认JVM参数 4.2.4、（选择合适的年轻代比重）年轻代尽量大 年轻代 尽量大，那么可以减少YoungGC。进而减少了对象进入老年代的频率,进而减少FullGC的频率。 4.2.5、-XX:MaxTenuringThreshold 合理年轻代对象晋升进入老年代的年龄 -XX:MaxTenuringThreshold 设置年轻代对象进入老年代的年龄大小，减少老年代的内存占用，降低 FullGC 发生的频率 4.3.6、（小心大对象）避免大对象直接进入老年代 怎么应对/避免？ 一：-XX:+PretenureSizeThreshold 控制 设置-XX:+PretenureSizeThreshold 参数：代表超过这个值的时候，对象直接在old区分配内存。默认值是0，代表不管新对象多大都是先在eden中分配内存。 注意：PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效，Parallel Scavenge收集器不认识这个参数。如果遇到必须使用此参数的场合，可以考虑ParNew加CMS的收集器组合。 二：更大的年轻代，含：eden区、survivor区 eden区能申请的到，就不会去old区申请了。同时可适当调高-XX:MaxTenuringThreshold（Linux 64下，默认15），让大对象在年轻代生，在年轻代亡。 同时，可考虑搭配最小堆大小和最大堆大小，并设置MinHeapFreeRatio或MaxHeapFreeRatio来掌控堆大小的按需扩大与收缩。 4.3、GC调优分析工具发现JVM内存问题以及查看对应GC情况是简单的 （原始一点的）登录到服务器上敲命令：jstat、jmap、jstack。 （常见的）登录公司运维平台查看指标情况：Grafana、容器管理平台等 （辅助工具型的）APM工具，如：pinpoint。 pinpoint： Grafana： 一般我们能从统计图表里快速的看到问题现象，例如： FullGC频繁； 年轻代占用比例不高，但老年代会有规律性FullGC； …… 然后，进一步定位GC现象发生的原因和具体代码位置，是需要些技术分析能力和不断试验的。 这里我们需要用工具来帮我们高效的定位问题。 常用工具： 使用顺序： 1、dump JVM堆 2、用工具load dump后的文件，通过工具查看内存占用Top的对象，通过对象Class声明或Reference找到代码位置。 1、JProfiler（推荐）（功能很强大；需付费） 软件下载地址：https://www.ej-technologies.com/products/jprofiler/overview.html IntelliJ IDEA有插件版本 例图： 2、JVisualVM（免费） 软件下载地址：http://visualvm.github.io/index.html IntelliJ IDEA有插件版本 使用指导贴：https://www.cnblogs.com/happy-rabbit/p/6232581.html 例图： 4.4、GC调优的问题举例5、监控指标怎么看5.1、Heap &amp; Non-Heap 以JDK8及以后为背景 例图来自Grafana 例图来自JProfiler 5.1.1、Heap Memory = 堆内存 ​ 看完之前章节，应熟悉堆内存包含什么。这里不再赘述。 5.1.2、Non-Heap Memory = 非堆内存 如果non-heap使用上升趋势，我们应该关注什么呢？ non-heap（非堆内存）指Java进程内存中，JVM 堆内存范围以外的内存。不清楚的同学，复习上文第2章节：《JVM体系结构》 那么，non-heap（非堆内存）主要包含哪些内容呢？ 1、【栈区】：虚拟机栈；本地方法栈；&lt;&lt;&lt;&lt; 这块基本不用操心。也不会持续增大。 2、【方法区】； &lt;&lt;&lt;&lt; 存在持续增大的可能，见本文《怎么构造方法区OOM》 3、【Native Memory】； &lt;&lt;&lt;&lt; 一般是JNI用到的内存，可能是频繁NIO导致大量Direct Buffer；也可能是内存未管理好，持续泄露内存了。 4、【Code Cache】：&lt;&lt;&lt;&lt; 用于编译和保存本地代码的内存。JVM内部处理或优化。一般不操心。 6、JVM类加载器6.1、类加载过程类加载的7个步骤: 装载。根据查找路径找到相应的 class 文件，然后导入。 验证，检查待加载的 class 文件的正确性。《《《链接的 3 小步 准备，给类中的静态变量分配存储空间。《《《链接的 3 小步 解析，将符号引用转换为直接引用(这一步可选)。《《《链接的 3 小步 初始化。对静态变量和静态代码块执行初始化工作。 使用 卸载 类的加载方式分为隐式加载和显示加载。 隐式加载指的是程序在使 用 new 等方式创建对象时，会隐式地调用类的加载器把对应的类 加载到 JVM 中。 显示加载指的是通过直接调用 class.forName() 方法来把所需的类加载到 JVM 中。 1、Class.forName 和 ClassLoader.loadClass 都能加载类，这两者在加载类时的区别？ Class.forName有重载方法可以指定是否需要初始化，而默认的方法初始化设置为true这会初始化类执行链接和初始化操作 ClasaLoader是有类加载器的loadClass方法加载，传入的是false，只会执行连接操作，不会初始化操作 类只有被使用到的时候才会被加载，采用这种方法一方面可以加快加载速度，另一方面可以节约程序运行 时对内存的开销。 此外，在 Java 语言中，每个类或接口都对应一 个 .class 文件，这些文件可以被看成是一个个可以被动态加载的 单元，因此当只有部分类被修改时，只需要重新编译变化的类即可， 而不需要重新编译所有文件，因此加快了编译速度。 6.2、类加载器的种类在Java中，类加载器主要有下面四种： BootstrapClassLoader：启动类加载器，使用C++实现； ExtClassLoader：扩展类加载器，使用Java实现； AppClassLoader：应用程序类加载器，加载当前应用的classpath的所有类； UserDefinedClassLoader：用户自定义类加载器； 6.3、双亲委派机制类加载器的加载过程中使用到了双亲委派机制：当一个类收到了类加载请求，它首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载器(BootstrapClassLoader)中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class），子类加载器才会尝试自己去加载。 好处： 比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个 Object对象。 6.4、沙箱安全机制沙箱安全机制是由基于双亲委派机制上采取的一种JVM的自我保护机制，假设我们自定了一个java.lang.String 的类，由于双亲委派机制，加载请求会先交给BootstrapClassLoader启动类加载器试图去进行加载，但是BootstrapClassLoader在加载类时首先通过包和类名查找rt.jar中有没有java.lang.String，有则优先加载rt.jar包中的类，由于rt.jar中已经包含了java.lang.String类，所以我们自定义的String类永远得不到加载(当然编译是不会报错的)，它保证了Java源代码的安全。 7、其他独立知识点7.1、内存逃逸分析 见本文《2.4.3、堆内存区 - 逃逸分析》章节 7.2、直接内存 见本文《2.4.6、堆外内存区》章节 7.3、Java内存屏障7.3.1、什么是内存屏障（Memory Barrier）？ 内存屏障（memory barrier）是一个CPU指令。 ​ 通过在代码中插入这样一条指令可达到几种目的效果： 作用一：干预编译器的指令重排行为，确保内存屏障前后的代码指令有严格的先后执行顺序。 作用二：内存屏障的另一个作用是强制更新一次不同CPU的缓存。以此来主动影响一些数据的可见性。 例如，一个写屏障会把这个屏障前写入的数据刷新到缓存，这样任何试图读取该数据的线程将得到最新值，而不用考虑到底是被哪个cpu核心或者哪颗CPU执行的。 7.3.2、为什么需要内存屏障 在多CPU（核）场景下，为了充分利用CPU，会通过流水线将指令并行进行。为了能并行执行，又需要将指令进行重排序以便进行并行执行，那么问题来了，那些指令不是在所有场景下都能进行重排，除了本身的一些规则（如Happens Before 规则）之外，我们还需要确保多CPU的高速缓存中的数据与内存保持一致性, 不能确保内存与CPU缓存数据一致性的指令也不能重排，内存屏障正是通过阻止屏障两边的指令重排序来避免编译器和硬件的不正确优化而提出的一种解决办法。 7.3.3、Java中内存屏障的主要类型Java内存屏障主要有Load和Store两类。 对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据 。 对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存。 对于Load和Store，在实际使用中，又分为以下四种： 1、LoadLoad 屏障：序列：Load1，Loadload，Load2 。 确保Load1所要读入的数据能够在被Load2和后续的load指令访问前读入。通常能执行预加载指令或/和支持乱序处理的处理器中需要显式声明Loadload屏障。 2、StoreStore 屏障：序列：Store1，StoreStore，Store2 。 确保Store1的数据在Store2以及后续Store指令操作相关数据之前对其它处理器可见（例如向主存刷新数据）。 3、LoadStore 屏障：序列： Load1，LoadStore， Store2 。 确保Load1的数据在Store2和后续Store指令被刷新之前读取。在等待Store指令可以越过loads指令的乱序处理器上需要使用LoadStore屏障。 4、StoreLoad 屏障：序列: Store1，StoreLoad， Load2 。 确保Store1的数据在被Load2和后续的Load指令读取之前对其他处理器可见。 7.3.4、Java中内存屏障的使用 1、Synchronized 通过 Synchronized关键字包住的代码区域，当线程进入到该区域读取变量信息时，JVM保证读到的是最新的值。这是因为在同步区内对变量的写入操作，在离开同步区时就将当前线程内的数据刷新到内存中，而对数据的读取也不能从缓存读取，只能从内存中读取，保证了数据的读有效性。这就是插入了StoreStore屏障 2、volatile 知识点：如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 使用了volatile修饰变量，则对变量的写操作，会插入StoreLoad屏障。 大致过程： 1、在volatile变量的作用域插入内存屏障，防止指令重排序 2、通过内存屏障，强制将本CPU的修改操作立即写入主存。此时会利用缓存一致性机制，组织多个CPU同时刷主存的此数据区域。 3、本CPU回写volatile字段数据到主存后，其他CPU的嗅探技术会发现此字段已被回写过主存了，其他CPU的嗅探技术会将它的字段缓存设置为无效，其他CPU下次访问此字段时没，会强制从主存读最新值。 3、Unsafe类 UNSAFE.putOrderedObject类似这样的方法,会插入StoreStore内存屏障 Unsafe.putVolatiObject 则是插入了StoreLoad屏障 7.4、Java的平台无关性 Java的平台无关性(一次编译、到处运行)得益于： 1、统一的Class字节码文件格式； 2、统一的JVM 规范 (指令集，内存模型，操作数栈架构)； JVM将平台相关性的活给干了，屏蔽了差异。 JVM不止有”平台无关性”，还有”语言无关性”，只要最终能编译成符合Class字节码文件格式规范要求的，都能在JVM上运行。如：Coljure, Groovy, JRuby, Scala等 7.5、Java对象引用类型对象引用类型分为强引用、软引用、弱引用、虚引用。 强引用：就是我们一般声明对象时是虚拟机生成的引用，强引用环境下，垃圾回收时需要严格判断当前对象是否被强引用，如果被强引用，则不会被垃圾回收。对应到我们日常写的代码。 软引用：软引用一般被作为缓存来使用。与强引用的区别是，软引用在垃圾回收时，虚拟机会根据当前系统的剩余内存来决定是否对软引用进行回收。如果剩余内存紧张，则虚拟机会回收软引用所引用的空间。 弱引用：弱引用与软引用类似，都是作为缓存来使用。但与软引用不同，弱引用在进行垃圾回收时，是一定会被回收掉的，因此其生命周期只存在于一个垃圾回收周期内。 “软引用”和“弱引用”比较少见。 他们一般被作为缓存使用，而且一般是在内存大小比较受限的情况下做为缓存。因为如果内存足够大的话，可以直接使用强引用作为缓存即可，同时可控性更高。 虚引用：使用虚引用的目的就是为了得知对象被GC的时机，可以利用虚引用来进行销毁前的一些操作，比如说资源释放等。虚引用一个很重要的用途就是用来做堆外内存的释放，DirectByteBuffer就是通过虚引用来实现堆外内存的释放的。 7.6 、容器化环境中的JVM内存设置须知在JDK10前，JVM是无法感知容器环境存在的，JVM获取到的有关系统硬件的指标都是实际物理机的CPU和内存指标。这其实对于JVM运行环境来说是不合理的。 Java在JDK10以后，开始了对容器资源限制的支持（支持向linux cgroup获取容器内的硬件资源指标），可以使用-XX:+UseContainerSupport参数来指定JVM使用容器的内存指标，注：此参数是JVM内默认开启的。（其他类似的JVM还有：-XX:InitialRAMPercentage； -XX:MaxRAMPercentage等） 值得庆幸的是，其中一些功能已被移植到JDK-8u131及以后的版本。在JDK-8u131+及java9，需要加上”-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap”才能使得Xmx感知docker的memory limit。 我们知道JVM对于CPU和内存都有默认取值逻辑，且这个对于JVM的运行性能影响非常大。这个值设置的不对会严重影响线上应用的可用性和性能。 推荐： 建议大家部署Java应用时，必须设置明确的”Xms,Xmx”。减少外部依赖或假设，以减少未知风险的发生概率。 7.7、怎么构造方法区OOM？先牢记知识点方法区存的是哪些东西：“已被虚拟机加载的类信息、常量、静态变量、编译器编译后的代码等数据” 观察这些存放的信息里，哪几个在JVM运行期是动态的？ 运行期产生大量的动态类。 持续高频使用String.intern()方法，产生大量常量。 怎么优化？ 通过工具查看方法区大量的动态类的来源代码。 一般方法区的溢出是由于大量的动态类，而动态类往往来自于框架或三发SDK。基本没的干预，所以一般是调大方法区大小。 7.8、怎么构造Java内存泄露Java 中的内存泄露的情况:长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这 就是 Java 中内存泄露的发生场景 例如 缓存系统，我们加载了一个对 象放在缓存中 (例如放在一个全局 map 对象中)，然后一直不再 使用它，这个对象一直被缓存引用，但却不再被使用。 如果一个外部类的实例对象的方法返回了一个内部类的实例对象， 这个内部类对象被长期引用了，即使那个外部类实例对象不再被使 用，但由于内部类持久外部类的实例对象，这个外部类对象将不会 被垃圾回收，这也会造成内存泄露。 内存泄露的另外一种情况:当一个对象被存储进 HashSet 集合中 以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否 则，对象修改后的哈希值与最初存储进 HashSet 集合中时的哈希 值就不同了，在这种情况下，即使在 contains 方法使用该对象的 当前引用作为的参数去 HashSet 集合中检索对象，也将返回找不 到对象的结果，这也会导致无法从 HashSet 集合中单独删除当前 对象，造成内存泄露。 &gt;&gt;&gt;&gt; 更多内容，很快到来 &lt;&lt;&lt;&lt;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务API设计之——API命名规范]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%9C%8D%E5%8A%A1API%E8%AE%BE%E8%AE%A1%E4%B9%8B%E2%80%94%E2%80%94API%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[API命名规范命名风格 面向资源 同RESTful命名风格 在大型系统中，常以”业务领域”视角进行模块划分，以达到业务”高内聚低耦合”的效果。 “业务领域”必有”数据对象”沉淀，从宏观抽象的角度看，&quot;数据对象&quot;可统称为&quot;资源&quot;，”业务领域”就是业务相近的”资源”的集合。 &quot;资源&quot;一定是业务抽象后的对象： 可以是具体的数据对象： 商品 订单 合同 发票 采购计划 etc 可以是抽象的对象概念： 租户 用户 支付 文件 需求 etc &quot;业务领域&quot;与&quot;业务领域&quot;之间的依赖，可理解为是对&quot;资源&quot;操作(读、写、通知)的依赖。 所以，API作为&quot;业务领域&quot;间沟通的手段，其应该(Should)以面向资源角度进行命名。 注：子资源，需要逐级索引命名，例如：修改-订单-商品：updateOrderItem。 单一视角 参见单一视角原则 动宾风格API应该(Should)以&quot;动宾短语&quot;风格命名。 例如： 12345xxx.xxx.xxx.OrderService // 上下文已涵盖Order语义Response&lt;T&gt; save(...) Response&lt;T&gt; updateItem(Long orderId, List&lt;T&gt; items) 1234567xxx.xxx.xxx.WCService // 上下文未涵盖Order语义Response&lt;T&gt; saveOrder(...) Response&lt;Boolean&gt; removeOrder(Long orderId) Response&lt;T&gt; updateOrderItem(Long orderId, List&lt;T&gt; items) // 逐级索引子资源 统一术语API命名统一”动词”术语、”名词”术语。优点是能风格一致，经验复用。 详见政采云API术语参考 注：统一术语的节奏，参考研发级术语规范逐步执行：业务内统一、业务领域内统一、平台统一。 错误实践-1：”商品”命名不统一1234业务1：商品 -&gt; item ✔️业务2：商品 -&gt; items业务3: 商品 -&gt; product业务4：商品 -&gt; goods 错误实践-2：”特性”命名不统一123业务1：特性 -&gt; feature ✔️业务2: 特性 -&gt; character业务3：特性 -&gt; rule 错误实践-3：”金额”命名不统一123业务1：金额 -&gt; amount ✔️业务2: 金额 -&gt; money业务3：金额 -&gt; sum 错误实践-4：”校验”命名不统一123业务1：校验 -&gt; verify业务2: 校验 -&gt; check ✔️业务3：校验 -&gt; test 错误实践-5：”分页”命名不统一123业务1：分页 -&gt; page业务2: 分页 -&gt; paging✔️业务3：分页 -&gt; list 错误实践-6：”创建”命名不统一123业务1：创建 -&gt; save✔️业务2: 创建 -&gt; create业务3：创建 -&gt; insert 错误实践-7：”删除”命名不统一1234业务1：删除 -&gt; delete业务2: 删除 -&gt; remove✔️业务3：删除 -&gt; disable 业务3：删除 -&gt; cancel 错误实践-8：”检索”命名不统一123业务1：搜索 -&gt; query✔️业务2: 搜索 -&gt; search业务3：搜索 -&gt; list 常见API命名参考 假设：未按资源划分Service(上下文未界定资源域)的情况 “XXX”指某一种资源，”xxx”指”XXX”下的子资源 分页查询 正确实践 1Response&lt;Page&lt;T&gt;&gt; pagingXXX(QueryDTO q) //用对象包装查询条件 错误实践 1Response&lt;Page&lt;T&gt;&gt; pagingXXX(String name, String code, Long orgId, Long creatorId, Integer pageNo, Integer PageSize) 以上错误实践缺点：1、对于调用方来说，无论以什么条件查询，都需要逐个条件传参2、API对扩展不友好，一旦想增加查询条件，API就不兼容。 列表查询 正确实践 1Response&lt;List&lt;T&gt;&gt; listXXX(...) 获取单个详情 正确实践 12345Response&lt;T&gt; getXXX(Long id) 类同条件，用重载Response&lt;T&gt; getXXX(String code) 错误实践 123Response&lt;T&gt; getXXXById(Long id) Response&lt;T&gt; getXXXByCode(String code) 说明： API契约应该由”API名 + 入参”共同组成，而不是只靠”API名”说明一切。 API方法支持获取单个详情的方式，可以通过入参字段名自解释。无需再用”By***”来额外标注。 不带”By***”声明的方法语义上更具有扩展性。 创建 正确实践 1Response&lt;T&gt; saveXXX(...) //参照《阿里巴巴Java编码规范》 删除 正确实践 1Response&lt;T&gt; removeXXX(...) //参照《阿里巴巴Java编码规范》 更新 正确实践 123Response&lt;T&gt; updateXXX(...) //参照《阿里巴巴Java编码规范》Response&lt;T&gt; updateXXXxxx(...) //更新主资源下的子资源 提审 正确实践 1Response&lt;T&gt; submitXXX(...) 审核 正确实践 1Response&lt;T&gt; auditXXX(...) 退回（退回到流程中的某一步） 正确实践 1Response&lt;T&gt; returnXXX(...) 撤销（退回到流程的第一步） 正确实践 1Response&lt;T&gt; cancelXXX(...)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>API</tag>
        <tag>API命名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务API设计之——API错误返回规范]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%9C%8D%E5%8A%A1API%E8%AE%BE%E8%AE%A1%E4%B9%8B%E2%80%94%E2%80%94API%E9%94%99%E8%AF%AF%E8%BF%94%E5%9B%9E%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[API错误返回规范禁止通过抛异常形式返回API业务错误API禁止抛Checked异常，即业务处理上的参数错误、逻辑错误、业务错误等禁止通过抛异常形式返回，应用Response#code, message表达业务错误。 注：不要逼调用方到处写try{}catch()。 正例： 1Response&lt;T&gt; saveDesposit(...); 反例： 1T saveDesposit(...) throws ServiceException, IllegalArgumentException, ValidationException; 禁止通过抛异常形式返回API业务错误API禁止抛Checked异常，即业务处理上的参数错误、逻辑错误、业务错误等禁止通过抛异常形式返回，应用Response#code, message表达业务错误。 注：不要逼调用方到处写try{}catch()。 正例： 1Response&lt;T&gt; saveDesposit(...); 反例： 1T saveDesposit(...) throws ServiceException, IllegalArgumentException, ValidationException; 需要调用方做错误细分处理的，API提供方务必一并提供判断工具类 正例： 1234567891011public void saveXXX()&#123; Response&lt;T&gt; result = xxxWriteService(...) if (!result.isSuccess())&#123; if (xxxUtils.isBankUnSupport(result.getCode))&#123; &lt;&lt;&lt;API提供方提供工具类解析code含义，且code含义可持续迭代更新，调用方无感知。 //银行渠道未开通，需要特殊提示 ... &#125;else&#123; ... &#125; &#125;&#125; 反例： 1234567891011public void saveXXX()&#123; Response&lt;T&gt; result = xxxWriteService(...) if (!result.isSuccess())&#123; if (&quot;10101&quot;.equals(result.getCode))&#123; &lt;&lt;&lt;调用方按API提供方的错误码值做硬编码，代码耦合。 //银行渠道未开通，需要特殊提示 ... &#125;else&#123; ... &#125; &#125;&#125; 【推荐】API返回可直接显示给用户的中文提示信息API失败时，只有API实现方最清楚是什么原因，该怎么提示。那么，请提供对应的提示信息。 我们系统中存在一些用国际化风格的error message，而当前的国际化实现方式真如你想的那么好用吗？ error message国际化原理： 代码中的提示信息国际化配置文件 国际化提示原理 1) 提示信息国际化的行为发生在Web层，Web层启动时会加载Web层的resources/messages提示信息文件 2)当REST API需要返回提示信息时，Web会根据HTTP 请求中的Locale值（例如：zh_CN、zh_TW、en_US、es_ES_Traditional_WIN等）来决定返回哪一种语言的提示信息。将errorMessage以此种语言方式返回给浏览器进行提示。 问题： 1）在分布式系统中，各个应用按领域自治，其resources/messages只维护了自身业务需要的errorMessage。 2）当图中C Service 将errorMessage = template.status.not.match 返回给 XX Service，XX Service直接透传给XX Web的情况下，XX Web的resources/messages是不包括template.status.not.match的，所以此errorMessage将无法正确的展示其本应该提示的信息。 所以，推荐API返回可直接显示给用户的中文提示信息。 正例： 123456789101112public Response&lt;Boolean&gt; saveTemplate(...) &#123; try&#123; ... &#125;catch(StateMachineException e)&#123; log.warn(&quot;...&quot;); ... return Response.fail(&quot;模板配置正在审核中，请在审核完成后再更新&quot;); &#125;catch(Exception e)&#123; ... &#125;&#125; 反例： 123456789101112public Response&lt;Boolean&gt; saveTemplate(...) &#123; try&#123; ... &#125;catch(StateMachineException e)&#123; log.warn(&quot;...&quot;); ... return Response.fail(&quot;模板管理状态机异常&quot;); &#125;catch(Exception e)&#123; ... &#125;&#125; 【推荐】返回具备可读性，引导性的错误提示信息 正例： 123456789101112public Response&lt;Boolean&gt; saveTemplate(...) &#123; try&#123; ... &#125;catch(StateMachineException e)&#123; log.warn(&quot;...&quot;); ... return Response.fail(&quot;模板配置正在审核中，请在审核完成后再更新&quot;); &#125;catch(Exception e)&#123; ... &#125;&#125; 反例： 例1 123456789101112public Response&lt;Boolean&gt; saveTemplate(...) &#123; try&#123; ... &#125;catch(StateMachineException e)&#123; log.warn(&quot;...&quot;); ... return Response.fail(&quot;模板管理状态机异常&quot;); &lt;&lt;&lt;&lt; 你作为用户，是不是吓一跳？ &#125;catch(Exception e)&#123; ... &#125;&#125; 例2 123456789101112public Response&lt;Boolean&gt; saveTemplate(...) &#123; try&#123; ... &#125;catch(StateMachineException e)&#123; log.warn(&quot;...&quot;); ... return Response.fail(e.getMessage()); &lt;&lt;&lt;&lt; message谁都看不懂，没有任何意义 &#125;catch(Exception e)&#123; ... &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>API</tag>
        <tag>错误码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务API设计之——API版本规范]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%9C%8D%E5%8A%A1API%E8%AE%BE%E8%AE%A1%E4%B9%8B%E2%80%94%E2%80%94API%E7%89%88%E6%9C%AC%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[API版本规范发布RELEASE版本正式发布的api包必须是RELEASE版本 eg. 12345&lt;dependency&gt; &lt;groupId&gt;cn.gov.zcy.paas.template&lt;/groupId&gt; &lt;artifactId&gt;template-api&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 版本号风格使用 《Semantic Versioning》风格 概述Version号由 “MAJOR.MINOR.PATCH” 三段组合构成，version号增加含义： MAJOR version：【主版本号】代表API发生了不兼容的变更，即使是微小的不兼容。 MINOR version：【次版本号】代表以兼容的方式新增了功能、特性 PATCH version：【补丁版本号】代表以兼容的方式做了bugfix 用法 / FAQ版本号以0开始 X.Y.Z 三个版本号都是以0开始。 【特别注意】当版本号是 “1.0.9.RELEASE”时，它的下一个补丁版本号是”1.0.10.RELEASE” ！！！ 而不是”1.1.0.RELEASE”，这里不存在满十进位之说。 初始 MAJOR version 初始MAJOR version以0开始，代表业务的初始开发阶段，这过程中功能上任何改变都可能发生，此时的API是不稳定的。 初始版本一旦发布生产环境，即将MAJOR version变更为1，即 1.0.0.RELEASE。是第一个基线版本。 预发布版本 可以通过在补丁版本之后紧跟附加连字符和一系列点分隔标识符来表示预发布版本。标识符必须仅包含ASCII字母数字和连字符[0-9A-Za-z-]。标识符不能为空。数字标识符不得包含前导零。 预发布版本的优先级低于关联的普通版本。 预发布版本表示版本不稳定，可能无法满足其关联的正常版本所表示的预期兼容性要求。示例：1.0.0-alpha，1.0.0-alpha.1,1.0.0-0.3.7,1.0.0-x.7.z.92]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>API</tag>
        <tag>API版本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务API设计之——API参数规范]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%9C%8D%E5%8A%A1API%E8%AE%BE%E8%AE%A1%E4%B9%8B%E2%80%94%E2%80%94API%E5%8F%82%E6%95%B0%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[【强制】字段名称用小驼峰风格【强制】Service API返回值必须使用Response包装 Service API返回值强制要求进行通用包装，例如：Response。 Response的作用： 统一方法表示API调用是否成功 API调用失败时，统一格式反馈错误Code，错误Message 统一的Response易于调用方经验复用，框架集成 作为API调用方，其编码诉求很简单： API调用是否成功； 调用不成功时，提示文案是什么； 调用方几不想： 不想关心API内部有多牛逼 不想关心API可能会抛的各种Exception，以及因此不得不做各种异常处理 关于当前不统一的Response 【新业务】【强制】使用架构组定义的统一Response：ZCY Response 目前业务方有自定义Result/Response，风格和作用大同小异。有更好的设计可以自荐给架构组集成，杜绝各自开辟重复的新定义。 【强制】杜绝完全不规范的缩写，避免望文不知义。（国际通用缩写除外） 错误实践 AbstractClass“缩写”命名成 AbsClass; condition“缩写”命名成 condi； 此类随意缩写严重降低了代码的可阅读性。 【强制】禁止使用 Map 作为参数类型Map&lt;K,V&gt;机制非常灵活，但这样的灵活却是负作用巨大。 Map的数据说明是晦涩的，调用方、实现方之间需要具有隐式的契约解释支持哪些Key，每个Key的Value是什么类型。增加了双方的使用复杂度。 Map&lt;K,V&gt;不可被校验。加之第1条的使用复杂度，导致使用上非常容易出错。 用Map类型字段做预留扩展性的设计都是不优雅的设计。 注：参数中的调用方自定义数据部分允许使用Map。API提供方不关系、不解析、只透传。 【强制】业务对象/查询条件用DTO封装，禁止以入参方式平铺字段。 正确实践 分页查询，将查询条件以DTO方式包装。 Dubbo序列化特点： Dubbo API的POJO类中，UID不一致：没关系。 Dubbo API的POJO类中，字段数量不一致：没关系，只要字段名和类型一致，数据能反序列化成功。 发送方比接收方的字段多：没关系。 发送方比接收方的字段少：没关系。 1Response&lt;Page&lt;T&gt;&gt; pagingXXX(QueryDTO q) 错误实践 1Response&lt;Page&lt;T&gt;&gt; pagingXXX(String name, String code, Long orgId, Long creatorId, Integer pageNo, Integer PageSize) 以上错误实践缺点：1、对于调用方来说，无论以什么条件查询，都需要逐个条件传参。2、API对扩展不友好，一旦想增加查询条件，API就不兼容。 【推荐】DTO字段设置JSR303 Annotation进行基础校验 正确实践 123public interface ZcyPayFacade &#123; Result&lt;Boolean&gt; validTradePay(@NotNull @Valid TradePayPO tradePayPO);&#125; 1234567891011121314151617181920212223242526272829303132333435public class TradePayPO implements Serializable &#123; @NotBlank @Length(max = 15) /** 业务交易编号(订单编号) */ private String businessTradeNo; /** * 业务渠道：1-订阅，2-CA * @see BusinessTypeEnum * * */ @NotNull @Range(min = 1, max = 2) private Integer businessType; ...... /** 商户名称(商家) */ @NotBlank @Length(max = 50) private String merchantName; /** 订单标题（即商品名称），粗略描述用户的支付目的。如“喜士多（浦东店）消费”*/ @NotBlank @Length(max = 256) private String orderSubject; /** 订单描述（即商品描述），可以对交易或商品进行一个详细地描述，比如填写&quot;购买商品2件共15.00元&quot;*/ @NotBlank @Length(max = 128) private String orderBody; ......&#125; 【推荐】在客户端完成基础字段校验 方式1：【推荐】自定义Dubbo Filter实现通用拦截、校验。 方式2：【推荐】通过Builder模式构建入参对象。 方式3：【不推荐】Dubbo 客户端参数校验，要求consumer方设置validation=”true”，Dubbo 客户端参数校验。缺点：以抛异常方式处理校验失败，需要业务方额外处理Exception。而且，IDE并不会提示consumer方需要处理ConstraintViolationException。 方式4：Dubbo方式，local-stub特性。实现较复杂，校验代码通用性低。Dubbo local-stub 注：此规范与《阿里巴巴Java编码规范》互补，同时有效。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>API</tag>
        <tag>API规范</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务API设计之——API设计原则]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%9C%8D%E5%8A%A1API%E8%AE%BE%E8%AE%A1%E4%B9%8B%E2%80%94%E2%80%94API%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[你是否也感同身受？ 对接XX业务时，XX业务具备的功能和API全靠跑业务负责人那反复逐个询问、确认。用哪个API；怎么用；有没有限制；等等 各个业务间，甚至同一业务内，API风格不统一。 API命名：按自然语义全翻译的；按属性角度定义的；按操作角度定义的；动宾、非动宾的；复数、非复数的；等等 API入参：带Map的；相同语义字段名称不一样； API出参：有包装Resoponse的；直接返回结果数据的；相同数据，返回格式和字段名称有差别的； 错误信息：直接返回中文提示的；返回提示信息编码的；返回异常类型的；等等 XX业务API性能方面未知。 随着业务的演进，开放的API持续在增加，但类同的很多 API编码规范迫在眉睫 优秀API的特质 自解释 从API本身一眼就能看懂API是干什么的，支持的用法，适用的场景，异常的处理等 易学习 有完善的文档，以及提供尽可能多的示例和可copy－paste的代码。 易使用 功能强大，但使用简单。不增加调用方的使用成本（例如要求业务方用API时需要额外的配置和依赖），不暴露复杂的细节、冗长的使用流程给调用方感知。调用方只做最小的感知和最少的传参。 难误用 优秀的API可以使有经验的开发直接使用API而不需要阅读文档。 充分的静态检查、动态校验、显式的异常说明、有效的错误提示。 ZCY API 设计原则1. 充分原则不是随便一个功能就要有个接口，也不是随便一个需求就要加个接口。 每新建一个接口，要有充分的理由和考虑，即这个接口的存在是十分有意义和价值的。无意义的接口不仅增加了维护的难度，更重要是对于程序的可控性的大大降低，接口也会十分臃肿。 2. 单一视角原则设计接口时，分析的角度要统一。否则会造成接口结构的混乱。例如：不要一会以角色的角度设计，一会儿就要以功能的角度设计。 推荐：以”属性对象 + 行为”的视角定义API 3. 单一功能原则每个API接口应该只专注一件事，并做好。产品概念简单、关系清楚。功能模棱两可，诸多特殊逻辑的API肯定不是个优雅的API，且会造成功能类似重复的API。 注：如果API它很难命名，那么这或许是个不好的征兆，好的名称可以驱动开发、并且只需拆分与合并模块即可。 功能大而全的API在灵活性、简单性方面肯定捉襟见肘。定义API的粒度之前，建议先将业务分领域、划边界，以此来提取业务对象，然后再根据业务对象用例来设计单一功能的API。 比如：查询会员，可能除了查询会员表外还要获取该会员的其他必要信息，但不要在查询会员的同时还有修改权限等类似的其他业务功能，应该分成两个接口执行。 4. 简单原则接口设计简单、清晰。API执行的功能可以很丰富、很强大，但API声明和用法一定要尽量的简单，不能将功能的丰富通过复杂的用法来实现，这会导致API功能不单一，演进不可控。 最终的评审要看API的简单易用程度。 你写的例子，能不能让你的代码看起来更简单？ 你是不是强迫调用方关注/提供他们不在乎的选项/配置？ 有没有毫无价值的额外步骤？ 编写的代码一定要易于读、易于理解，这样别人才会欣赏，也能够给你提出合理化的建议。相反，若是繁杂难解的程序，其他人总是会避而远之的。 5. 抽象原则API的入参、出参所述的对象、属性，一定是按业务特性进行抽象后的实体。误将底层数据模型概念如实的反应到API上。抽象API、抽象对象实体更宏观，具有更好的适用性、兼容性、扩展性。 6. 兼容扩展原则对扩展开放，对修改关闭。保证API的向后兼容。 扩展参数应当是便利的，保证后续类似的需求，可以在已有的API上通过兼容扩展的方式实现。 7. 最小惊讶原则代码应该尽可能减少让读者惊喜。业务API只需根据需求来设计即可，不需要刻意去设计一下复杂无用、华而不实的API，以免弄巧成拙。 8. 低耦合原则API应该减少对其他业务代码的依赖关系。低耦合往往是完美结构系统和优秀设计的标志。 耦合的种类： 代码实现业务逆向调用。 条件逻辑依赖耦合。例如：此API在处理国税网超订单类型时，需要额外发送结算支付凭证上传的事件MQ出来。 耦合API无关的业务行为。例如：采购计划链路日志API被调用时，若是项目采购委托单的情况，需要额外调用公告的API拉取链路信息，新建成为一条此委托单的一条链路日志。 9. 正交原则正交性是指改变某个特性而不会影响到其他的特性。 API之间的功能应该成正交性，无功能重合。API之间应该是互相补充的关系。 10. 易测试原则对于API调用者而言，API应该是可被测试且易于被测试的。测试API不需要依赖额外的环境、容器、配置、公共服务等。 对可测试友好的API也是可被有效集成测试的前提。 11. 统一原则API要具备统一的命名、统一的入/出参规范、统一的异常规范、统一的错误码规范、统一的版本规范等。 统一规范的API优点： 易于被框架集成、处理 有助于API调用方、API提供方开发经验复用 避免犯错，避免误用]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>API</tag>
        <tag>API设计原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JStorm-分享资料]]></title>
    <url>%2F2018%2F09%2F16%2FJStorm-%E5%88%86%E4%BA%AB%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[JStorm分享-课件资料]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>实时计算</tag>
        <tag>JStorm</tag>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring数据库原理-事务管理]]></title>
    <url>%2F2018%2F08%2F11%2FSpring%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86-%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[知识点分解核心类对象 对象 一句话介绍 PlatformTransactionManager Spring事务的核心底层interface，定义了事务核心方法 AbstractPlatformTransactionManager Spring标准事务处理流程的抽象基类，定义了Spring事务处理框架 TransactionDefinition 事务属性相关。事务隔离级别；超时；传播行为；等 TransactionStatus 事务实例状态对象，可供查询，用于回滚、SavePoint等场景 DataSourceTransactionManager Spring框架TransactionManager的典型实现 TransactionTemplate 将编程式上下文多个步骤合并成一个核心的execute方法，方便事务编程 PlatformTransactionManager jar包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;&lt;/dependency&gt; Spring事务的核心底层interface，定义了事务核心方法：getTransaction, commit, rollback。 AbstractPlatformTransactionManager jar包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;&lt;/dependency&gt; Spring标准事务处理流程的抽象基类，定义了Spring事务处理框架。 AbstractPlatformTransactionManager 利用模板方式定义了Spring标准事务的处理流程，并提供了必须的默认实现，且将doBengin, doSuspend, doResume, doCommit, doRollback等方法开放给继承类实现。 AbstractPlatformTransactionManager 提供了如下事务流程功能 确定是否已存在事务 处理事务传播行为 控制事务的暂停和恢复 检查commit上的rollback-only标记 在回滚时进行必要的处理 触发已注册的事务同步回调。trigger[Before/After][Begin/Commit/Rollback/…]系列，参见：TransactionSynchronizationUtils。 DataSourceTransactionManager jar包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; Spring TransactionManager的典型实现类。 继承了AbstractPlatformTransactionManager类，并做了完整的实现。可供编程式事务开发。也可作为TransactionManager的具体实现注入到如TransactionTemplate， Mybatis SqlSessionFactory中去。 TransactionTemplate jar包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;&lt;/dependency&gt; TransactionTemplate 提供的是便捷的编程式事务的方法，将编程式上下文多个步骤合并成一个核心的execute方法。 其本身不具备事务管理的机制，需要通过注入PlatformTransactionManager的Bean实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class TransactionTemplate extends DefaultTransactionDefinition implements TransactionOperations, InitializingBean &#123; public TransactionTemplate(PlatformTransactionManager transactionManager) &#123; this.transactionManager = transactionManager; &#125; // 核心方法 @Override public &lt;T&gt; T execute(TransactionCallback&lt;T&gt; action) throws TransactionException &#123; if (this.transactionManager instanceof CallbackPreferringPlatformTransactionManager) &#123; return ((CallbackPreferringPlatformTransactionManager) this.transactionManager).execute(this, action); &#125; else &#123; TransactionStatus status = this.transactionManager.getTransaction(this); T result; try &#123; result = action.doInTransaction(status); &#125; catch (RuntimeException ex) &#123; // Transactional code threw application exception -&gt; rollback rollbackOnException(status, ex); throw ex; &#125; catch (Error err) &#123; // Transactional code threw error -&gt; rollback rollbackOnException(status, err); throw err; &#125; catch (Exception ex) &#123; // Transactional code threw unexpected exception -&gt; rollback rollbackOnException(status, ex); throw new UndeclaredThrowableException(ex, "TransactionCallback threw undeclared checked exception"); &#125; this.transactionManager.commit(status); return result; &#125; &#125; private void rollbackOnException(TransactionStatus status, Throwable ex) throws TransactionException &#123; logger.debug("Initiating transaction rollback on application exception", ex); try &#123; this.transactionManager.rollback(status); &#125; catch (TransactionSystemException ex2) &#123; logger.error("Application exception overridden by rollback exception", ex); ex2.initApplicationException(ex); throw ex2; &#125; catch (RuntimeException ex2) &#123; logger.error("Application exception overridden by rollback exception", ex); throw ex2; &#125; catch (Error err) &#123; logger.error("Application exception overridden by rollback error", ex); throw err; &#125; &#125;&#125; @Transactional 声明式事务理解Spring事务的核心对象和配合关系后，再来看Spring框架的声明式事务机制@Transactional就很简单了。 sprint-tx包中的ProxyTransactionManagementConfiguration会去配置关于@Transactional注解的处理机制。其中核心的是注册了TransactionInterceptor作为切面事务处理类 当执行声明式事务的代码块之前，会优先被TransactionInterceptor拦截，先执行TransactionInterceptor#invoke进行事务包围。 TransactionAspectSupport#invokeWithinTransaction 12345678910111213141516171819public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable &#123; @Override public Object invoke(final MethodInvocation invocation) throws Throwable &#123; // Work out the target class: may be &#123;@code null&#125;. // The TransactionAttributeSource should be passed the target class // as well as the method, which may be from an interface. Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // Adapt to TransactionAspectSupport's invokeWithinTransaction... return invokeWithinTransaction(invocation.getMethod(), targetClass, new InvocationCallback() &#123; @Override public Object proceedWithInvocation() throws Throwable &#123; return invocation.proceed(); &#125; &#125;); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; //内部其他方法详见TransactionAspectSupport源码 protected Object invokeWithinTransaction(Method method, Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // If the transaction attribute is null, the method is non-transactional. final TransactionAttribute txAttr = getTransactionAttributeSource().getTransactionAttribute(method, targetClass); final PlatformTransactionManager tm = determineTransactionManager(txAttr); final String joinpointIdentification = methodIdentification(method, targetClass); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try &#123; // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // target invocation exception completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; commitTransactionAfterReturning(txInfo); return retVal; &#125; else &#123; // It's a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in. try &#123; Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, new TransactionCallback&lt;Object&gt;() &#123; @Override public Object doInTransaction(TransactionStatus status) &#123; TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); try &#123; return invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; if (txAttr.rollbackOn(ex)) &#123; // A RuntimeException: will lead to a rollback. if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new ThrowableHolderException(ex); &#125; &#125; else &#123; // A normal return value: will lead to a commit. return new ThrowableHolder(ex); &#125; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; &#125; &#125;); // Check result: It might indicate a Throwable to rethrow. if (result instanceof ThrowableHolder) &#123; throw ((ThrowableHolder) result).getThrowable(); &#125; else &#123; return result; &#125; &#125; catch (ThrowableHolderException ex) &#123; throw ex.getCause(); &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Spring</tag>
        <tag>数据库事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring数据库原理-DataSource]]></title>
    <url>%2F2018%2F08%2F11%2FSpring%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86-DataSource%2F</url>
    <content type="text"><![CDATA[DataSource引言用Spring进行Web应用开发时，我们经常会做datasource的配置。而且datasource的配法风格各异。那么他们到底有哪些异同点呢？ DataSource作用DataSource是javax.sql包中的类，是Java原生rt.jar包中的类。 1234567public interface DataSource extends CommonDataSource, Wrapper &#123; Connection getConnection() throws SQLException; Connection getConnection(String username, String password) throws SQLException;&#125; javax.sql.DataSource定义的是抽象方法，通过Java JNDI的方式将具体实现开放给各个厂商、组织自己、个人自己实现。 在Spring框架中，通过DataSource + 配置的方式，来定义具体的数据库源。并向Spring框架提供数据源的Connection服务。 在Spring中若想实现多数据源，那么就需要在DataSource下手。 javax.sql.DataSource源码注释说明1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * &lt;p&gt;A factory for connections to the physical data source that this * &#123;@code DataSource&#125; object represents. An alternative to the * &#123;@code DriverManager&#125; facility, a &#123;@code DataSource&#125; object * is the preferred means of getting a connection. An object that implements * the &#123;@code DataSource&#125; interface will typically be * registered with a naming service based on the * Java&amp;trade; Naming and Directory (JNDI) API. * &lt;P&gt; * The &#123;@code DataSource&#125; interface is implemented by a driver vendor. * There are three types of implementations: * &lt;OL&gt; * &lt;LI&gt;Basic implementation -- produces a standard &#123;@code Connection&#125; * object * &lt;LI&gt;Connection pooling implementation -- produces a &#123;@code Connection&#125; * object that will automatically participate in connection pooling. This * implementation works with a middle-tier connection pooling manager. * &lt;LI&gt;Distributed transaction implementation -- produces a * &#123;@code Connection&#125; object that may be used for distributed * transactions and almost always participates in connection pooling. * This implementation works with a middle-tier * transaction manager and almost always with a connection * pooling manager. * &lt;/OL&gt; * &lt;P&gt; * A &#123;@code DataSource&#125; object has properties that can be modified * when necessary. For example, if the data source is moved to a different * server, the property for the server can be changed. The benefit is that * because the data source&apos;s properties can be changed, any code accessing * that data source does not need to be changed. * &lt;P&gt; * A driver that is accessed via a &#123;@code DataSource&#125; object does not * register itself with the &#123;@code DriverManager&#125;. Rather, a * &#123;@code DataSource&#125; object is retrieved though a lookup operation * and then used to create a &#123;@code Connection&#125; object. With a basic * implementation, the connection obtained through a &#123;@code DataSource&#125; * object is identical to a connection obtained through the * &#123;@code DriverManager&#125; facility. * &lt;p&gt; * An implementation of &#123;@code DataSource&#125; must include a public no-arg * constructor. * * @since 1.4 */ 概要翻译 Part - 1: DataSource是获取物理数据源连接的工厂类。 作为DriverManager工具的替代方案，DataSource对象是获取连接的首选方法. DataSource的实现类一般都通过JNDI的方式注册到框架中进行使用。 Part - 2: DataSource一般由数据库厂商提供对应的实现类，DataSource有三种实现方式 基本实现，生成标准连接对象。 连接池实现，适用于中间层连接池管理器。 分布式事务实现。此实现适用于中间层事务管理器，并且几乎总是使用连接池管理器。 Part - 3: DataSource向Spring框架屏蔽了具体数据源的差异，即当物理数据源切换时，只需要更新相关的DataSource配置值即可，不需要应用层修改代码。 Part - 4: 数据库Driver都是通过DataSource对象被注册到DriverManager中，而不是由Driver直接向DriverManager注册。 但是对于获取Connection，先通过检索先获得DataSource，再根据DataSource对象进行getConnection，而不是直接从DriverManager获取Connection。 Spring-JDBC的DataSource实现案例 在 Spring-jdbc 下，DataSource 最顶级的类是 AbstractDataSource ，对 DataSource 的所有父接口方法做了实现。但保留 getConnection() 方法由子类实现。 在 AbstractDriverBasedDataSource 中，定义了大量的参数，诸如 url, username 等，这些都被用来定位并定义与数据库实例的连接。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package org.springframework.jdbc.datasource;import java.sql.Connection;import java.sql.SQLException;import java.util.Properties;import org.springframework.lang.UsesJava7;import org.springframework.util.Assert;public abstract class AbstractDriverBasedDataSource extends AbstractDataSource &#123; private String url; private String username; private String password; private String catalog; private String schema; private Properties connectionProperties; public AbstractDriverBasedDataSource() &#123; &#125; ......略 public Connection getConnection() throws SQLException &#123; return this.getConnectionFromDriver(this.getUsername(), this.getPassword()); &#125; public Connection getConnection(String username, String password) throws SQLException &#123; return this.getConnectionFromDriver(username, password); &#125; @UsesJava7 protected Connection getConnectionFromDriver(String username, String password) throws SQLException &#123; Properties mergedProps = new Properties(); Properties connProps = this.getConnectionProperties(); if(connProps != null) &#123; mergedProps.putAll(connProps); &#125; ......略 return con; &#125; protected abstract Connection getConnectionFromDriver(Properties var1) throws SQLException;&#125; 整合方案为将除 url 外的所有参数整合在同一个 Properties 对象中 (其中，Properties 可以被认为是一个线程安全的 Hash Map) 。最终调用 Connection getConnectionFromDriver(Properties props) 获取连接。 AbstractDriverBasedDataSource 抽象类的两个子类 DriverManagerDataSource 和 SimpleDriverDataSource 都以不同方式获得了连接(Connection)，但总结而言，获取连接(Connection) 的任务被委托给了 Driver 来实现。 1234567891011121314151617181920212223242526272829303132333435// ----------------------------// SimpleDriverDataSource 的实现// ----------------------------@Overrideprotected Connection getConnectionFromDriver(Properties props) throws SQLException &#123; Driver driver = getDriver(); String url = getUrl(); Assert.notNull(driver, "Driver must not be null"); if (logger.isDebugEnabled()) &#123; logger.debug("Creating new JDBC Driver Connection to [" + url + "]"); &#125; return driver.connect(url, props);&#125;// -----------------------------// DriverManagerDataSource 的实现// -----------------------------@Overrideprotected Connection getConnectionFromDriver(Properties props) throws SQLException &#123; String url = getUrl(); Assert.state(url != null, "'url' not set"); if (logger.isDebugEnabled()) &#123; logger.debug("Creating new JDBC DriverManager Connection to [" + url + "]"); &#125; // 调了个内部函数 return getConnectionFromDriverManager(url, props);&#125;protected Connection getConnectionFromDriverManager(String url, Properties props) throws SQLException &#123; // 委托给 DriverManager 类来获取连接 // DriverManager 的主要操作是遍历在该管理类中注册的 Driver // 每个 Driver 实例都去尝试一下，能不能获得一个连接 // 第一次在某个 Driver 中拿到一个连接即返回连接 (Connection) return DriverManager.getConnection(url, props);&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Spring</tag>
        <tag>DataSource</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo源码解析-Consumer启动]]></title>
    <url>%2F2018%2F06%2F02%2FDubbo%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-Consumer%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[Dubbo Consumer的启动过程和Provider一样，以DubboNamespaceHandler为起点，去解析代码配置中的ReferenceBean。 1public class ReferenceBean&lt;T&gt; extends ReferenceConfig&lt;T&gt; implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean &#123; ReferenceBean同样既继承了ReferenceConfig，又实现了InitializingBean。也是在afterProperitesSet()中去执行服务引用 ReferenceBean afterPropertiesSet ReferenceConfig init() 完成service interface的class， methods解析 获取Service 注册中心registeries配置信息，用于向注册中西订阅service 检测是否配置有Dubbo Mock， Dubbo Stub createProxy()完成ReferenceConfig + Registeries ——》 Dubbo Service Invoker的转化。createProxy()返回时，返回的是被Proxy后的Invoker，即外层加了Dubbo Filter Chain。 DubboProtocol.refer(…) DubboProtocolDubboProtocol.class 作为Dubbo RPC层的具体实现协议，尤其完成Consumer中向注册中心真正订阅的动作。 1234567891011121314151617181920212223242526272829303132public class DubboProtocol extends AbstractProtocol &#123; ... public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; optimizeSerialization(url); // create rpc invoker with url. DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker; &#125; private ExchangeClient[] getClients(URL url) &#123; // whether to share connection boolean service_share_connect = false; int connections = url.getParameter(Constants.CONNECTIONS_KEY, 0); // if not configured, connection is shared, otherwise, one connection for one service if (connections == 0) &#123; service_share_connect = true; connections = 1; &#125; ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) &#123; if (service_share_connect) &#123; clients[i] = getSharedClient(url); &#125; else &#123; clients[i] = initClient(url); &#125; &#125; return clients; &#125; ...&#125; Invoker12345678910111213141516171819public interface Invoker&lt;T&gt; extends Node &#123; /** * get service interface. * * @return service interface. */ Class&lt;T&gt; getInterface(); /** * invoke. * * @param invocation * @return result * @throws RpcException */ Result invoke(Invocation invocation) throws RpcException;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class DubboInvoker&lt;T&gt; extends AbstractInvoker&lt;T&gt; &#123; //与Service Provider端的连接 private final ExchangeClient[] clients; //同一service的invokers集合，集群时用到。 private final Set&lt;Invoker&lt;?&gt;&gt; invokers; ... public DubboInvoker(Class&lt;T&gt; serviceType, URL url, ExchangeClient[] clients, Set&lt;Invoker&lt;?&gt;&gt; invokers) &#123; super(serviceType, url, new String[]&#123;Constants.INTERFACE_KEY, Constants.GROUP_KEY, Constants.TOKEN_KEY, Constants.TIMEOUT_KEY&#125;); this.clients = clients; // get version. this.version = url.getParameter(Constants.VERSION_KEY, "0.0.0"); this.invokers = invokers; &#125; @Override protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; final String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(Constants.PATH_KEY, getUrl().getPath()); inv.setAttachment(Constants.VERSION_KEY, version); ExchangeClient currentClient; if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123; currentClient = clients[index.getAndIncrement() % clients.length]; &#125; try &#123; boolean isAsync = RpcUtils.isAsync(getUrl(), invocation); boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); int timeout = getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (isOneway) &#123; boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture(null); return new RpcResult(); &#125; else if (isAsync) &#123; ResponseFuture future = currentClient.request(inv, timeout); RpcContext.getContext().setFuture(new FutureAdapter&lt;Object&gt;(future)); return new RpcResult(); &#125; else &#123; RpcContext.getContext().setFuture(null); return (Result) currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException e) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, "Invoke remote method timeout. method: " + invocation.getMethodName() + ", provider: " + getUrl() + ", cause: " + e.getMessage(), e); &#125; catch (RemotingException e) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, "Failed to invoke remote method: " + invocation.getMethodName() + ", provider: " + getUrl() + ", cause: " + e.getMessage(), e); &#125; &#125; ...&#125; ReferenceConfig 核心数据12345678910111213141516171819202122232425262728public class ReferenceConfig&lt;T&gt; extends AbstractReferenceConfig &#123; //核心是DubboProtocol private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); //集群模式下使用，此处不解释 private static final Cluster cluster = ExtensionLoader.getExtensionLoader(Cluster.class).getAdaptiveExtension(); //注册中心地址 private final List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); // interface name private String interfaceName; private Class&lt;?&gt; interfaceClass; // client type private String client; // url for peer-to-peer invocation private String url; // Service的方法列表 private List&lt;MethodConfig&gt; methods; // default config private ConsumerConfig consumer; private String protocol; // invoker 的代理类 private transient volatile T ref; //原生的service invoker private transient volatile Invoker&lt;?&gt; invoker; private transient volatile boolean initialized; private transient volatile boolean destroyed;&#125; ConsumerModel经过ReferenceConfig一番处理后，最终会得到：Reference Dubbo Service Name, InvokerRef, Service Methods, ReferenceConfig Instance。 这些信息会封装成ConsumerModel，放到ApplicationModel.class中去全局统一记录Consumer的情况。 1234567public class ConsumerModel &#123; private ReferenceConfig metadata; private Object proxyObject; private String serviceName; private final Map&lt;Method, ConsumerMethodModel&gt; methodModels = new IdentityHashMap&lt;Method, ConsumerMethodModel&gt;(); ...&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[翻译] REST API必须是超文本驱动的]]></title>
    <url>%2F2018%2F05%2F20%2F%E7%BF%BB%E8%AF%91-REST-API%E5%BF%85%E9%A1%BB%E6%98%AF%E8%B6%85%E6%96%87%E6%9C%AC%E9%A9%B1%E5%8A%A8%E7%9A%84%2F</url>
    <content type="text"><![CDATA[原文地址：Roy T. Fielding: REST APIs must be hypertext-driven I am getting frustrated by the number of people calling any HTTP-based interface a REST API. Today’s example is the SocialSite REST API. That is RPC. It screams RPC. There is so much coupling on display that it should be given an X rating. 我是越来越失望了，许多人把任何基于HTTP的接口叫做REST API，眼前的例子就是SocialSite REST API。那是RPC，实实在在的RPC。它与显示如此耦合，再差也莫过于此 What needs to be done to make the REST architectural style clear on the notion that hypertext is a constraint? In other words, if the engine of application state (and hence the API) is not being driven by hypertext, then it cannot be RESTful and cannot be a REST API. Period. Is there some broken manual somewhere that needs to be fixed? 基于超文本概念，如何才能确保清晰的REST架构风格呢？这样来说吧，如果应用程序状态引擎（即API）不是由超文本驱动的，那就不是RESTful也不是REST的API。就这么简单。某些REST方面的破手册是否该修正一下呢？ API designers, please note the following rules before calling your creation a REST API: API的设计者们，把你们的那些东西叫做REST API前请注意以下的规则： A REST API should not be dependent on any single communication protocol, though its successful mapping to a given protocol may be dependent on the availability of metadata, choice of methods, etc. In general, any protocol element that uses a URI for identification must allow any URI scheme to be used for the sake of that identification. [Failure here implies that identification is not separated from interaction.] REST API不应依赖于任何特定的通讯协议，在采用某个具体协议时可能受限于元数据的有效性、方法的选择等。通常，协议元素使用URI作标识时，对该标识必须允许运用任何URI方案。[ 不符合这一点意味着标识与交互没有分离 ] A REST API should not contain any changes to the communication protocols aside from filling-out or fixing the details of underspecified bits of standard protocols, such as HTTP’s PATCH method or Link header field. Workarounds for broken implementations (such as those browsers stupid enough to believe that HTML defines HTTP’s method set) should be defined separately, or at least in appendices, with an expectation that the workaround will eventually be obsolete. [Failure here implies that the resource interfaces are object-specific, not generic.] REST API不应修改通讯协议中预留出来作为补充或修正标准协议用途的资源，例如HTTP的PATCH方法和Link head域。违背了这一原则的方案应当单独定义，或者至少在附录中标注出来这样的方案最终会废弃掉。[ 不符合这一点意味着资源接口是对象相关的，不通用 ] A REST API should spend almost all of its descriptive effort in defining the media type(s) used for representing resources and driving application state, or in defining extended relation names and/or hypertext-enabled mark-up for existing standard media types. Any effort spent describing what methods to use on what URIs of interest should be entirely defined within the scope of the processing rules for a media type (and, in most cases, already defined by existing media types). [Failure here implies that out-of-band information is driving interaction instead of hypertext.] REST API应当将绝大部分精力放在媒体类型的定义上，或者是扩展关系名称的定义、已有超文本标记中的标准媒体类型等方面，以实现资源的表述、操作应用程序状态。任何类似于对某某URI应当使用什么样的方法等工作，都应当完全定义在特定媒体类型的处理规则范围中（绝大部分情况下已有媒体类型都已经定义好了这些规则）。[ 不符合这一点意味着交互是由其它信息驱动，而不是超文本 ] A REST API must not define fixed resource names or hierarchies (an obvious coupling of client and server). Servers must have the freedom to control their own namespace. Instead, allow servers to instruct clients on how to construct appropriate URIs, such as is done in HTML forms and URI templates, by defining those instructions within media types and link relations. [Failure here implies that clients are assuming a resource structure due to out-of band information, such as a domain-specific standard, which is the data-oriented equivalent to RPC’s functional coupling]. REST API决不能定义固定的资源名称或者层次关系（这是明显的客户端、服务器端耦合），服务器必须可以自由控制自己的名称空间。应当像HTML forms和URI模板一样，通过媒体类型和链接关系指示客户端如何构造正确的URI。[ 不符合这一点意味着客户端在通过其它信息（例如领域相关标准）猜测资源结构，这是数据导向，类似于RPC的函数耦合 ] A REST API should never have “typed” resources that are significant to the client. Specification authors may use resource types for describing server implementation behind the interface, but those types must be irrelevant and invisible to the client. The only types that are significant to a client are the current representation’s media type and standardized relation names. [ditto] REST API决不能使用对客户端有重要意义的类型化资源。规范的作者可能使用资源类型描述接口背后的服务器端实现，但这些类型必须与客户端无关，对客户端不可见。对客户端唯一有意义的类型是当前的表述性媒体类型和标准的关系名称。[ 同上 ] A REST API should be entered with no prior knowledge beyond the initial URI (bookmark) and set of standardized media types that are appropriate for the intended audience (i.e., expected to be understood by any client that might use the API). From that point on, all application state transitions must be driven by client selection of server-provided choices that are present in the received representations or implied by the user’s manipulation of those representations. The transitions may be determined (or limited by) the client’s knowledge of media types and resource communication mechanisms, both of which may be improved on-the-fly (e.g., code-on-demand). [Failure here implies that out-of-band information is driving interaction instead of hypertext.] 使用REST API应该只需要知道初始URI（书签）和一系列针对目标用户的标准媒体类型（任何客户端都了解用来操作该媒体类型的API）。这样所有的应用程序状态转换都通过这样的方式进行：服务器在返回的表述性消息中提供选项，由客户端进行选择，或者是伴随着用户对表述性内容的操作而进行。状态转换由客户端对媒体类型的了解程度和资源通讯机制决定，或者受限于这些因素，这些问题都可以根据实际情况得以改善的（例如使用javascript这种code-on-demand技术）。[ 不符合这一点意味着交互是由其它信息驱动，而不是超文本 ] There are probably other rules that I am forgetting, but the above are the rules related to the hypertext constraint that are most often violated within so-called REST APIs. Please try to adhere to them or choose some other buzzword for your API. 也许还有其它一些规则我一时想不起来了，但在那些所谓的REST API中通常都违背了上面这些超文本约束相关的规则，请纠正这些错误或者改用其它称谓吧]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>REST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful API命名实践]]></title>
    <url>%2F2018%2F05%2F18%2FRESTful-API%E5%91%BD%E5%90%8D%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[引言在互联网高度普及的今天，作为一名Web开发者，如果你还没听说过“REST”这个技术名词，出门都不好意思跟人打招呼。尽管如此，对于REST这个泊来品的理解，大多数人仍然停留在“盲人摸象”的阶段。 有人认为，在Web Controller层写的API就是REST API。而且，从开发角度对于URI的命名、HTTP Mehthod的选择没有建立起规范的意识。这样是不优雅的！（没有对错之分） 作为带着问题学习总结的我，未打算通过本篇文档全面的阐述清楚REST，而是尽量的总结一些理论和思考，一起探讨！ REST 的诞生Web 技术发展Web开发技术的发展可以粗略划分成以下几个阶段： 静态内容阶段：在这个最初的阶段，使用Web的主要是一些研究机构。Web由大量的静态HTML文档组成，其中大多是一些学术论文。Web服务器可以被看作是支持超文本的共享文件服务器。 可以想象下当时的HTTP请求只有“GET”，且MIME为“HTML或TEXT” CGI程序阶段：在这个阶段，Web服务器增加了一些编程API。通过这些API编写的应用程序，可以向客户端提供一些动态变化的内容。Web服务器与应用程序之间的通信，通过CGI（Common Gateway Interface）协议完成，应用程序被称作CGI程序。 脚本语言阶段：在这个阶段，服务器端出现了ASP、PHP、JSP、ColdFusion等支持session的脚本语言技术，浏览器端出现了Java Applet、JavaScript等技术。使用这些技术，可以提供更加丰富的动态内容。 瘦客户端应用阶段：在这个阶段，在服务器端出现了独立于Web服务器的应用服务器。同时出现了Web MVC开发模式，各种Web MVC开发框架逐渐流行，并且占据了统治地位。基于这些框架开发的Web应用，通常都是瘦客户端应用，因为它们是在服务器端生成全部的动态内容。 RIA应用阶段：在这个阶段，出现了多种RIA（Rich Internet Application）技术，大幅改善了Web应用的用户体验。应用最为广泛的RIA技术是DHTML+Ajax。Ajax技术支持在不刷新页面的情况下动态更新页面中的局部内容。同时诞生了大量的Web前端DHTML开发库，例如Prototype、Dojo、ExtJS、jQuery/jQuery UI等等，很多开发库都支持单页面应用（Single Page Application）的开发。其他的RIA技术还有Adobe公司的Flex、微软公司的Silverlight、Sun公司的JavaFX（现在为Oracle公司所有）等等。 移动Web应用阶段：在这个阶段，出现了大量面向移动设备的Web应用开发技术。除了Android、iOS、Windows Phone等操作系统平台原生的开发技术之外，基于HTML5的开发技术也变得非常流行。 REST 的诞生从上述Web开发技术的发展过程看，Web从最初其设计者所构思的主要支持静态文档的阶段，逐渐变得越来越动态化。Web应用的交互模式，变得越来越复杂：从静态文档发展到以内容为主的门户网站、电子商务网站、搜索引擎、社交网站，再到以娱乐为主的大型多人在线游戏、手机游戏。 Web发展到了1995年，在CGI、ASP等技术出现之后，沿用了多年、主要面向静态文档的HTTP/1.0协议已经无法满足Web应用的开发需求，因此需要设计新版本的HTTP协议。在HTTP/1.0协议专家组之中，有一位年轻人脱颖而出，显示出了不凡的洞察力，后来他成为了HTTP/1.1协议专家组的负责人。这位年轻人就是Apache HTTP服务器的核心开发者Roy Fielding，他还是Apache软件基金会的合作创始人。 所以，REST 并不是在互联网诞生之初就有的，它是在HTTP/1.1协议中才出现的，由Roy Thomas Fielding这位大神对Web技术做了深入的总结和分析，提出的一套网络软件的架构风格理论框架，当时Fielding为这种架构风格取了一个轻松愉快的名字：“REST” ———— Representational State Transfer（表述性状态转移） Roy Thomas Fielding 关于REST的论文 https://www.ics.uci.edu/~fielding/pubs/dissertation/fielding_dissertation.pdf REST 详解REST 架构风格问题：REST 究竟是什么？是一种新的技术、一种新的架构、还是一种新的规范？ 首先，REST是Web自身的架构风格，也是世界上最成功的分布式应用架构风格。它是为运行在互联网环境的分布式超媒体系统量身定制的。 REST是一种架构风格！ REST是一种架构风格！ REST是一种架构风格！ 所以，就会存在实际开发工作中即使没有正确的理解和应用REST，但也能顺利的完成开发工作。也正因为如此，给开发工作中推广正确实践和统一风格带来不小的困难。因为大多数程序员总是在寻找最快解决问题，最快完成需求的方式，怎么简单怎么来。 解读 RESTREST ———— Representational State Transfer (表现层状态转化) 从“Representational State Transfer”这个定义去理解REST架构风格原则。 1. 资源（Resources）REST 的名称“表现层状态转化”中，省略了主语。“表现层”其实指的是“资源（Resources）”的“表现层” 资源是一种看待服务器的方式，此处指的“资源”是一个抽象的概念，它不仅仅指服务器端真实存在的文件、数据库表，而是指任何可被名词表述的东西。所以在定义“资源”时可以要多抽象就多抽象。 对于客户端，可以将服务器端看作是由很多离散的资源组成。服务端可以用URI（统一资源定位符）指向资源，每种资源都对应一个特定的URI。要向获取这个资源，访问它的URI就可以了，因此URI就成了每一个资源的地址或独一无二的识别符。 所谓“上网”，就是与互联网上一系列的“资源”互动，调用它的URI。 2. 表现层（Representation）“资源”是一种信息实体，它可以有多在的表现形式。我们把“资源”具体呈现出来的形式，叫做它的“表现层（Representation）” 比如，文本信息可以用txt格式表现，也可以用HTML格式 、XML格式、JSON格式表现，甚至可以用二进制格式；图片可以用JPG格式表现，也可以用PNG格式表现。 URI只代表资源的实体，不代表它的表现形式。资源的具体表现形式，应该在HTTP请求的的头部信息中用Accept和Content-Type字段指明，这两个字段才是对“表现层”的描述。 详见HTTP MIME明细 3. 状态转化（State Transfer）HTTP协议是一个无状态的协议，这意味着所有资源的状态都保存在服务器端。因为客户端想要操作服务器，必须通过某种手段，让服务器端资源发生“状态转化”。而这种转化是建立在表现层之上的，所以就是“表现层状态转化”。 客户端用到的手段，只能是HTTP协议。具体对应HTTP协议中的HTTP Method：GET、POST、PUT、PATCH、DELETE、HEAD、OPTIONS。每一种HTTP Method代表资源状态转化的一种约定的方式。 HTTP 动词 对于资源的具体操作类型，有HTTP动词表示。 常用的HTTP动词如下： 123456789- GET : 从服务器取出资源（一个或多个）- POST : 在服务器新建一个资源，并返回创建后的完整资源到客户端- PUT : 在服务器以覆盖形式，全量更新资源，并返回更新后的完整资源到客户端- PATCH : 在服务器端更新资源，但只更新指定的内容- DELETE : 在服务器端删除资源 其中，GET、PUT、PATCH、DELETE都应该是幂等的。 另外，HEAD、OPTIONS对于团队开发来说基本不用。 123- HEAD : 获取资源的元数据- OPTIONS : 获取信息，关于资源的哪些属性是客户端可以改变的 4. 综述综合上面的解读，总结一下什么是REST架构风格： (1) 服务器端的任何信息和数据都要被抽象资源化；(2) 资源用URI进行表述，每一个URI代表一种资源；(3) 客户端与服务器之间，基于某种表现层形式，互相传递资源；(4) 客户端与服务器之间，基于HTTP Method对服务器端资源的操作，实现“表现层状态转化”； REST 与 RESTful定义： 如果一个架构符合REST原则，就称它为RESTful架构 如果HTTP API的设计符合REST原则，那么可称它为RESTful API 所以，回到开篇讲的大多数人对于REST还是处于“盲人摸象”的阶段，回想下自己和身边的同事，在工作中经常交流到的REST API或RESTful API，其实只能算个HTTP API吧？ REST 风格优点架构风格不是非此即彼的是非题，在实际开发中可以自主的选择是否应用REST风格。那么，如果应用REST风格会带来哪些优势呢？ 从面向操作编程，转变为面向资源编程。更面向对象，架构更清晰、松耦合。 我们应该确定的认为系统由“资源+对资源的操作”组成，而不是由“操作”组成 面向操作编程会导致API膨胀，功能重复度高。 统一URI命名风格，URI具备很强的可读性，具备自解释的能力。服务器资源层次目录清晰。 状态无关。确保系统横向扩展的能力。 超文本驱动。确保系统演化的能力。 REST实践体会1. URI命名难度变大在没有要求URI必须用资源名词来组成URI时，URI的命名从来不是什么难事，常见的命名风格有： 动词+名词 /deposit/getUsers: 获取某个项目保证金用户列表 /orders/submitAudit: 订单提交审核 /cart/add: 商品加购物车 URI全局唯一即可 /finance/budget/getPurchaseplanNextAuditOrgList：我有点小无语… 为什么会这样： 我们平时搞系统是这样的： 有新建用户功能 新建用户需要一个URL 往这个URL发送的数据要定义好 开始写后端和前端 这是以操作为第一位的设计方法，首先确认了一个操作，然后围绕这个操作把周边需要的东西建设好，这种方式当然可以架构出一个系统，甚至是一个好系统，但是偶尔会有些问题： 操作之间是会有关联，你的设计容易变成“第2个操作要求第1个操作进行过”，这种关系多起来你的系统就乱了 你的URL设计会缺乏一致性 操作通常被认为是有副作用（Side Effect）的，所以很少有人基于操作去设计缓存之类的东西 该怎么应对？ 确实，REST是高度抽象的理论和风格，在实际开发中会面对各种复杂的功能和场景，导致很难完全的应用REST风格。当我们在争论REST风格到底如何设计才是正宗时，发现心中的困惑不仅没有降低，反而增加了。 我的想法：仍以真正的系统需求为出发点，使用REST风格让系统的架构更清晰，让系统的开发协作更高效。部分不适合REST的场景应该灵活变通。 回到URI的命名： 坚持URI仍以资源为导向，清晰的表述服务器端资源目录 保障URI资源层次清晰的情况下，只允许在URI最末一级添加动词，例如：/market/orders/1/audit 如果某些动作是HTTP动词表示不了的，考虑把动作抽象成一种资源 比如：网上汇款，从账户1向账户2汇款100元，错误的URI 1POST /accounts/1/transfer/500/to/2 正确的写法是把动词transfer改成名词transaction 1POST /transaction?from=1&amp;to=2&amp;amount=100 2. 用不用HTTP PATCHPATCH 作为HTTP的Method之一，其实它是2010年3月份才正式成为HTTP Method的，详见：RFC 5789 也正因为PATCH出现的晚, 所以并不是所有Web容器都支持，反而目前实现了PATCH方法的Web容器很少 几个常见Web容器实现PATCH方法的情况，供参考： Apache HttpComponents HttpClient version 4.2 or later 支持了 PATCH 目前 JDK7 的 HttpURLConnection 未实现 PATCH TOMCAT 7 也不行 PlayFramework 2 也不支持 Spring 3.2 开始支持 PATCH 方法，但要选对部署的容器 JBoss Netty 支持 PATCH，可见： http://docs.jboss.org/netty/3.2/api/org/jboss/netty/handler/codec/http/class-use/HttpMethod.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>RESTful</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引合并]]></title>
    <url>%2F2018%2F05%2F06%2FMySQL%E7%B4%A2%E5%BC%95%E5%90%88%E5%B9%B6%2F</url>
    <content type="text"><![CDATA[历史背景MySQL 5.0版本之前，一个表一次只能选择并使用一个索引。 MySQL 5.1版本开始，引入了Index Merge Optimization技术，使得MySQL支持一个表一次查询同时使用多个索引。 官方文档：MySQL Index Merge Optimization Index Merge Optimization支持三种合并算法 The Index Merge Intersection Access Algorithm 对应SQL 中的 AND 场景 The Index Merge Union Access Algorithm 对应SQL中的 OR 场景（where条件是等值判断） The Index Merge Sort-Union Access Algorithm 对应SQL中的 OR 场景（where条件是范围查询） 注：索引合并(Index Merge)的使用取决于optimizer_switch系统变量的index_merge，index_merge_intersection，index_merge_union和index_merge_sort_union标志的值。默认情况下，所有这些标志都打开。 要仅启用特定算法，请将index_merge设置为关闭，并仅启用其他应允许的其他算法。 ##关于”Index Merge Intersection Access Algorithm”的疑问 针对 MySQL Index Merge Optimization Intersection Algorithm AND 场景的 index merge optimization为什么会比使用单个索引来的高效？ 设想： 使用单个索引的场景 选中选择性高的索引先获得一份数据 在再mysql服务器端用using where的方式，按第二条件进行过滤，得到最终满足所有条件的数据行。 同时使用表内多个索引的场景 按每个索引，在索引树里拿只满足本索引条件的行数据 将两份行数据，放一块进行交集运算。 从索引的次数、磁盘IO、内存交接运算来看，事情没变少、反而变多了。 自我初版解释合理的解释样例SQL1select * from table_sample where column_1 = A AND column_2 = B; 前提条件，SQL中不能有范围查询，如果存在范围查询，数据库优化器默认使用单索引方式，不用index merge optimization SQL的WHERE从句中的所有条件字段都有对应的索引，否则问题就来了，肯定会在内存中有次using_where的。 单表多Index并行检索时，拿到的是数据行地址，以上述SQL为例，即拿到了两份行数据地址：Index Column_1的行数据地址集，Index Column_2的行数据地址集 再在内存中完成两份行数据地址集的交集运算（只需要比地址） 此时，再决定是否回表拿更多的数据。 如果字段中有primary key，就不用回表啦！ 如上的执行步骤，就会比较合理。有效率上的优势。 【更进一步】 explain 显示type 为 index_merge时，到底要不要引起关注？【需要引起注意】 拿着SQL琢磨下，是否还有优化的空间，例如：采用组合索引；强制走单索引（需要对比测试看效果，还要看业务数据场景和增长趋势）； 注： 当索引本身信息可以覆盖select的字段时（或是select count(*)）,效率会很高，因为内存索引里已经能提供返回的数据了，不用回表。 当索引本身信息不能覆盖select的字段时，就要回表查行数据了，性能差别很大。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL子查询很慢的问题分析]]></title>
    <url>%2F2018%2F05%2F04%2FMySQL%E5%AD%90%E6%9F%A5%E8%AF%A2%E5%BE%88%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[慢查询案例1DELETE FROM settlement_invoice_attachment g1 WHERE demand_id in (SELECT id FROM settlement_invoice_demand g2 WHERE statement_id = 1802065000000074956) 乍眼一看，上述SQL如此简单，且demand_id和statement_id字段都是建了索引，即使是Review也会认为是OK没问题的。 然而，实际情况却是个慢查询，情况如下： explain明细 settlement_invoice_attachment是全表查 注：rows 2689 是因为用的测试环境，真线环境数据是几十万级别 子查询 原理分析(上述SQL子查询为什么这么慢)经验之谈 当看到SQL执行计划中select_type字段出现“DEPENDENT SUBQUERY”的时候，要打起精神了！着重分析下潜在风险！ 基础知识：Dependent SubQuery意味着什么？ 官方含义为： SUBQUERY: 子查询中的第一个SELECT； DEPENDENT SUBQUERY: 子查询中的第一个SELECT， 取决于外面的查询。 换句话说，就是子查询的g2查询执行方式依赖于外层g1的查询结果什么意思呢？它以为着两步走： 第一步：【先执行外部SQL查询】MySQL根据”DELETE FROM settlement_invoice_attachment g1 WHERE” 得到一个大结果集t1，其数据量就是全表所有行了，假设是85万行。 第二步：【后执行内部SQL子查询】第一步的大结果集t1中的每一条记录，都将与子查询SQL组成新的查询语句：SELECT id FROM settlement_invoice_demand g2 WHERE statement_id = 1802065000000074956 AND id = %t1.demand_id%。等于说，子查询要执行85万次……即使这两部查询都用到了索引，也是巨慢的。 优化策略 改写SQL为JOIN的方式 12DELETE ah FROM settlement_invoice_attachment ah INNER JOIN settlement_invoice_demand de ON ah.demand_id = de.id WHERE de.statement_id = 1802065000000074956; 拆成独立SQL多次执行 平时怎么识别？ 看子查询出现的位置 若子查询出现在WHERE从句中，而且是出现在IN（）中，则需要引起注意，用Explain瞧瞧（并不是子查询放IN（）里就一定是全表扫，本案例用，将DELETE改成SELECT就不是DEPENDENT SUBQUERY） 数据库原理 MySQL处理子查询时，会(优化)改写子查询，但优化的不是很友好，一直受业界批评比较多 有时候优化的挺糟糕的，特别是WHERE从句中的IN（）子查询 MySQL 子查询的弱点 mysql 在处理子查询时，会改写子查询。通常情况下，我们希望由内到外，先完成子查询的结果，然后再用子查询来驱动外查询的表，完成查询。 例如：select * from test where tid in(select fk_tid from sub_test where gid=10)通常我们会感性地认为该 sql 的执行顺序是： 1、sub_test 表中根据 gid 取得 fk_tid(2,3,4,5,6)记录。2、然后再到 test 中，带入 tid=2,3,4,5,6，取得查询数据。 但是实际mysql的处理方式为：select from test where exists (select from sub_test where gid=10 and sub_test.fk_tid=test.tid)mysql 将会扫描 test 中所有数据，每条数据都将会传到子查询中与 sub_test 关联，子查询不会先被执行，所以如果 test 表很大的话，那么性能上将会出现问题。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo源码解析-Provider暴露服务]]></title>
    <url>%2F2018%2F05%2F02%2FDubbo%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-Provider%E6%9A%B4%E9%9C%B2%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[前言Dubbo Provider暴露服务的流程中，需要掌握几个核心抽象对象 过程中的重要类 ServiceConfig：记录了Dubbo Service所有相关的配置信息。ServiceConfig作用 DubboProtocol：以Dubbo协议的方式暴露服务，并以此为中心维护所有相关的动态服务数据。 RegisterProtocol: 内部会加载具体的注册中心Register,例如：ZookeeperRegister。完成服务向注册中心注册的动作。 ServiceConfig#loadRegistries：解析获得注册中心地址列表 过程中的重要对象 com.alibaba.dubbo.common.URL: 服务发布的地址 Invoker: 对原Service Interface进行了代理封装，屏蔽了具体Service Interface的差异，方便统一管理和调用。 Exporter： 一个ServiceBean每向一个注册中心Register注册一次，就会生成已各Exporter。Exporter用于连接暴露服务的Url与本地Invoker的对应关系。 ExporterMap: 记录着服务地址和Exporter的对应关系 来自Dubbo官方的几个架构设计图，先感觉下 ServiceBean核心流程 Spring容器启动，带动Dubbo Bean配置解析以及Bean实例化。 Dubbo启动 关键类： DubboNamespaceHandler ServiceBean ServiceConfig作用 ServiceBean 继承了ServiceConfig，所有的Provider服务的Dubbo配置都在ServiceConfig中。 Dubbo Service基本信息 Dubbo Service参数配置 注册中心地址信息。对应ServiceConfig中的loadRegistries(). ServiceBean 实现了InitializingBean, 实现了afterPropertiesSet()方法，在每个Dubbo Service Bean实例化后，在afterPropertiesSet()方法中进行所有Dubbo服务注册需要的操作。 afterPropertiesSet()中前置代码都是在做一些配置校验和默认值设置，最后会执行export()方法注册暴露服务。 afterPropertiesSet() export() doExport() doExportUrls() doExportUrlsFor1Protocol(DubboProtocol, regitsryURLs) DubboProtocol.export(wrapperInvoker) doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List registryURLs) 是真正执行export暴露服务的代码区 DubboProtocol#Export核心流程1234567891011121314151617181920212223242526272829public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; URL url = invoker.getUrl(); // export service. String key = serviceKey(url); DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); exporterMap.put(key, exporter); //export an stub service for dispatching event Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice) &#123; String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(new IllegalStateException("consumer [" + url.getParameter(Constants.INTERFACE_KEY) + "], has set stubproxy support event ,but no stub methods founded.")); &#125; &#125; else &#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125; //获取一个服务端口，使用NettyServer绑定并监听，并设置Server监听事件处理回调为：DubboProtocol#requestHandler //Exchanger.bind的实际对象可配置，对应dubbo-remoting-api包 openServer(url); optimizeSerialization(url); return exporter;&#125; DubboProtocol核心数据123456789101112131415161718192021222324252627public class DubboProtocol extends AbstractProtocol &#123; ... //单例 private static DubboProtocol INSTANCE; //本地启动Server监听服务的Map private final Map&lt;String, ExchangeServer&gt; serverMap = new ConcurrentHashMap&lt;String, ExchangeServer&gt;(); // &lt;host:port,Exchanger&gt; //记录消费端的Exchanger private final Map&lt;String, ReferenceCountExchangeClient&gt; referenceClientMap = new ConcurrentHashMap&lt;String, ReferenceCountExchangeClient&gt;(); // &lt;host:port,Exchanger&gt; // private final ConcurrentMap&lt;String, LazyConnectExchangeClient&gt; ghostClientMap = new ConcurrentHashMap&lt;String, LazyConnectExchangeClient&gt;(); // private final Set&lt;String&gt; optimizers = new ConcurrentHashSet&lt;String&gt;(); //consumer side export a stub service for dispatching event //servicekey-stubmethods private final ConcurrentMap&lt;String, String&gt; stubServiceMethodsMap = new ConcurrentHashMap&lt;String, String&gt;(); private ExchangeHandler requestHandler = &#123;...&#125;; ...&#125; 12345public abstract class AbstractProtocol implements Protocol &#123; // ExporterMap protected final Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap = new ConcurrentHashMap&lt;String, Exporter&lt;?&gt;&gt;();&#125; Dubbo Service是哪个时机注册到注册中心的？ 有关注到这个章节内容的小伙伴，说明你此时可能也还没想通吧，请听我道来。 这里会涉及到Dubbo的SPI机制，Dubbo 有好几个利用SPI+动态代理+Filter的处理责任链模式，ProtocolFilterWrapper.java算一个。 - Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 在Dubbo源码中，Dubbo有自行注册几个protocol SPI （这里只列举Dubbo服务注册相关的） SPI机制用法详见 Dubbo Protocol SPI扩展详见 RegistryProtocol SPI: 注册位置：dubbo-registry-api包,resources下的com.alibaba.dubbo.rpc.Protocol 注册位置：dubbo-registry-zookeeper包,resources下的com.alibaba.dubbo.register.RegistryFactory 其实，在ServiceConfig中拿到的全局protocol并不直接是DubboProtocol，而是一串Protocol，DubboProtocol只是其中之一，这些Protocol会以责任链的方式逐一被调用 所以，在doExportUrlsFor1Protocol中protocol.export(…)时，会先执行DubboProtocol#export,再执行RegisterProtocol#export,各司其职。 RegisterProtocol中会根据Dubbo Service配置的register地址类型来决定加载哪个具体的RegisterFactory 123456789101112131415161718public void register(URL registryUrl, URL registedProviderUrl) &#123; //RegisterFactory根据注册中心类型，获取到注册实例，例如ZookeeperRegistry Registry registry = registryFactory.getRegistry(registryUrl); //执行注册，实际对应ZookeeperRegistry#register registry.register(registedProviderUrl); &#125; public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; ... if (register) &#123; register(registryUrl, registedProviderUrl); ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); &#125; ... &#125; Netty Server当DubboProtocol.export.openServer()时，就是在本地启动Dubbo Service的Server服务并启动监听。 实现上是通过Exchanger拿到被配置的信息交换层的实现套件（一般是Netty）。 - 获取一个服务端口，使用NettyServer绑定并监听，并设置Server监听事件处理回调为：DubboProtocol#requestHandler - Exchanger.bind的实际对象可配置，对应dubbo-remoting-api包 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class NettyServer extends AbstractServer implements Server &#123; private static final Logger logger = LoggerFactory.getLogger(NettyServer.class); private Map&lt;String, Channel&gt; channels; // &lt;ip:port, channel&gt; private ServerBootstrap bootstrap; private org.jboss.netty.channel.Channel channel; public NettyServer(URL url, ChannelHandler handler); @Override protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerBoss", true)); ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory("NettyServerWorker", true)); ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap = new ServerBootstrap(channelFactory); final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); channels = nettyHandler.getChannels(); // https://issues.jboss.org/browse/NETTY-365 // https://issues.jboss.org/browse/NETTY-379 // final Timer timer = new HashedWheelTimer(new NamedThreadFactory("NettyIdleTimer", true)); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ChannelPipeline pipeline = Channels.pipeline(); /*int idleTimeout = getIdleTimeout(); if (idleTimeout &gt; 10000) &#123; pipeline.addLast("timer", new IdleStateHandler(timer, idleTimeout / 1000, 0, 0)); &#125;*/ pipeline.addLast("decoder", adapter.getDecoder()); pipeline.addLast("encoder", adapter.getEncoder()); pipeline.addLast("handler", nettyHandler); return pipeline; &#125; &#125;); // bind channel = bootstrap.bind(getBindAddress()); &#125; @Override protected void doClose(); public Collection&lt;Channel&gt; getChannels(); public Channel getChannel(InetSocketAddress remoteAddress); public boolean isBound();&#125; ServiceConfig作用(见代码注释)12345678910111213141516171819202122232425262728293031323334public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; ... // 采用的protocol远程调用层实现，用于封装RPC调用，默认是DubboProtocol，其余可选还有HttpProtocol,HessianProtocol,InjvmProtocol,RedisProtocol等 private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); //对ServiceBean进行代理，包装成Dubbo内部通用的Invoker private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); //ServiceBean作为Dubbo Provider启动时，会在本地起server服务，每个server服务都会绑定并监听端口。 private static final Map&lt;String, Integer&gt; RANDOM_PORT_MAP = new HashMap&lt;String, Integer&gt;(); //记录已暴露服务的服务地址 private final List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); //一个ServiceBean每向一个注册中心Register注册一次，就会生成已各Exporter。Exporter用于连接暴露服务的Url与本地Invoker的对应关系。 private final List&lt;Exporter&lt;?&gt;&gt; exporters = new ArrayList&lt;Exporter&lt;?&gt;&gt;(); //关于本ServiceBean的Java Class信息 private String interfaceName; private Class&lt;?&gt; interfaceClass; // reference to interface impl private T ref; // service name private String path; // method configuration private List&lt;MethodConfig&gt; methods; private ProviderConfig provider; private transient volatile boolean exported; private transient volatile boolean unexported; private volatile String generic; Dubbo 启动Spring容器启动，带动Dubbo Bean配置实例化。Dubbo Bean配置来自于Dubbo Provider XML 文件。 1234567891011121314151617181920public class DubboNamespaceHandler extends NamespaceHandlerSupport &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; public void init() &#123; registerBeanDefinitionParser("application", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser("module", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser("registry", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser("monitor", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser("provider", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser("consumer", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser("protocol", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser("service", new DubboBeanDefinitionParser(ServiceBean.class, true)); //dubbo provider bean配置解析 registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser("annotation", new AnnotationBeanDefinitionParser()); &#125;&#125; 具体详见笔记：Dubbo源码解析-Spring Bean注册 ServiceBean实例化123public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware &#123; ......&#125; ServiceBean 继承了ServiceConfig，所有的Provider服务的Dubbo配置都在ServiceConfig中。 ServiceBean 实现了InitializingBean, 实现了afterPropertiesSet()方法，在每个Dubbo Service Bean实例化后，进行暴露服务的相关操作。 afterPropertiesSet()中前置代码都是在做一些配置校验和默认值设置，最后会执行export()方法注册暴露服务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145public void afterPropertiesSet() throws Exception &#123; //如果没有配置provider if (getProvider() == null) &#123; //获取IOC容器里的所有provider Map&lt;String, ProviderConfig&gt; providerConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProviderConfig.class, false, false); if (providerConfigMap != null &amp;&amp; providerConfigMap.size() &gt; 0) &#123; Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false); if ((protocolConfigMap == null || protocolConfigMap.size() == 0) &amp;&amp; providerConfigMap.size() &gt; 1) &#123; // 兼容旧版本 List&lt;ProviderConfig&gt; providerConfigs = new ArrayList&lt;ProviderConfig&gt;(); for (ProviderConfig config : providerConfigMap.values()) &#123; if (config.isDefault() != null &amp;&amp; config.isDefault().booleanValue()) &#123; providerConfigs.add(config); &#125; &#125; //关联所有providers if (providerConfigs.size() &gt; 0) &#123; setProviders(providerConfigs); &#125; &#125; else &#123; ProviderConfig providerConfig = null; for (ProviderConfig config : providerConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (providerConfig != null) &#123; throw new IllegalStateException("Duplicate provider configs: " + providerConfig + " and " + config); &#125; providerConfig = config; &#125; &#125; if (providerConfig != null) &#123; setProvider(providerConfig); &#125; &#125; &#125; &#125; //如果没有配置application，且没有配置provider if (getApplication() == null &amp;&amp; (getProvider() == null || getProvider().getApplication() == null)) &#123; //获取所有applications Map&lt;String, ApplicationConfig&gt; applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false); if (applicationConfigMap != null &amp;&amp; applicationConfigMap.size() &gt; 0) &#123; ApplicationConfig applicationConfig = null; for (ApplicationConfig config : applicationConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (applicationConfig != null) &#123; throw new IllegalStateException("Duplicate application configs: " + applicationConfig + " and " + config); &#125; applicationConfig = config; &#125; &#125; //关联application if (applicationConfig != null) &#123; setApplication(applicationConfig); &#125; &#125; &#125; //如果没有配置module，且没有配置provider if (getModule() == null &amp;&amp; (getProvider() == null || getProvider().getModule() == null)) &#123; Map&lt;String, ModuleConfig&gt; moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false); if (moduleConfigMap != null &amp;&amp; moduleConfigMap.size() &gt; 0) &#123; ModuleConfig moduleConfig = null; for (ModuleConfig config : moduleConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (moduleConfig != null) &#123; throw new IllegalStateException("Duplicate module configs: " + moduleConfig + " and " + config); &#125; moduleConfig = config; &#125; &#125; //关联module if (moduleConfig != null) &#123; setModule(moduleConfig); &#125; &#125; &#125; //如果没有配置registries，且没有配置provider if ((getRegistries() == null || getRegistries().size() == 0) &amp;&amp; (getProvider() == null || getProvider().getRegistries() == null || getProvider().getRegistries().size() == 0) &amp;&amp; (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().size() == 0)) &#123; Map&lt;String, RegistryConfig&gt; registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false); if (registryConfigMap != null &amp;&amp; registryConfigMap.size() &gt; 0) &#123; List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;(); for (RegistryConfig config : registryConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; registryConfigs.add(config); &#125; &#125; //关联registries if (registryConfigs != null &amp;&amp; registryConfigs.size() &gt; 0) &#123; super.setRegistries(registryConfigs); &#125; &#125; &#125; //如果没有配置monitor，且没有配置provider if (getMonitor() == null &amp;&amp; (getProvider() == null || getProvider().getMonitor() == null) &amp;&amp; (getApplication() == null || getApplication().getMonitor() == null)) &#123; Map&lt;String, MonitorConfig&gt; monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false); if (monitorConfigMap != null &amp;&amp; monitorConfigMap.size() &gt; 0) &#123; MonitorConfig monitorConfig = null; for (MonitorConfig config : monitorConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (monitorConfig != null) &#123; throw new IllegalStateException("Duplicate monitor configs: " + monitorConfig + " and " + config); &#125; monitorConfig = config; &#125; &#125; //关联monitor if (monitorConfig != null) &#123; setMonitor(monitorConfig); &#125; &#125; &#125; //如果没有配置protocol，且没有配置provider if ((getProtocols() == null || getProtocols().size() == 0) &amp;&amp; (getProvider() == null || getProvider().getProtocols() == null || getProvider().getProtocols().size() == 0)) &#123; Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false); if (protocolConfigMap != null &amp;&amp; protocolConfigMap.size() &gt; 0) &#123; List&lt;ProtocolConfig&gt; protocolConfigs = new ArrayList&lt;ProtocolConfig&gt;(); for (ProtocolConfig config : protocolConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; protocolConfigs.add(config); &#125; &#125; //关联protocol if (protocolConfigs != null &amp;&amp; protocolConfigs.size() &gt; 0) &#123; super.setProtocols(protocolConfigs); &#125; &#125; &#125; //如果没有配置path if (getPath() == null || getPath().length() == 0) &#123; if (beanName != null &amp;&amp; beanName.length() &gt; 0 &amp;&amp; getInterface() != null &amp;&amp; getInterface().length() &gt; 0 &amp;&amp; beanName.startsWith(getInterface())) &#123; setPath(beanName); &#125; &#125; //暴露provider,重点！！！ if (! isDelay()) &#123; export(); &#125; &#125; Export暴露服务 export()方法会完成后续服务注册的所有流程 12345678910111213141516171819202122232425262728293031323334public synchronized void export() &#123; //如果provider没有配置 if (provider != null) &#123; //如果exporter没有配置使用provider所关联的exporter if (export == null) &#123; export = provider.getExport(); &#125; //如果delay（延迟暴露）没有配置，获取provider的delay if (delay == null) &#123; delay = provider.getDelay(); &#125; &#125; //如果不需要暴露接口则直接返回 if (export != null &amp;&amp; ! export.booleanValue()) &#123; return; &#125; //如果延迟暴露的时间（毫秒级）是存在的，开启线程并等待delay毫秒后开始暴露接口，否则直接执行暴露接口过程 if (delay != null &amp;&amp; delay &gt; 0) &#123; Thread thread = new Thread(new Runnable() &#123; public void run() &#123; try &#123; Thread.sleep(delay); &#125; catch (Throwable e) &#123; &#125; doExport(); &#125; &#125;); thread.setDaemon(true); thread.setName("DelayExportServiceThread"); thread.start(); &#125; else &#123; doExport(); &#125; &#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务端业务处理不成功，应该返回HTTP 200 还是 HTTP 4XXX系列？]]></title>
    <url>%2F2018%2F04%2F23%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%B8%9A%E5%8A%A1%E5%A4%84%E7%90%86%E4%B8%8D%E6%88%90%E5%8A%9F%EF%BC%8C%E5%BA%94%E8%AF%A5%E8%BF%94%E5%9B%9EHTTP-200-%E8%BF%98%E6%98%AF-HTTP-4XXX%E7%B3%BB%E5%88%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[场景其实，纠结只出现在例如保存表单的场景，如果服务端因各种业务上的原因（校验不通过，状态不满足等）导致保存未成功，并要返回对应的提示信息，此时服务端回应此HTTP 请求时，是用 “200 + json” 还是用“400 + 错误信息”？ 在公司内不同项目间，两种风格都有，且小伙伴们各执己见。 我这么看首先，我先表达我赞同“200 + json”的方式。 更具体些，服务端所有的Controller Method对返回值做统一的Response包装 1234567891011121314样例1：&#123; "code": 200, "data": &#123;...&#125;, "message":"操作成功"&#125;样例2：&#123; "success": false "data": &#123;...&#125;, "code": 100409, "message":"数据已存在"&#125; 我的观点1. 协议分层对于RPC请求，存在两个层面的操作结果 [1] HTTP请求本身的结果 ———— 业务无关性，与网络、框架层面相关[2] 业务处理的结果 ———— 强业务逻辑相关性，与网络、框架层面无关 为什么我们会有本贴讨论的话题与分歧，或者说为什么大部分人觉得http code不够试用，是因为实际开发应用场景中，尝试着只用http code 去表达上述两个层面的结果。 分层表示的优点： RPC请求， 是可以基于不同的底层协议的， 比如我们用的HTTP协议，很容易替换成ZeroMQ, RabbitMQ, UDP， 基于TCP的自定义协议…… 只要能实现一问一答模型的协议，都是可以用的。这个时候， HTTP协议只是一种底层协议， 底层协议的错误号，并不应该被上层协议使用。 2. HTTP Code 表达能力局限性虽然HTTP协议非常友好的定义了诸多的HTTP Code码，但在实际开发应用中，对于繁多的应用场景，HTTP Code的表达能力显得力不从心，部分场景仍旧不能避免的辅以Response Body信息。加之这些HTTP Code并不是应用开发中的绝对标准。 3. HTTP Code 语义表达的不统一性[1] 同样是HTTP 4XX系列，不同系统的解释也是不一样的[2] 同样是”参数校验不通过”的业务问题，不同系统使用的HTTP码也是不一样的 4. Http Code数量有限，表达能力有限这个应该很好理解，大家应该也有体会。 5. 系统集成友好性如果我们把HTTP协议当作一种传输层协议看待，200 可以很好表达， 整个底层传输都是没有问题， 包括负载均衡系统， nginx， 反向代理， fast cgi守护程序都是工作正常的。 而返回各种HTTP Status Code经常会让外部使用者非常的困惑，特别是他们对HTTP Status Code有一定了解，却对你的系统不甚了解的情况下。 所以，除了考虑ajax请求的处理，还要考虑整个调用的中间链路以及框架集成方面的因素 返回200能避免CDN等中间商替换或缓存 国内的通信运营商画蛇添足根据HTTP状态码给替换成导航页或广告推广页面 对于系统审计程序不友好，例如 HTTP Response Code = 4XX的请求算请求成功？请求失败？请求异常？————无法区分！ 6. 扩展性 返回200OK，扩展性更强，修改的时候只需要修改字段而不需要特别处理Status Code 易于与真正的400错误区分，方便审计和分析。而实际上，当服务器能够正常返回，证明服务器已经正确的理解并得出相应的结果（并且这个结果也是预定义的，并非未知），这显然与400的定义不符。 返回200更优。保不准哪天某种状态是HTTP协议不支持的，保不准哪个需要新增的字段是HTTP协议没有的]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>WEB</tag>
        <tag>REST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo源码解析-Spring Bean注册]]></title>
    <url>%2F2018%2F04%2F22%2FDubbo%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-Spring-Bean%E6%B3%A8%E5%86%8C%2F</url>
    <content type="text"><![CDATA[相信大家对于Dubbo Provider/Consumer的配置非常熟练，但这背后的实现原理清楚吗？如果有不太清楚的朋友，可以再往下阅读下。 知识点 自定义 Spring XML Bean机制 背景据我们所知 Spring 注解方式声明Bean的方式是在Class上打上@Component注解（@Component的扩展注解也可），当Spring容器启动时，Spring会自动扫面所有带有@Component注解的Class，自动注册到Bean容器中。 例如： 1234@Componentpublic class Student &#123; //do something&#125; 也可以通过XML文件配置的方式声明Bean 例如： 1&lt;bean id="Student" class="com.test.spring.beans.Student"&gt;&lt;/bean&gt; 但，回过头来看Dubbo，我们并没有通过上述的方式去声明Dubbo配置中的Bean，却也能像使用Spring Bean一样用@Autowire去注入Dubbo服务的Bean，这其中的原理是什么呢？让我们从源码中找答案。 原理启动Spring容器在SpringBoot+Dubbo的搭配中，Java应用的启动入口main方法一般会这么写。通过此步骤去启动Java程序并将Dubbo Bean注册Spring容器。 12345678910111213141516package com.sample;@ComponentScan(basePackages = &#123; "com.sample.myapp"&#125;)@SpringBootApplication@EnableSchedulingpublic class MyApplication &#123; public static void main(String[] args) &#123; //启动Spring容器 SpringApplication application = new SpringApplication(MyApplication.class, "classpath:/spring/dubbo-config.xml"); //指定Dubbo配置文件 application.run(args); &#125;&#125; Spring如何识别Dubbo 自定义Bean标签Spring为了支持用户自定义类加载到Spring容器，提供了org.springframework.beans.factory.xml.NamespaceHandler接口和org.springframework.beans.factory.xml.NamespaceHandlerSupport抽象类，NamespaceHandler#init方法会在对象的构造函数调用之后、属性初始化之前被DefaultNamespaceHandlerResolver调用。dubbo的DubboNamespaceHandler类正是继承了NamespaceHandlerSupport，其代码实现如下： 1234567891011121314151617181920public class DubboNamespaceHandler extends NamespaceHandlerSupport &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; public void init() &#123; registerBeanDefinitionParser("application", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser("module", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser("registry", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser("monitor", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser("provider", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser("consumer", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser("protocol", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser("service", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser("annotation", new AnnotationBeanDefinitionParser()); &#125;&#125; registerBeanDefinitionParser方法使用的是父抽象类NamespaceHandlerSupport的默认实现，第一个参数是elementName，即元素名称，即告诉Spring你要解析哪个标签，第二个参数是BeanDefinitionParser的实现类，BeanDefinitionParser是Spring用来将xml元素转换成BeanDefinition对象的接口。dubbo的DubboBeanDefinitionParser类就实现了这个接口，负责将标签转换成bean定义对象BeanDefinition。 所以，以后想要了解Dubbo Bean初始化相关细节，可以查看DubboBeanDefinitionParser#parse的代码实现。 例如： Dubbo Bean 会有哪些默认设置 dubbo服务提供者使用dubbo:service标签时，如果既不设置id，也不设置name，则dubbo给ServiceBean在Spring容器中定义的ID是什么？ Dubbo xml文件中的配置是怎么作用到Dubbo Bean中去的 关于NamespaceHandlerSupport spring.handlers # 指定xml namespace的解析handler类 spring.schemas # 指定xml xsd文件位置 dubbo.xsd # 设计你要的xml配置格式 DubboNamespaceHandler # 自定义NamespaceHandler,完成从xml中读取配置内容，并转换成Spring Bean进行注册 Spring容器会默认加载classpath/META-INF下的spring.handlers和spring.schemas两个文件，来加载xsd和对应的NamespaceHandler,所以dubbo-config-spring包下的META-INF目录下也有这两个文件 练习DEMO1. 设计配置属性和JavaBean 设计好配置项，并通过JavaBean来建模，本例中需要配置People实体，配置属性name和age（id是默认需要的） 12345public class People &#123; private String id; private String name; private Integer age; &#125; 2. 编写XSD文件 为上一步设计好的配置项编写XSD文件，XSD是schema的定义文件，配置的输入和解析输出都是以XSD为契约，本例中XSD如下 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;xsd:schema xmlns="http://veryjj/cutesource/schema/people" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:beans="http://www.springframework.org/schema/beans" targetNamespace="http://veryjj/cutesource/schema/people" elementFormDefault="qualified" attributeFormDefault="unqualified"&gt; &lt;xsd:import namespace="http://www.springframework.org/schema/beans" /&gt; &lt;xsd:element name="people"&gt; &lt;xsd:complexType&gt; &lt;xsd:complexContent&gt; &lt;xsd:extension base="beans:identifiedType"&gt; &lt;xsd:attribute name="name" type="xsd:string" /&gt; &lt;xsd:attribute name="age" type="xsd:int" /&gt; &lt;/xsd:extension&gt; &lt;/xsd:complexContent&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt; &lt;/xsd:schema&gt; 关于xsd:schema的各个属性具体含义就不作过多解释，可以参见http://www.w3school.com.cn/schema/schema_schema.asp &lt;xsd:element name=”people”&gt;对应着配置项节点的名称，因此在应用中会用people作为节点名来引用这个配置 &lt;xsd:attribute name=”name” type=”xsd:string” /&gt;和&lt;xsd:attribute name=”age” type=”xsd:int” /&gt;对应着配置项people的两个属性名，因此在应用中可以配置name和age两个属性，分别是string和int类型 完成后需把xsd存放在classpath下，一般都放在META-INF目录下（本例就放在这个目录下） 3. 编写NamespaceHandler和BeanDefinitionParser完成解析工作 1234567891011121314151617181920212223242526 public class MyNamespaceHandler extends NamespaceHandlerSupport &#123; public void init() &#123; registerBeanDefinitionParser("people", new PeopleBeanDefinitionParser()); &#125; &#125; public class PeopleBeanDefinitionParser extends AbstractSingleBeanDefinitionParser &#123; protected Class getBeanClass(Element element) &#123; return People.class; &#125; protected void doParse(Element element, BeanDefinitionBuilder bean) &#123; String name = element.getAttribute("name"); String age = element.getAttribute("age"); String id = element.getAttribute("id"); if (StringUtils.hasText(id)) &#123; bean.addPropertyValue("id", id); &#125; if (StringUtils.hasText(name)) &#123; bean.addPropertyValue("name", name); &#125; if (StringUtils.hasText(age)) &#123; bean.addPropertyValue("age", Integer.valueOf(age)); &#125; &#125; &#125; 4. 编写spring.handlers和spring.schemas串联起所有部件 spring提供了 spring.handlers和spring.schemas这两个配置文件来完成这项工作，这两个文件需要我们自己编写并放入META-INF文件夹 中，这两个文件的地址必须是META-INF/spring.handlers和META-INF/spring.schemas，spring会默认去 载入它们，本例中spring.handlers如下所示： spring.handlers 1http\://veryjj/cutesource/schema/people=study.schemaExt.MyNamespaceHandler spring.schemas 1http\://veryjj/cutesource/schema/people.xsd=META-INF/people.xsd 以上就是载入xsd文件 5. 使用自定义schema定义Spring Bean 到此为止一个简单的自定义配置以完成，可以在具体应用中使用了。使用方法很简单，和配置一个普通的spring bean类似，只不过需要基于我们自定义schema，本例中引用方式如下所示： 12345678&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:cutesource="http://veryjj/cutesource/schema/people" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://veryjj/cutesource/schema/people http://veryjj/cutesource/schema/people.xsd"&gt; &lt;cutesource:people id="cutesource" name="黄老师" age="27"/&gt; &lt;/beans&gt; 其中xmlns:cutesource=”http://veryjj/cutesource/schema/people&quot; 是用来指定自定义schema，xsi:schemaLocation用来指定xsd文件。&lt;cutesource:people id=”cutesource” name=”黄老师” age=”27”/&gt;是一个具体的自定义配置使用实例。 6. 注入自定义schema定义的Spring Bean 跟Spring Bean的注入方式完全一样，按你喜欢的方式来。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo源码解析-Dubbo可以这么学]]></title>
    <url>%2F2018%2F04%2F22%2FDubbo%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-Dubbo%E5%8F%AF%E4%BB%A5%E8%BF%99%E4%B9%88%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[最近面试工作颇多，Dubbo作为的微服务主流技术架构，也是分布式系统中面试的高频考题之一。但从面试的过程中得到的反馈，大家对于Dubbo的关注以及掌握程度基本都处于会基本使用的程度，基本没遇到有对Dubbo框架做学习研究的求职者。 求职者一般只会聊下面两个话题： Dubbo 是什么东西？ 答：RPC框架/微服务框架，在实际工作中用Dubbo做业务功能服务化。 Dubbo的工作原理是什么样的？ 答：Provider端将服务注册到Zookeeper中，Consumer端从Zookeeper获取Provider，然后就可以调用API了。 一般情况下关于Dubbo的基本都聊到此结束了，虽然说没回答错，但也忒简洁了吧，连Dubbo架构图中（下图）的内容都没说完整，而这并不是面试官想得到的讯息。 Dubbo作为主流的微服务技术框架，必然有其优秀的一面，也是学习RPC框架思想很好的素材 Dubbo 应该掌握哪些内容？（个人思路） 阅读Dubbo的用户手册以及开发手册。Dubbo.io 知晓Dubbo支持的功能 知晓Dubbo的各种扩展点 知晓Dubbo的设计思想（这里不得不说Dubbo.io的文档说明写的非常详细、到位，甚至一度让我觉得没有写Blog的必要） Dubbo 核心流程源码实现 Dubbo Bean的集成 Provider 注册、暴露服务 Consumer 注册、订阅服务 Consumer 调用实现 Provider 处理请求 Dubbo SPI机制 Dubbo Filter机制 思考些高级的 Dubbo各可配机制主流选择的优缺点 register remoting rpc Dubbo Cluster Dubbo 怎么做服务治理 策略路由 降级 熔断 Dubbo 性能基线&amp;性能调优 框架扩展 服务监控 流量分析 那么，逐步的去落实吧！如果开始、请务必坚持！]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Dubbo</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 核心对象梳理-1]]></title>
    <url>%2F2018%2F04%2F08%2FNetty-%E6%A0%B8%E5%BF%83%E5%AF%B9%E8%B1%A1%E6%A2%B3%E7%90%86-1%2F</url>
    <content type="text"><![CDATA[《Netty In Action》阅读笔记摘要 What is NettyNetty是一款用于快速开发高性能的网络应用程序的Java框架 它封装了网络编程的复杂性 Key words: 是一款Java语言的开发框架 封装、提供程序快速网络编程的能力 高性能 Netty是完全异步和事件驱动的 Netty 核心组件ChannelChannel 是Java NIO的一个基本构造 可以将Channel 看作是连接的载体。因此，它可以被打开、被关闭、连接、断开连接。 事件Channel连接上发生的事件。可以等价的理解为 epoll 中关于每个Socket事件，例如：EPOLLIN, EPOLLOUT, EPOLLHUP的回调 回调类似于常见的回调，Netty内部用回调来处理事件； 可理解为 epoll 中关于每个Socket事件的回调，例如：EPOLLIN, EPOLLOUT, EPOLLHUP的回调。 应用程序可以自定义回调，感知Netty网络通信的事件。 ChannelFutureFuture提供了另一种在操作完成时通知应用程序的方式。 JDK中的java.util.concurrent.Future 在使用上是阻塞调用的，不优雅。Netty 提供了另一种实现：ChannelFuture，用于在执行异步操作的时候使用。 Netty的每个出站I/O都将返回一个ChannelFuture。 使用ChannelFuture时，可以配合使用ChannelFutureListener。只要实现operationComplete() 回调即可，非常方便。且支持多ChannelFuture。 1234567891011121314151617Channel channel = ...;//Does not block ChannelFuture future = channel.connect(new InetSocketAddress("192.168.0.1", 25));​future.addListener(new ChannelFuturelistener()&#123; @Override public void operationComplete(ChannelFuture future)&#123; if (future.isSuccess())&#123; ByteBuf buffer = Unpooled.copiedBuffer("Hello", Charset.defaultCharset()); ChannelFuture wf = future.channel().writeAndFlush(buffer); ... &#125; else &#123; Throwable cause = future.cause(); cause.printStackTrace(); &#125; &#125;&#125;) ChannelHandler可以初步理解为每个ChannelHandler实例都类似于一种为了响应特定事件而被执行的回调。 PSNetty 的内部实现细节跟Linux epoll的用法很相似，熟悉Linux Epoll以及编程模型的朋友来说可以对比着来学习，寻找类同点、差异点以及差异的原因。 Netty 同时支持OIO, NIO, EPOLL等多路复用模式，我是以熟悉的epoll作为切入熟悉的内部流程原理。 Netty的组件和设计 Channel ———— Socket； EventLoop ———— 控制流、多线程处理、并发； ChannelFuture ———— 异步通知； Channel 接口Netty的Channel接口所提供的API，大大地降低了使用Socket类的复杂性。 EventLoopGroup 接口主要作用 用于注册Channel 执行部分Runnable任务 这里重点讲下“注册Channel”，在实际编程或应用时，每个Channel都是向EventLoopGroup注册的，由EventLoopGroup按照指定的策略方法，将Channel注册到EventLoopGroup下某个具体的EventLoop当中去。 12345678910111213141516171819202122232425262728293031323334public interface EventLoopGroup extends EventExecutorGroup &#123; ... /** * Register a &#123;@link Channel&#125; with this &#123;@link EventLoop&#125;. The returned &#123;@link ChannelFuture&#125; * will get notified once the registration was complete. */ ChannelFuture register(Channel channel); ...&#125;public abstract class MultithreadEventLoopGroup extends MultithreadEventExecutorGroup implements EventLoopGroup &#123; ... @Override public ChannelFuture register(Channel channel) &#123; return next().register(channel); &#125; ...&#125;public abstract class MultithreadEventExecutorGroup extends AbstractEventExecutorGroup &#123; ... @Override public EventExecutor next() &#123; return chooser.next(); &#125; ... EventLoop 接口EventLoop定义了Netty的核心抽象，用于处理连接的生命周期中所发生的事件。 一个EventLoopGroup包含一个或者多个EventLoop； 一个EventLoop在它的生命周期内只和一个Thread绑定； 所有由EventLoop处理的I/O事件都将在它专有的Thread上被处理； 一个Channel在它的生命周期内只注册于一个EventLoop； 一个EventLoop可能会被分配给一个或多个Channel； 在这种设计中，一个给定的Channel的I/O操作都是由相同的Thread执行的，实际上消除了对于同步的需要。 ChannelFuture 接口Netty中所有的I/O操作都是异步的。所有我们需要一种用于在之后的某个时间点确定其结果的方法。 为此，Netty提供了ChannelFuture接口，其addListener()方法注册了一个ChannelFutureListener，以便在某个操作完成时得到通知。 ChannelHandler 接口顾名思义，Channel的Handler，它充当了所有处理入站和出站数据的应用程序逻辑的容器。ChannelHandler的方法是由网络事件触发的。 ChannelPipeline 接口ChannelPipeline为ChannelHandler链提供了容器，并定义了用于在该链上传播入站和出站事件流的API。当Channel被创建时，它会被自动的分配到它专属的ChannelPipeline。 ChannelPipleline中的ChannelHandler的执行顺序是由它们被添加的顺序所决定的。 编码器和解码器Netty用于网络通信，天然需要编码和解码。也是用ChannelPipeline + ChannelHandler的机制实现的。 所有由Netty提供的编码器/解码器适配器类都实现了ChannelOutboundHandler或者ChannelInboundHandler接口。 引导（Bootstrap）Netty的引导类为应用程序的网络层配置提供了容器。 类别 Bootstrap ServerBootstrap 网络编程中的作用 连接到远程主机和端口 绑定到一个本地端口 EventLoopGroup的数目 1 2 使用Netty的ChannelOption和属性 在每个Channel创建时都手动配置它可能会变得相当乏味。幸运的是，你不必这样做。相反，你可以使用option()方法来将ChannelOption应用到Bootstrap上。你所提供的值将会被自动应用到Bootstrap所创建的所有Channel。 引导DatagramChannel Bootstrap除了引导基于TCP协议的SocketChannel，也可以用于引导无连接的协议。Netty提供了各种DatagramChannel的实现。与面向连接的TCP相比，唯一区别是不再调用connect()方法，而是只调用bind()方法 123456789101112131415161718192021222324//使用Bootstrap和DatagramChannelBootstrap bootstrap = new Bootstrap();bootstap.group(new OioEventLoopGroup()) .channel(OioDatagramChannel.class) .handler(new SimpleChannelInboundHandler&lt;DatagramPacket&gt;()&#123; @Override public void channelRead0(ChannelHandlerContext ctx, DatagramPacket msg) throws Exception &#123; //Do something with the packet &#125; &#125;);ChannelFuture future = bootstrap.bind(new InetSocketAddress(0));future.addListener(new ChannelFutureListener()&#123; @Override public void operationComplete(ChannelFuture channelFuture) throws Exception&#123; if (channelFuture.isSuccess())&#123; System.out.println("Channel bound"); &#125; else &#123; System.out.println("Bind attempt failed"); channelFuture.cause().printStackTrace(); &#125; &#125;&#125;) 我的理解 引导的根对象是 EventLoopGroup，间接的负责监听、处理所有Channel的网络事件。 EventLoop是EventLoopGroup内的成员，每个EventLoop与具体的线程绑定。也可以理解一个线程，一个EventLoop。 EventLoop直接负责处理其下所有Channel的网络事件。 ChannelHadler是Channel网络事件逻辑处理的容器，应用逻辑开发的重点就在此。 当一个Channel上来一个网络事件时，对应的EventLoop首先进行响应，并找到Channel所属的ChannelPipeline，Channel作为输入驱动一次ChannelPipeline。 ChannelPipeline 遍历其下ChannelHandler，逐个处理Channel的网络事件。 ChannelFuture可以同步等结果，也可以异步通知结果，都支持，自己选！ ByteBuf网络数据的基本单位是字节。Java NIO提供了ByteBuffer作为它的字节容器，但是这个类使用起来过于复杂，而且也有些繁琐。 Netty的ByteBuffer替代品是ByteBuf，一个强大的实现，既解决了JDK API的局限性，又为网络应用程序的开发者提供了更好的API。 ByteBuf优点： 对于同一个数据buffer，维护readIndex, writeIndex两份索引 ByteBuf模式 堆缓冲区模式： 将数据存储在JVM的堆空间中，应用代码可直接访问缓冲区中的数据。 直接缓冲区模式： JDK 1.4引入的ByteBuffer类允许JVM实现直接使用操作系统的本地内容，这就避免了JAVA 应用在每次调用本地I/O操作前/后 需要将缓冲区的内容复制到一个与操作系统结合的中间缓冲区中。 缺点：因为数据不是在堆上，所以业务代码处理时不得不经过一次复制。 复合缓冲区： 为多个ByteBuf提供一个统一的聚合视图，可以根据需要向复合缓冲区中添加或者删除ByteBuf实例。 字节级操作 可以以字节的操作方式使用ByteBuf 随机访问索引 顺序访问索引 可丢弃字节 可读字节 可写字节 索引管理 indexOf / ByteBufProcessor 派生缓冲区 读/写操作 ByteBuf池化分配 为了降低分配和释放内存的开销，Netty通过interface ByteBufAllocator实现了ByteBuf的池化。 Unpooled 缓冲区 如果未能获取到一个ByteBufAllocator的引用，Netty提供一个简单的Unpooled工具类，它提供创建未池化的ByteBuf实例。 关于 ChannelFuture 和 ChannelPromise ChannelFuture read-only 没有返回值的异步通知、调用 DefaultFutureListeners -&gt; listeners[N] ChannelPromise writeable 可写异步执行结果的通知、调用 notifyListenerNow -&gt; 回到Listeners -&gt; 取出对应的Channel进行回调操作]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅聊分布式事务]]></title>
    <url>%2F2018%2F03%2F30%2F%E6%B5%85%E8%81%8A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[前言 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最近很久没有写博客了，一方面是因为公司事情最近比较忙，另外一方面是因为在进行 CAP 的下一阶段的开发工作，不过目前已经告一段落了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接下来还是开始我们今天的话题，说说分布式事务，或者说是我眼中的分布式事务，因为每个人可能对其的理解都不一样。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式事务是企业集成中的一个技术难点，也是每一个分布式系统架构中都会涉及到的一个东西，特别是在微服务架构中，几乎可以说是无法避免，本文就分布式事务来简单聊一下。 数据库事务 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在说分布式事务之前，我们先从数据库事务说起。 数据库事务可能大家都很熟悉，在开发过程中也会经常使用到。但是即使如此，可能对于一些细节问题，很多人仍然不清楚。比如很多人都知道数据库事务的几个特性：原子性(Atomicity )、一致性( Consistency )、隔离性或独立性( Isolation)和持久性(Durabilily)，简称就是ACID。但是再往下比如问到隔离性指的是什么的时候可能就不知道了，或者是知道隔离性是什么但是再问到数据库实现隔离的都有哪些级别，或者是每个级别他们有什么区别的时候可能就不知道了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文并不打算介绍这些数据库事务的这些东西，有兴趣可以搜索一下相关资料。不过有一个知识点我们需要了解，就是假如数据库在提交事务的时候突然断电，那么它是怎么样恢复的呢？ 为什么要提到这个知识点呢？ 因为分布式系统的核心就是处理各种异常情况，这也是分布式系统复杂的地方，因为分布式的网络环境很复杂，这种“断电”故障要比单机多很多，所以我们在做分布式系统的时候，最先考虑的就是这种情况。这些异常可能有 机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠的TCP、存储数据丢失、其他异常等等… &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们接着说本地事务数据库断电的这种情况，它是怎么保证数据一致性的呢？我们使用SQL Server来举例，我们知道我们在使用 SQL Server 数据库是由两个文件组成的，一个数据库文件和一个日志文件，通常情况下，日志文件都要比数据库文件大很多。数据库进行任何写入操作的时候都是要先写日志的，同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时候，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;接着，我们就说一下分布式事务。 分布式理论 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当我们的单个数据库的性能产生瓶颈的时候，我们可能会对数据库进行分区，这里所说的分区指的是物理分区，分区之后可能不同的库就处于不同的服务器上了，这个时候单个数据库的ACID已经不能适应这种情况了，而在这种ACID的集群环境下，再想保证集群的ACID几乎是很难达到，或者即使能达到那么效率和性能会大幅下降，最为关键的是再很难扩展新的分区了，这个时候如果再追求集群的ACID会导致我们的系统变得很差，这时我们就需要引入一个新的理论原则来适应这种集群的情况，就是 CAP 原则或者叫CAP定理，那么CAP定理指的是什么呢？ CAP定理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CAP定理是由加州大学伯克利分校Eric Brewer教授提出来的，他指出WEB服务无法同时满足一下3个属性： 一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效) 可用性(Availability) ： 每个操作都必须以可预期的响应结束 分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成 具体地讲在分布式系统中，在任何数据库设计中，一个Web应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。 这个定理在迄今为止的分布式系统中都是适用的！ 为什么这么说呢？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个时候有同学可能会把数据库的2PC（两阶段提交）搬出来说话了。OK，我们就来看一下数据库的两阶段提交。 对数据库分布式事务有了解的同学一定知道数据库支持的2PC，又叫做 XA Transactions。 MySQL从5.5版本开始支持，SQL Server 2005 开始支持，Oracle 7 开始支持。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，XA 是一个两阶段提交协议，该协议分为以下两个阶段： 第一阶段：事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交. 第二阶段：事务协调器要求每个数据库提交数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。这样做的缺陷是什么呢? 咋看之下我们可以在数据库分区之间获得一致性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果CAP 定理是对的，那么它一定会影响到可用性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果说系统的可用性代表的是执行某项操作相关所有组件的可用性的和。那么在两阶段提交的过程中，可用性就代表了涉及到的每一个数据库中可用性的和。我们假设两阶段提交的过程中每一个数据库都具有99.9%的可用性，那么如果两阶段提交涉及到两个数据库，这个结果就是99.8%。根据系统可用性计算公式，假设每个月43200分钟，99.9%的可用性就是43157分钟, 99.8%的可用性就是43114分钟，相当于每个月的宕机时间增加了43分钟。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上，可以验证出来，CAP定理从理论上来讲是正确的，CAP我们先看到这里，等会再接着说。 BASE理论&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢？ 前人已经给我们提出来了另外一个理论，就是BASE理论，它是用来对CAP定理进行进一步扩充的。BASE理论指的是： Basically Available（基本可用） Soft state（软状态） Eventually consistent（最终一致性） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有了以上理论之后，我们来看一下分布式事务的问题。 分布式事务&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式系统中，要实现分布式事务，无外乎那几种解决方案。 一、两阶段提交（2PC）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;和上一节中提到的数据库XA事务一样，两阶段提交就是使用XA协议的原理，我们可以从下面这个图的流程来很容易的看出中间的一些比如commit和abort的细节。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;两阶段提交这种解决方案属于牺牲了一部分可用性来换取的一致性。在实现方面，在 .NET 中，可以借助 TransactionScop 提供的 API 来编程实现分布式系统中的两阶段提交，比如WCF中就有实现这部分功能。不过在多服务器之间，需要依赖于DTC来完成事务一致性，Windows下微软搞的有MSDTC服务，Linux下就比较悲剧了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外说一句，TransactionScop 默认不能用于异步方法之间事务一致，因为事务上下文是存储于当前线程中的，所以如果是在异步方法，需要显式的传递事务上下文。 优点： 尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不能100%保证强一致） 缺点： 实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景，如果分布式系统跨接口调用，目前 .NET 界还没有实现方案。 二、补偿事务（TCC）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。它分为三个阶段： Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 举个例子，假入 Bob 要向 Smith 转账，思路大概是：我们有一个本地方法，里面依次调用1、首先在 Try 阶段，要先调用远程接口把 Smith 和 Bob 的钱给冻结起来。2、在 Confirm 阶段，执行远程调用的转账的操作，转账成功进行解冻。3、如果第2步执行成功，那么转账成功，如果第二步执行失败，则调用远程冻结接口对应的解冻方法 (Cancel)。 优点： 跟2PC比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些 缺点： 缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。 三、本地消息表（异步确保）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本地消息表这种实现方式应该是业界使用最多的，其核心思想是将分布式事务拆分成本地事务进行处理，这种思路是来源于ebay。我们可以从下面的流程图中看出其中的一些细节： 基本思路就是： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种方案遵循BASE理论，采用的是最终一致性，笔者认为是这几种方案里面比较适合实际业务场景的，即不会出现像2PC那样复杂的实现(当调用链很长的时候，2PC的可用性是非常低的)，也不会像TCC那样可能出现确认或者回滚不了的情况。 优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。在 .NET中 有现成的解决方案。 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 四、MQ 事务消息&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持。 以阿里的 RocketMQ 中间件为例，其思路大致为： 第一阶段Prepared消息，会拿到消息的地址。 第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。 也就是说在业务方法内要想消息队列提交两次请求，一次发送消息和一次确认消息。如果确认消息发送失败了RocketMQ会定期扫描消息集群中的事务消息，这时候发现了Prepared消息，它会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 优点： 实现了最终一致性，不需要依赖本地数据库事务。 缺点： 实现难度大，主流MQ不支持，没有.NET客户端，RocketMQ事务消息部分代码也未开源。 五、Sagas 事务模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Saga事务模型又叫做长时间运行的事务（Long-running-transaction）, 它是由普林斯顿大学的H.Garcia-Molina等人提出，它描述的是另外一种在没有两阶段提交的的情况下解决分布式系统中复杂的业务事务问题。你可以在这里看到 Sagas 相关论文。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们这里说的是一种基于 Sagas 机制的工作流事务模型，这个模型的相关理论目前来说还是比较新的，以至于百度上几乎没有什么相关资料。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该模型其核心思想就是拆分分布式系统中的长事务为多个短事务，或者叫多个本地事务，然后由 Sagas 工作流引擎负责协调，如果整个流程正常结束，那么就算是业务成功完成，如果在这过程中实现失败，那么Sagas工作流引擎就会以相反的顺序调用补偿操作，重新进行业务回滚。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如我们一次关于购买旅游套餐业务操作涉及到三个操作，他们分别是预定车辆，预定宾馆，预定机票，他们分别属于三个不同的远程接口。可能从我们程序的角度来说他们不属于一个事务，但是从业务角度来说是属于同一个事务的。 他们的执行顺序如上图所示，所以当发生失败时，会依次进行取消的补偿操作。 因为长事务被拆分了很多个业务流，所以 Sagas 事务模型最重要的一个部件就是工作流或者你也可以叫流程管理器（Process Manager），工作流引擎和Process Manager虽然不是同一个东西，但是在这里，他们的职责是相同的。在选择工作流引擎之后，最终的代码也许看起来是这样的 12345678910111213SagaBuilder saga = SagaBuilder.newSaga(&quot;trip&quot;) .activity(&quot;Reserve car&quot;, ReserveCarAdapter.class) .compensationActivity(&quot;Cancel car&quot;, CancelCarAdapter.class) .activity(&quot;Book hotel&quot;, BookHotelAdapter.class) .compensationActivity(&quot;Cancel hotel&quot;, CancelHotelAdapter.class) .activity(&quot;Book flight&quot;, BookFlightAdapter.class) .compensationActivity(&quot;Cancel flight&quot;, CancelFlightAdapter.class) .end() .triggerCompensationOnAnyError();camunda.getRepositoryService().createDeployment() .addModelInstance(saga.getModel()) .deploy(); 这里有一个 C# 相关示例，有兴趣的同学可以看一下。 优缺点 这里我们就不说了，因为这个理论比较新，目前市面上还没有什么解决方案，即使是 Java 领域，我也没有搜索的太多有用的信息。 转自：https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识鱼骨图]]></title>
    <url>%2F2018%2F03%2F29%2F%E8%AE%A4%E8%AF%86%E9%B1%BC%E9%AA%A8%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[今天，偶然的机会在同事电脑上漂见“鱼骨图”。晚上吃完饭就在思考这个问题：“为什么我从来没用过鱼骨图分析问题？鱼骨图适用于什么类型的分析？” 查了些资料追求普及，介绍的内容大同小异 概念摘要鱼骨分析法，又名 因果分析法，是一种发现问题”根本原因”的分析方法。 鱼骨图可以进一步被划分为： 整理问题型鱼骨图（各要素与特性值间不存在原因关系，而是结构构成关系） 原因型鱼骨图（鱼头在右，特性值通常以“为什么……”来写） 对策型鱼骨图（鱼头在左，特性值通常以“如何提高/改善……”来写） 怎么作图分析结构 A、针对问题点，选择层别方法（如人机料法环等）； B、按头脑风暴分别对各层别类别找出所有可能原因（因素）； C、将找出的各要素进行归类、整理，明确其从属关系； D、分析选取重要因素； E、检查各要素的描述方法，确保语法简明、意思明确; 分析要点 A、确定大要因（大骨）时，现场作业一般从“人机料法环”着手,管理类问题一般从“人事时地物”层别，应视具体情况决定； B、大要因必须用中性词描述（不说明好坏），中、小要因必须使用价值判断（如…不良）； C、头脑风暴时，应尽可能多而全地找出所有可能原因，而不仅限于自己能完全掌控或正在执行的内容。对人的原因，宜从行动而非思想态度面着手分析； D、中要因跟特性值、小要因跟中要因间有直接的原因-问题关系，小要因应分析至可以直接下对策； E、如果某种原因可同时归属于两种或两种以上因素，请以关联性最强者为准（必要时考虑三现主义：即现时到现场看现物，通过相对条件的比较，找出相关性最强的要因归类。）； F、选取重要原因时，不要超过7项，且应标识在最未端原因。 绘图过程 A、填写鱼头（按为什么不好的方式描述），画出主骨； B、画出大骨，填写大要因； C、画出中骨、小骨，填写中小要因； D、用特殊符号标识重要因素； 使用步骤(1) 查找要解决的问题； (2) 把问题写在鱼骨的头上； (3) 召集同事共同讨论问题出现的可能原因，尽可能多地找出问题； (4) 把相同的问题分组，在鱼骨上标出； (5) 根据不同问题征求大家的意见，总结出正确的原因； (6) 拿出任何一个问题，研究为什么会产生这样的问题； (7) 针对问题的答案再问为什么？这样至少深入五个层次（连续问五个问题）； (8) 当深入到第五个层次后，认为无法继续进行时，列出这些问题的原因，而后列出至少20个解决方法。 看了鱼骨图的概念介绍后，在脑海中立马出现了新的问题：”鱼骨图和思维导图有什么区别？” 鱼骨图和思维导图有什么区别？类同点 都是基于主题逐步分解、细化的过程 都是类树形结构 我的理解理解-1首先、思维导图和鱼骨图都是图形思维，而图形思维最大的特点就是将我们的思维结构化，并由此实现图形化。 而所谓的结构化一般就是构建逻辑思维，任何的逻辑思维都是基于这两个出发点而来的：1、分类；2、顺序；所以只要你的分类与顺序是一样的，那么你的逻辑思维是一样的，由此产生的图形思维也是一样的。而图形、分列、表格……只是图形思维具体的呈现方式。换句话说，在图形思维一样的前提下，不同的人选择了自己认为好的呈现方式让图形思维更可视化、更清晰化、更感性化。 另外，还有不同之处在于思维导图不仅仅能用于构建逻辑思维，还能扩展发散思维，以及还能强化思维记忆。这是和鱼骨图的区别之一！ 理解-2 【思维导图】在实际应用中，思维导图常用于个人，侧重于个人思维的发散，以求思维的全面性，思维导图的层次感是逻辑思维自然的产出。应用场景广泛。 【鱼骨图】常用在多人同时参与的头脑风暴场景，侧重于发挥团队智力逐层解剖问题，找到问题原因。往往会以”问题原因分析 + 跟进Action”作为结果产出。 鱼骨图作图工具 Xmind]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>分析图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo写作技巧]]></title>
    <url>%2F2018%2F03%2F17%2FHexo%E5%86%99%E4%BD%9C%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[Hexo 写作的技巧与备忘，不喜勿喷。 链接： Hexo命令 文章插入图片原生Markdown语法原生Markdown语法插入图片有三种方式 1. 插入本地图片只需要在基础语法的括号中填入图片的位置路径即可，支持绝对路径和相对路径。例如： 1![image](/home/picture/1.png) 评价：不灵活不好分享，本地图片的路径更改或丢失都会造成markdown文件调不出图。 2. 插入网络图片只需要在基础语法的括号中填入图片的网络链接即可，现在已经有很多免费/收费图床和方便传图的小工具可选。例如： 1![image](http://baidu.com/pic/doge.png) 评价：将图片存在网络服务器上，非常依赖网络和网络图片存储 3. 把图片存入markdown文件用base64转码工具把图片转成一段字符串，然后把字符串填到基础格式中链接的那个位置。基础用法： 1![avatar](data:image/png;base64,iVBORw0......) 这个时候会发现插入的这一长串字符串会把整个文章分割开，非常影响编写文章时的体验。如果能够把大段的base64字符串放在文章末尾，然后在文章中通过一个id来调用，文章就不会被分割的这么乱了。比如： 12![avatar][doge] [doge]:data:image/png;base64,iVBORw0...... 评价：麻烦，费劲。 Hexo方式安装插件与配置 把主页配置文件_config.yml 里的post_asset_folder:这个选项设置为true 在你的hexo目录下执行这样一句话npm install hexo-asset-image –save，这是下载安装一个可以上传本地图片的插件 等待一小段时间后，再运行hexo n “xxxx”来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 使用方式在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片 1![你想输入的替代文字](xxxx/图片名.jpg) 注意： xxxx是这个md文件的名字，也是同名文件夹的名字。只需要有文件夹名字即可，不需要有什么绝对路径。你想引入的图片就只需要放入xxxx这个文件夹内就好了，很像引用相对路径。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo装修记录]]></title>
    <url>%2F2018%2F03%2F17%2FHexo%E8%A3%85%E4%BF%AE%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[前篇《个人博客搭建-结缘Hexo》 从时间投入上来说，搭建Hexo可谓是分分钟的事情，装修可花了我近一天的时间。 Hexo 是一个开放、扩展性强的框架，样式风格、功能都可以通过主题包、插件来实现。完全可以根据个人口味来装修你的博客。 选主题关于Hexo的主题，你可以问度娘”Hexo Themes”网友好评度高的主题，也可以去官网自行挑选https://hexo.io/themes/ 需要提前说明的是：不是选上对应主题，所有功能就有了，这也是我为什么会单独写这篇备忘的原因。 经过各种试用和对比，我最终选择了：NexT这个主题 Go Github，理由如下： （Most Important）界面符合我口味。NexT 中的Pisces主题，样例：IIssNan’s Notes NexT主题集成的插件多，极大的方便了初级的小白用户，详见：NexT主题的_config.xml配置项 博客评论 Baidu Analytics / Google Analytics 文章阅读数量 baidu push algolia_search / local_search 背景画布特效 highlight_theme 等等 支持手机端 安装主题Hexo theme 统一放在Hexo根目录的themes目录下，每个主题一个子目录。 如果主题是Github上的，推荐使用如下命令下载 1git clone https://github.com/iissnan/hexo-theme-next.git themes/next 然后修改hexo根目录下的_config.xml，切换主题 OK, hexo g -&gt; hexo s 看下效果吧 主题配置找到 hexo/themes/next/_config.xml，一项项阅读熟悉吧，注释写的很详细。 基础配置基础配置项： 菜单配置：主页、关于、标签、分类、归档等 头像 打赏 社交主页 侧边栏 主题的_config.xml会引用hexo的_config.xml中基础配置，所以请同时配置hexo的_config.xml，例如：博客抬头、语种、相关数据目录等 背景特效效果图示 配置next主题的_config.xml 支持搜索 文章阅读计数NexT提供两种插件方式：1、leancloud_visitors（国内的） 和 2、firestore(谷歌的)我选用的是leancloud_visitors，配置相对简单一些 配置LeanCloud 注册：https://leancloud.cn打开LeanCloud官网，进入注册页面注册。完成邮箱激活后，点击头像，进入控制台页面创建新应用，如下： 创建名称为Counter的Class 修改NexT的_config.xml配置文件 123456# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.leancloud_visitors: enable: true app_id: "你的App Id" app_key: "你的App Key" PV/UV Google Analytics12# Google Analyticsgoogle_analytics: '你的Google Analytics Code' 问题解决标签和分类页面不显示问题当时切换NexT主题后，侧边栏的标签、分类点击时，是无法正常显示标签和分类的，属：Cannot Get /tags/ 若出现此问题，请按下方式解决在hexo 目录下执行 步骤一： 1hexo new page 'tags' 步骤二： 编辑刚新建的页面，将页面的类型设置为tags，主题会自动为这个页面显示标签云。 123456---title: TagClouddate: 2018-03-17 15:31:21type: "tags"comments: false #注意：如果有启动多说或Disqus评论，需要关闭评论，添加comments字段并设置为false--- “分类”同理~ 其他推荐 hexo的next主题个性化配置教程]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人博客搭建-结缘Hexo]]></title>
    <url>%2F2018%2F03%2F17%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA-%E7%BB%93%E7%BC%98Hexo%2F</url>
    <content type="text"><![CDATA[Github Pages + Hexo 搭建个人博客偶然的机会，看到”***.github.io”域名的个人博客，瞬间就来了兴趣，莫非Github能方便的创建个人博客？ 咨询了下度娘，知道了用GitHub Pages + Hexo 搭建个人博客的方式，于是说干就干！ PS: 我用的是Macbook + Shell，某些操作Windows的朋友可能要转化翻译成Windows上的命令。 1. 创建Github仓库首先，个人Github账号应该有吧？如果没有，先去注册一个。 然后，在Github上新建一个仓库，如下图： 确保新建的仓库以Github Pages方式发布 OK，此步骤完成了！ 2. 安装Hexo正式使用Hexo前，请先安装Node.js 和Git 安装Node.js去官网下载并安装：Link 安装Git 作为玩Github的程序员，默认你已经安装了Git 安装Hexo 新建一个目录作为Hexo的根目录（PS: 后续Hexo相关的功能以及写博客都基于此目录） 进入新建的目录 12345npm install hexo-cli -ghexo init #初始化网站npm installhexo g #hexo generate的简写，意思生成博客站点hexo s #hexo server的简写，即启动运行hexo的站点，这一步之后就可以通过http://localhost:4000 查看了 常用Hexo命令 1234hexo c : hexo clean 清除hexo已生成的publichexo g : hexo generate 重新生成hexo站点hexo s : hexo server 运行hexo站点。注：本地运行时，在hexo上做的修改保存后即生效的，不用重新hexo ghexo d : hexo deploy 将hexo发布到github上去。 3. Hexo deploy 到Github 编辑根目录下_config.yml文件 1234deploy: type: git repo: https://github.com/VeryJJ/VeryJJ.github.io.git #这里的网址填你自己的 branch: master 安装hexo deploy插件： npm install hexo-deployer-git –save 在Hexo目录下执行hexo d hexo d 成功后，就大工告成拉！你可以在浏览器输入***.github.io(你新建的github.io仓库)，就能看到你的个人博客拉！ 以后写博客的步骤为： 在电脑本地hexo new ‘文章名’ 丰富你的文章 hexo g hexo d 发布 博客搭建好了，但相信你会觉得它好丑，没关系，请继续阅读下一篇Hexo的装修总结 参考链接 我是如何利用Github Pages搭建起我的博客，细数一路的坑]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 场景化下的命令备忘]]></title>
    <url>%2F2018%2F03%2F15%2FGit%20%E5%9C%BA%E6%99%AF%E5%8C%96%E4%B8%8B%E7%9A%84%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%2F</url>
    <content type="text"><![CDATA[查看分支1234git branchgit branch -a 查看远端所有分支git branch -v 查看本地分支，以及分支上最新的commit提交信息git branch -vv 在-v基础上，多现实本地分支和远程分支的关联关系 查看某次commit的修改1git show commit号 查看某个文件的历史修改记录12345678910111213141516171819202122232425262728293031323334git log 文件名git log -p 文件名git log --author=提交人 只查看提交人的提交记录git log --pretty=oneline 单行显示提交记录git log --name-only 显示每次commit修改的文件列表git log --name-status 查看commit记录里的文件修改状态git log --grep=&apos;abc&apos; 显示commit描述匹配abc的commit记录git log -S &quot;代码内容&quot; 按代码内容搜索commit记录，如果代码内容部分想用正则表达式，则将-S换成-Ggit log --pretty=&apos;%H %Cblue%cd %C(yellow)%cn %Cred%s&apos; 按commit号+提交日期+提交人+commit标题 显示pretty格式%H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %_ae 作者的电子邮件地址 （由于新浪博客显示问题，请去除 %_ae 中的 _ ）%_ad 作者修订日期（可以用 -date= 选项定制格式）（由于新浪博客显示问题，请去除 % ad 中的 _ ）%ar 作者修订日期，按多久以前的方式显示 %cn 提交者(committer)的名字 %_ce 提交者的电子邮件地址（由于新浪博客显示问题，请去除 %_ce 中的 _ ）%_cd 提交日期 （由于新浪博客显示问题，请去除 %_cd 中的 _ ）%cr 提交日期，按多久以前的方式显示 %d: ref名称%s: 提交的信息标题%b: 提交的信息内容%Cred: 切换到红色 %Cgreen: 切换到绿色 %_Cblue: 切换到蓝色 （由于新浪博客显示问题，请去除 %_Cblue 中的 _）%Creset: 重设颜色 %C(...): 制定颜色, as described in color.branch.* config option %n: 换行 查看未commit的本地修改12git diff git diff 文件名 git diff 比较commit之间的差异123git diff commit 比较HEAD与commit之间的差异git diff commit_1 commit_2 比较两个commit之间的差异git diff commit_1..commit_2 与git diff commit_1 commit_2 一样效果 从服务器拉代码git pull --rebase (推荐)会把本地未push得commit放到缓冲区，然后把远程最新版本拉过来，再应用本地commit，这样不会造成本地有新commit时，merge的效果。 git pull 直接更新，若本地和远端都有新commit，都执行自动merge。 拉分支git checkout -b branchName 创建本地新分支 git checkout -b branchName remotes/origin/branchName 以远端分支创建本地新分支 git push origin $newBranch:$newBranch 将本地分支提交到远端进行创建 删除远程分支123$ git push origin :master# 等同于$ git push origin --delete master 提交修改git add . 将修改加到stage状态区 git commint -m &quot;注释&quot; git push 推送所有分支 git push origin develop 只推送develop分支 添加文件git add -A 删除文件git rm 文件名 git rm -r 目录名 Pushgit push push所有分支 git push origin master 将本地主分支推到远程主分支 git push –u origin master 将本地主分支推到远程（如无远程主分支则创建，用于初始化远程仓库） git push origin &lt;local_branch&gt; 创建远程分支，origin是远程仓库名。 git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; 创建远程分支 强制push如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用–force选项。 git push --force origin 合并分支mergegit merge remotes/origin/mc-s-3 将远端mc-s-3分支merge到本地 rebasegit rebase develop git rebase remotes/origin/develop 配置mergetoolgit config –global merge.tool bc3 git config –global mergetool.bc3.path 软件执行文件地址 merge策略1234567891011Git merge 策略的总结:1、使用 -s 指定策略，使用 -X 指定策略的选项2、默认策略是recursive3、策略有 ours，但是没有theirs (Git老版本好像有)4、策略ours直接 忽略 合并分支的任何内容，只做简单的合并，保留分支改动的存在5、默认策略recursive有选项ours 和 theirs6、-s recursive -X ours 和 -s ours 不同，后者如第3点提到直接忽略内容，但是前者会做合并，遇到冲突时以自己的改动为主7、-s recursive -X theirs的对立面是 -s recursive -X ours`注：-s recursive -X ours 合并分支，冲突时以本地为主` 回退未commit的修改git checkout [path] 将指定路径的修改还原到最新版本 回退已commit，未push的修改git reset HEAD &lt;file&gt; --mixed 选项：默认的 --soft 选项：改动会回退到stage状态 --hard 选项：改动会直接丢失。 git rebase -i 想要删除的commit的前一个commit号。 出来的界面里，将想要删除的commit描述改为drop，保存即可。 回退已push的修改git revert 指定的commit号。跳出来的界面，选择要回退的commit内容（取消前面的#） 可以随便选某个commit删除 若revert一个merge的commit，则要指定parent 号 git revert commit 号 -m 1。 这样就选parent 1，那么parent 1又是哪一个呢？一般来说，如果你在master上mergezhc_branch,那么parent 1就是master，parent 2就是zhc_branch. 重排commit顺序git rebase -i commit号 出来的界面中，将列出来的commit行重新排序再保存，就等于修改commit顺序了。 修改commit的描述未push方法一： git rebase -i commit号 对应commit号前改为edit，保存。出来后git commit --amend。将commit描述修改掉，保存。 出来后再git rebase --continue即可。 方法二： git commit --amend 修改最近的一次commit 代码仓库迁移git clone --bare robbin_site robbin_site.git git remote remove origin git remote add origin git@120.27.160.167:ZCY/doc-round-1.git git push –-all -–progress origin 导出指定版本的代码版本 git archive -o ../updated.zip HEAD $(git diff --name-only HEAD^) 例如：git archive -o ./version.zip 指定commit号 或者 git archive --format zip -output &quot;./archive.zip&quot; HEAD tag功能创建taggit tag -a v1.0.0 -m &apos;备注&apos; 查看taggit tag 切换taggit checkout tag名 删除taggit tag -d v1.0.0 指定commit打taggit tag -a v1.0.0 commit号 发布标签git push origin v1.0.0 将本地v1.0.0标签推送到git服务器 git push origin -tags 将本地所有tag一次性推送到git服务器 创建补丁当前分支所有超前master的提交：git format-patch -M master 某次提交以后的所有patch:git format-patch 4e16 --4e16指的是commit名 从根到指定提交的所有patch:git format-patch --root 4e16 某两次提交之间的所有patch:git format-patch 365a..4e16 -o &lt;patch_dir&gt; --365a和4e16分别对应两次提交的名称 某次提交（含）之前的几次提交：git format-patch –n 07fe --n指patch数，07fe对应提交的名称 故，单次提交即为： git format-patch -1 07fe 应用补丁方法一（推荐）12345678910111、在同一个仓库下找到对应的commit号2、切换到对应分支下，git cherry-pick commit 号3、如果冲突，git mergetool 解决冲突。4、git status根据提示commit代码，并pushcherry-pick 一个commit区间git cherry-pick &lt;start-commit-id&gt;^..&lt;end-commit-id&gt; start-commit-id是版本树里较早的commitcherry-pick一个merge commitgit cherry-pick &lt;commit-id&gt; -m parent-number -m代表 --mainline实际例子：git cherry-pick 32b234 -m 1 1，2分别代表什么 查看未push到远程仓库的commit1、查看到未传送到远程代码库的提交次数12345 git status //只能看次数显示结果类似于这样：# On branch master# Your branch is ahead of &apos;origin/master&apos; by 2 commits. 2、查看到未传送到远程代码库的提交描述/说明12345git cherry -v显示结果类似于这样：+ b6568326134dc7d55073b289b07c4b3d64eff2e7 add default charset for table items_has_images+ 4cba858e87752363bd1ee8309c0048beef076c60 move Savant3 class into www/includes/class/ 3、查看到未传送到远程代码库的提交详情1234567891011121314git log master ^origin/master这是一个git log命令的过滤，^origin/master可改成其它分支。显示结果类似于这样：commit 4cba858e87752363bd1ee8309c0048beef076c60Author: Zam &lt;zam@iaixue.com&gt;Date: Fri Aug 9 16:14:30 2013 +0800 move Savant3 class into www/includes/class/commit b6568326134dc7d55073b289b07c4b3d64eff2e7Author: Zam &lt;zam@iaixue.com&gt;Date: Fri Aug 9 16:02:09 2013 +0800 add default charset for table items_has_images 查看两个分支的差异查看dev中有，而master中没有的1234git log dev ^master反之：查看master中有，dev中没有的git log master ^dev 查看dev中比master多了哪些提交（A比B多了哪些，就把A放..右边）1git log master..dev 不在乎谁多谁少，只想看差异的提交1git log --left-right dev...master #--left-right 会帮助显示差异的commit属于哪个分支 整个目录比较差异详情1git difftool develop..pre-online --dir Git stash 暂存1234567891011121314151617git stash 将当前工作区里未commit的修改放到暂存区，将代码恢复到最近的一次修改git stash list 查看暂存区的列表git show stash@&#123;0&#125; see the last stash git stash pop apply lastest stash and remove it from th list git stash clear 清空暂存栈git stash apply stash@&#123;1&#125; 指定暂存区里的某一次stash，应用到本地 删除本地git branch -a 能看到，而远程已经删掉的分支记录1git fetch -p 更改时间显示方式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--date=(relative|local|default|iso|rfc|short|raw) Only takes effect for dates shown in human-readable format, such as when using &quot;--pretty&quot;. log.date config variable sets a default value for log command’s --date option.--date=relative shows dates relative to the current time, e.g. &quot;2 hours ago&quot;.--date=local shows timestamps in user’s local timezone.--date=iso (or --date=iso8601) shows timestamps in ISO 8601 format.--date=rfc (or --date=rfc2822) shows timestamps in RFC 2822 format, often found in E-mail messages.--date=short shows only date but not time, in YYYY-MM-DD format.--date=raw shows the date in the internal raw git format %s %z format.--date=default shows timestamps in the original timezone (either committer’s or author’s).####格式化显示例子：--date=format:&apos;%Y-%m-%d %H:%M:%S&apos;参数：%a Abbreviated weekday name%A Full weekday name%b Abbreviated month name%B Full month name%c Date and time representation appropriate for locale%d Day of month as decimal number (01 – 31)%H Hour in 24-hour format (00 – 23)%I Hour in 12-hour format (01 – 12)%j Day of year as decimal number (001 – 366)%m Month as decimal number (01 – 12)%M Minute as decimal number (00 – 59)%p Current locale&apos;s A.M./P.M. indicator for 12-hour clock%S Second as decimal number (00 – 59)%U Week of year as decimal number, with Sunday as first day of week (00 – 53)%w Weekday as decimal number (0 – 6; Sunday is 0)%W Week of year as decimal number, with Monday as first day of week (00 – 53)%x Date representation for current locale%X Time representation for current locale%y Year without century, as decimal number (00 – 99)%Y Year with century, as decimal number%z, %Z Either the time-zone name or time zone abbreviation, depending on registry settings; no characters if time zone is unknown%% Percent sign 全局更改方式1git config --global log.date relative 代码量统计当天提交的代码量1git log --author=&quot;$(git config --get user.name)&quot; --no-merges --since=1am --stat 统计报告-gitstats 用GitStatX图形化工具查看 统计报告-gitinspector1gitinspector --format=html --since=2018-01-01 --until=2018-12-30 --timeline --localize-output -w ./ &gt; ~/tmp/gitinspector/zcy-payment-center-201801.html gitinspector命令说明123456789101112131415161718192021222324252627282930313233343536➜ car-manage git:(master) gitinspector --help用法：/usr/local/bin/gitinspector [选项]... [目录] 在目录列出有关库的信息,如果没有指定目录，那么将使用现目录。如果有多个目录，将采用指定的最后一个目录长选项的强制性参数对短选项也适用布尔参数只能给予长选项 -f, --file-types=EXTENSIONS 一串逗号分隔的文件类型 这些文件将会被用于计算统计数据. 默认文件类型: java,c,cc,cpp,h,hh,hpp,py,glsl,rb,js,sql -F, --format=FORMAT 指定生成的输出文件的格式； 默认格式是&apos;text&apos; 和 可选格式: html,htmlembedded,text,xml --grading[=BOOL] 按照学生成评判项目的格式， 显示统计数据和信息； 等同于 -HlmrTw 选项 -H, --hard[=BOOL] 记录行数并且寻找重复的内容; 如果数据库较大，这个可能会需要一些时间 -l, --list-file-types[=BOOL] 列出所有现在的数据库分支的文件格式 -L, --localize-output[=BOOL] 在翻译版本存在的前提下，将输出结果翻译到系统语言 -m --metrics[=BOOL] 在分析提交时，检查特定指标 -r --responsibilities[=BOOL] 显示每位作者主要职责 --since=DATE 只显示从特定时间起的结果 -T, --timeline[=BOOL] 显示提交时间轴, 包括作者名称 --until=DATE 只显示特定时间前的结果 -w, --weeks[=BOOL] 按周来显示统计数据，而非月 -x, --exclude=PATTERN 按特定格式排除不应该被统计 的文件，作者名字或邮箱;可以按文件名，作者名， 作者邮箱。可以重复 -h, --help 显示这个帮助信息并退出 --version 显示版本信息并退出gitinspector 会过滤信息并且仅统计那些修改，增加或减少，指定文件类型的提交，如需详细信息，请参考 -f 或 --file-types 选项]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
